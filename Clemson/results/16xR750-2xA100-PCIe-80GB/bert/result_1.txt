Beginning trial 02 of 10
:::DLPAL /scratch/nnisbet/bert.sif 2042 16 node[0400-0401,0403-0410,0413-0418]
Clearing cache on node0400.palmetto.clemson.edu
Clearing cache on node0403.palmetto.clemson.edu
Clearing cache on node0404.palmetto.clemson.edu
Clearing cache on node0409.palmetto.clemson.edu
Clearing cache on node0406.palmetto.clemson.edu
Clearing cache on node0418.palmetto.clemson.edu
Clearing cache on node0407.palmetto.clemson.edu
Clearing cache on node0410.palmetto.clemson.edu
Clearing cache on node0408.palmetto.clemson.edu
Clearing cache on node0414.palmetto.clemson.edu
Clearing cache on node0413.palmetto.clemson.edu
Clearing cache on node0416.palmetto.clemson.edu
Clearing cache on node0415.palmetto.clemson.edu
Clearing cache on node0405.palmetto.clemson.edu
Clearing cache on node0417.palmetto.clemson.edu
Clearing cache on node0401.palmetto.clemson.edu
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
INFO:    underlay of /etc/localtime required more than 50 (96) bind mounts
INFO:    underlay of /usr/bin/nvidia-smi required more than 50 (478) bind mounts
13:4: not a valid test operator: (
13:4: not a valid test operator: 525.125.06
:::MLLOG {"namespace": "", "time_ms": 1696011839924, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 2}}
INFO:    underlay of /etc/localtime required more than 50 (96) bind mounts
INFO:    underlay of /etc/localtime required more than 50 (96) bind mounts
INFO:    underlay of /usr/bin/nvidia-smi required more than 50 (478) bind mounts
INFO:    underlay of /usr/bin/nvidia-smi required more than 50 (478) bind mounts
13:4: not a valid test operator: (
13:4: not a valid test operator: 525.125.06
13:4: not a valid test operator: (
13:4: not a valid test operator: 525.125.06
INFO:    underlay of /etc/localtime required more than 50 (96) bind mounts
INFO:    underlay of /etc/localtime required more than 50 (96) bind mounts
INFO:    underlay of /etc/localtime required more than 50 (96) bind mounts
INFO:    underlay of /etc/localtime required more than 50 (96) bind mounts
INFO:    underlay of /etc/localtime required more than 50 (96) bind mounts
INFO:    underlay of /etc/localtime required more than 50 (96) bind mounts
INFO:    underlay of /etc/localtime required more than 50 (96) bind mounts
INFO:    underlay of /etc/localtime required more than 50 (96) bind mounts
INFO:    underlay of /etc/localtime required more than 50 (96) bind mounts
INFO:    underlay of /etc/localtime required more than 50 (96) bind mounts
INFO:    underlay of /etc/localtime required more than 50 (96) bind mounts
INFO:    underlay of /etc/localtime required more than 50 (96) bind mounts
INFO:    underlay of /etc/localtime required more than 50 (96) bind mounts
INFO:    underlay of /etc/localtime required more than 50 (96) bind mounts
INFO:    underlay of /etc/localtime required more than 50 (96) bind mounts
INFO:    underlay of /etc/localtime required more than 50 (96) bind mounts
INFO:    underlay of /etc/localtime required more than 50 (96) bind mounts
INFO:    underlay of /etc/localtime required more than 50 (96) bind mounts
INFO:    underlay of /etc/localtime required more than 50 (96) bind mounts
INFO:    underlay of /etc/localtime required more than 50 (96) bind mounts
INFO:    underlay of /etc/localtime required more than 50 (96) bind mounts
INFO:    underlay of /etc/localtime required more than 50 (96) bind mounts
INFO:    underlay of /etc/localtime required more than 50 (96) bind mounts
INFO:    underlay of /etc/localtime required more than 50 (96) bind mounts
INFO:    underlay of /etc/localtime required more than 50 (96) bind mounts
INFO:    underlay of /etc/localtime required more than 50 (96) bind mounts
INFO:    underlay of /etc/localtime required more than 50 (96) bind mounts
INFO:    underlay of /etc/localtime required more than 50 (96) bind mounts
INFO:    underlay of /etc/localtime required more than 50 (96) bind mounts
INFO:    underlay of /etc/localtime required more than 50 (96) bind mounts
INFO:    underlay of /usr/bin/nvidia-smi required more than 50 (478) bind mounts
INFO:    underlay of /usr/bin/nvidia-smi required more than 50 (478) bind mounts
INFO:    underlay of /usr/bin/nvidia-smi required more than 50 (478) bind mounts
INFO:    underlay of /usr/bin/nvidia-smi required more than 50 (478) bind mounts
INFO:    underlay of /usr/bin/nvidia-smi required more than 50 (478) bind mounts
INFO:    underlay of /usr/bin/nvidia-smi required more than 50 (478) bind mounts
INFO:    underlay of /usr/bin/nvidia-smi required more than 50 (478) bind mounts
INFO:    underlay of /usr/bin/nvidia-smi required more than 50 (478) bind mounts
INFO:    underlay of /usr/bin/nvidia-smi required more than 50 (478) bind mounts
INFO:    underlay of /usr/bin/nvidia-smi required more than 50 (478) bind mounts
INFO:    underlay of /usr/bin/nvidia-smi required more than 50 (478) bind mounts
INFO:    underlay of /usr/bin/nvidia-smi required more than 50 (478) bind mounts
INFO:    underlay of /usr/bin/nvidia-smi required more than 50 (478) bind mounts
INFO:    underlay of /usr/bin/nvidia-smi required more than 50 (478) bind mounts
INFO:    underlay of /usr/bin/nvidia-smi required more than 50 (478) bind mounts
INFO:    underlay of /usr/bin/nvidia-smi required more than 50 (478) bind mounts
INFO:    underlay of /usr/bin/nvidia-smi required more than 50 (478) bind mounts
INFO:    underlay of /usr/bin/nvidia-smi required more than 50 (478) bind mounts
INFO:    underlay of /usr/bin/nvidia-smi required more than 50 (478) bind mounts
INFO:    underlay of /usr/bin/nvidia-smi required more than 50 (478) bind mounts
INFO:    underlay of /usr/bin/nvidia-smi required more than 50 (478) bind mounts
INFO:    underlay of /usr/bin/nvidia-smi required more than 50 (478) bind mounts
INFO:    underlay of /usr/bin/nvidia-smi required more than 50 (478) bind mounts
INFO:    underlay of /usr/bin/nvidia-smi required more than 50 (478) bind mounts
INFO:    underlay of /usr/bin/nvidia-smi required more than 50 (478) bind mounts
INFO:    underlay of /usr/bin/nvidia-smi required more than 50 (478) bind mounts
INFO:    underlay of /usr/bin/nvidia-smi required more than 50 (478) bind mounts
INFO:    underlay of /usr/bin/nvidia-smi required more than 50 (478) bind mounts
INFO:    underlay of /usr/bin/nvidia-smi required more than 50 (478) bind mounts
INFO:    underlay of /usr/bin/nvidia-smi required more than 50 (478) bind mounts
13:4: not a valid test operator: (
13:4: not a valid test operator: 525.125.06
13:4: not a valid test operator: (
13:4: not a valid test operator: 525.125.06
13:4: not a valid test operator: (
13:4: not a valid test operator: 525.125.06
13:4: not a valid test operator: (
13:4: not a valid test operator: 525.125.06
13:4: not a valid test operator: (
13:4: not a valid test operator: 525.125.06
13:4: not a valid test operator: (
13:4: not a valid test operator: 525.125.06
13:4: not a valid test operator: (
13:4: not a valid test operator: 525.125.06
13:4: not a valid test operator: (
13:4: not a valid test operator: 525.125.06
13:4: not a valid test operator: (
13:4: not a valid test operator: 525.125.06
13:4: not a valid test operator: (
13:4: not a valid test operator: 525.125.06
13:4: not a valid test operator: (
13:4: not a valid test operator: 525.125.06
13:4: not a valid test operator: (
13:4: not a valid test operator: 525.125.06
13:4: not a valid test operator: (
13:4: not a valid test operator: 525.125.06
13:4: not a valid test operator: (
13:4: not a valid test operator: 525.125.06
13:4: not a valid test operator: (
13:4: not a valid test operator: 525.125.06
13:4: not a valid test operator: (
13:4: not a valid test operator: 525.125.06
13:4: not a valid test operator: (
13:4: not a valid test operator: 525.125.06
13:4: not a valid test operator: (
13:4: not a valid test operator: 525.125.06
13:4: not a valid test operator: (
13:4: not a valid test operator: 525.125.06
13:4: not a valid test operator: (
13:4: not a valid test operator: 525.125.06
13:4: not a valid test operator: (
13:4: not a valid test operator: 525.125.06
13:4: not a valid test operator: (
13:4: not a valid test operator: 525.125.06
13:4: not a valid test operator: (
13:4: not a valid test operator: 525.125.06
13:4: not a valid test operator: (
13:4: not a valid test operator: 525.125.06
13:4: not a valid test operator: (
13:4: not a valid test operator: 525.125.06
13:4: not a valid test operator: (
13:4: not a valid test operator: 525.125.06
13:4: not a valid test operator: (
13:4: not a valid test operator: 525.125.06
13:4: not a valid test operator: (
13:4: not a valid test operator: 525.125.06
13:4: not a valid test operator: (
13:4: not a valid test operator: 525.125.06
13:4: not a valid test operator: (
13:4: not a valid test operator: 525.125.06
 4: INFO:    underlay of /etc/localtime required more than 50 (96) bind mounts
 5: INFO:    underlay of /etc/localtime required more than 50 (96) bind mounts
20: INFO:    underlay of /etc/localtime required more than 50 (96) bind mounts
21: INFO:    underlay of /etc/localtime required more than 50 (96) bind mounts
 0: INFO:    underlay of /etc/localtime required more than 50 (96) bind mounts
 1: INFO:    underlay of /etc/localtime required more than 50 (96) bind mounts
 6: INFO:    underlay of /etc/localtime required more than 50 (96) bind mounts
 7: INFO:    underlay of /etc/localtime required more than 50 (96) bind mounts
27: INFO:    underlay of /etc/localtime required more than 50 (96) bind mounts
26: INFO:    underlay of /etc/localtime required more than 50 (96) bind mounts
31: INFO:    underlay of /etc/localtime required more than 50 (96) bind mounts
30: INFO:    underlay of /etc/localtime required more than 50 (96) bind mounts
11: INFO:    underlay of /etc/localtime required more than 50 (96) bind mounts
10: INFO:    underlay of /etc/localtime required more than 50 (96) bind mounts
 9: INFO:    underlay of /etc/localtime required more than 50 (96) bind mounts
 8: INFO:    underlay of /etc/localtime required more than 50 (96) bind mounts
18: INFO:    underlay of /etc/localtime required more than 50 (96) bind mounts
19: INFO:    underlay of /etc/localtime required more than 50 (96) bind mounts
24: INFO:    underlay of /etc/localtime required more than 50 (96) bind mounts
28: INFO:    underlay of /etc/localtime required more than 50 (96) bind mounts
12: INFO:    underlay of /etc/localtime required more than 50 (96) bind mounts
25: INFO:    underlay of /etc/localtime required more than 50 (96) bind mounts
13: INFO:    underlay of /etc/localtime required more than 50 (96) bind mounts
29: INFO:    underlay of /etc/localtime required more than 50 (96) bind mounts
22: INFO:    underlay of /etc/localtime required more than 50 (96) bind mounts
23: INFO:    underlay of /etc/localtime required more than 50 (96) bind mounts
15: INFO:    underlay of /etc/localtime required more than 50 (96) bind mounts
14: INFO:    underlay of /etc/localtime required more than 50 (96) bind mounts
 2: INFO:    underlay of /etc/localtime required more than 50 (96) bind mounts
 3: INFO:    underlay of /etc/localtime required more than 50 (96) bind mounts
 6: INFO:    underlay of /usr/bin/nvidia-smi required more than 50 (478) bind mounts
 7: INFO:    underlay of /usr/bin/nvidia-smi required more than 50 (478) bind mounts
 5: INFO:    underlay of /usr/bin/nvidia-smi required more than 50 (478) bind mounts
 4: INFO:    underlay of /usr/bin/nvidia-smi required more than 50 (478) bind mounts
13: INFO:    underlay of /usr/bin/nvidia-smi required more than 50 (478) bind mounts
12: INFO:    underlay of /usr/bin/nvidia-smi required more than 50 (478) bind mounts
29: INFO:    underlay of /usr/bin/nvidia-smi required more than 50 (478) bind mounts
28: INFO:    underlay of /usr/bin/nvidia-smi required more than 50 (478) bind mounts
22: INFO:    underlay of /usr/bin/nvidia-smi required more than 50 (478) bind mounts
27: INFO:    underlay of /usr/bin/nvidia-smi required more than 50 (478) bind mounts
26: INFO:    underlay of /usr/bin/nvidia-smi required more than 50 (478) bind mounts
18: INFO:    underlay of /usr/bin/nvidia-smi required more than 50 (478) bind mounts
19: INFO:    underlay of /usr/bin/nvidia-smi required more than 50 (478) bind mounts
14: INFO:    underlay of /usr/bin/nvidia-smi required more than 50 (478) bind mounts
 8: INFO:    underlay of /usr/bin/nvidia-smi required more than 50 (478) bind mounts
 9: INFO:    underlay of /usr/bin/nvidia-smi required more than 50 (478) bind mounts
24: INFO:    underlay of /usr/bin/nvidia-smi required more than 50 (478) bind mounts
25: INFO:    underlay of /usr/bin/nvidia-smi required more than 50 (478) bind mounts
31: INFO:    underlay of /usr/bin/nvidia-smi required more than 50 (478) bind mounts
30: INFO:    underlay of /usr/bin/nvidia-smi required more than 50 (478) bind mounts
 2: INFO:    underlay of /usr/bin/nvidia-smi required more than 50 (478) bind mounts
21: INFO:    underlay of /usr/bin/nvidia-smi required more than 50 (478) bind mounts
20: INFO:    underlay of /usr/bin/nvidia-smi required more than 50 (478) bind mounts
 0: INFO:    underlay of /usr/bin/nvidia-smi required more than 50 (478) bind mounts
 1: INFO:    underlay of /usr/bin/nvidia-smi required more than 50 (478) bind mounts
16: INFO:    underlay of /etc/localtime required more than 50 (96) bind mounts
10: INFO:    underlay of /usr/bin/nvidia-smi required more than 50 (478) bind mounts
11: INFO:    underlay of /usr/bin/nvidia-smi required more than 50 (478) bind mounts
23: INFO:    underlay of /usr/bin/nvidia-smi required more than 50 (478) bind mounts
15: INFO:    underlay of /usr/bin/nvidia-smi required more than 50 (478) bind mounts
 3: INFO:    underlay of /usr/bin/nvidia-smi required more than 50 (478) bind mounts
17: INFO:    underlay of /etc/localtime required more than 50 (96) bind mounts
 7: 13:4: not a valid test operator: (
 7: 13:4: not a valid test operator: 525.125.06
 6: 13:4: not a valid test operator: (
 6: 13:4: not a valid test operator: 525.125.06
 4: 13:4: not a valid test operator: (
 4: 13:4: not a valid test operator: 525.125.06
 5: 13:4: not a valid test operator: (
 5: 13:4: not a valid test operator: 525.125.06
13: 13:4: not a valid test operator: (
13: 13:4: not a valid test operator: 525.125.06
14: 13:4: not a valid test operator: (
14: 13:4: not a valid test operator: 525.125.06
12: 13:4: not a valid test operator: (
12: 13:4: not a valid test operator: 525.125.06
29: 13:4: not a valid test operator: (
29: 13:4: not a valid test operator: 525.125.06
28: 13:4: not a valid test operator: (
28: 13:4: not a valid test operator: 525.125.06
23: 13:4: not a valid test operator: (
23: 13:4: not a valid test operator: 525.125.06
 9: 13:4: not a valid test operator: (
 9: 13:4: not a valid test operator: 525.125.06
 8: 13:4: not a valid test operator: (
 8: 13:4: not a valid test operator: 525.125.06
22: 13:4: not a valid test operator: (
22: 13:4: not a valid test operator: 525.125.06
15: 13:4: not a valid test operator: (
15: 13:4: not a valid test operator: 525.125.06
19: 13:4: not a valid test operator: (
19: 13:4: not a valid test operator: 525.125.06
31: 13:4: not a valid test operator: (
31: 13:4: not a valid test operator: 525.125.06
30: 13:4: not a valid test operator: (
30: 13:4: not a valid test operator: 525.125.06
 3: 13:4: not a valid test operator: (
 3: 13:4: not a valid test operator: 525.125.06
18: 13:4: not a valid test operator: (
18: 13:4: not a valid test operator: 525.125.06
 2: 13:4: not a valid test operator: (
 2: 13:4: not a valid test operator: 525.125.06
27: 13:4: not a valid test operator: (
27: 13:4: not a valid test operator: 525.125.06
26: 13:4: not a valid test operator: (
26: 13:4: not a valid test operator: 525.125.06
11: 13:4: not a valid test operator: (
11: 13:4: not a valid test operator: 525.125.06
10: 13:4: not a valid test operator: (
10: 13:4: not a valid test operator: 525.125.06
20: 13:4: not a valid test operator: (
20: 13:4: not a valid test operator: 525.125.06
21: 13:4: not a valid test operator: (
21: 13:4: not a valid test operator: 525.125.06
 0: 13:4: not a valid test operator: (
 0: 13:4: not a valid test operator: 525.125.06
 1: 13:4: not a valid test operator: (
 1: 13:4: not a valid test operator: 525.125.06
24: 13:4: not a valid test operator: (
24: 13:4: not a valid test operator: 525.125.06
25: 13:4: not a valid test operator: (
25: 13:4: not a valid test operator: 525.125.06
17: INFO:    underlay of /usr/bin/nvidia-smi required more than 50 (478) bind mounts
16: INFO:    underlay of /usr/bin/nvidia-smi required more than 50 (478) bind mounts
16: 13:4: not a valid test operator: (
16: 13:4: not a valid test operator: 525.125.06
17: 13:4: not a valid test operator: (
17: 13:4: not a valid test operator: 525.125.06
28: Run vars: id 2042 gpus 2 mparams ''
 3: Run vars: id 2042 gpus 2 mparams ''
28: STARTING TIMING RUN AT 2023-09-29 02:24:23 PM
28: WORLD_SIZE=32
28: slurm_job_nodelist=node[0400-0401,0403-0410,0413-0418]
28: MASTER_ADDR=node0400
28: HOSTNAME=node0400
28:      python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/tf2_ckpt/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples=10000     --cache_eval_data     --output_dir=/results     --fp16     --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     --bert_config_path=/workspace/phase1/bert_co
28: nfig.json  --local_rank=0  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --pad_fmha --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --packed_samples --cuda_graph_mode 'segmented'   --seed=22031
 3: STARTING TIMING RUN AT 2023-09-29 02:24:23 PM
 3: WORLD_SIZE=32
 3: slurm_job_nodelist=node[0400-0401,0403-0410,0413-0418]
 3: MASTER_ADDR=node0400
 3: HOSTNAME=node0400
 3:      python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/tf2_ckpt/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples=10000     --cache_eval_data     --output_dir=/results     --fp16     --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     --bert_config_path=/workspace/phase1/bert_co
 3: nfig.json  --local_rank=1  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --pad_fmha --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --packed_samples --cuda_graph_mode 'segmented'   --seed=5631
13: Run vars: id 2042 gpus 2 mparams ''
29: Run vars: id 2042 gpus 2 mparams ''
27: Run vars: id 2042 gpus 2 mparams ''
 7: Run vars: id 2042 gpus 2 mparams ''
14: Run vars: id 2042 gpus 2 mparams ''
 5: Run vars: id 2042 gpus 2 mparams ''
29: STARTING TIMING RUN AT 2023-09-29 02:24:23 PM
29: WORLD_SIZE=32
13: STARTING TIMING RUN AT 2023-09-29 02:24:23 PM
13: WORLD_SIZE=32
27: STARTING TIMING RUN AT 2023-09-29 02:24:23 PM
27: WORLD_SIZE=32
29: slurm_job_nodelist=node[0400-0401,0403-0410,0413-0418]
29: MASTER_ADDR=node0400
29: HOSTNAME=node0400
29:      python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/tf2_ckpt/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples=10000     --cache_eval_data     --output_dir=/results     --fp16     --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     --bert_config_path=/workspace/phase1/bert_co
29: nfig.json  --local_rank=1  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --pad_fmha --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --packed_samples --cuda_graph_mode 'segmented'   --seed=24903
14: STARTING TIMING RUN AT 2023-09-29 02:24:23 PM
14: WORLD_SIZE=32
13: slurm_job_nodelist=node[0400-0401,0403-0410,0413-0418]
13: MASTER_ADDR=node0400
13: HOSTNAME=node0400
13:      python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/tf2_ckpt/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples=10000     --cache_eval_data     --output_dir=/results     --fp16     --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     --bert_config_path=/workspace/phase1/bert_co
13: nfig.json  --local_rank=1  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --pad_fmha --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --packed_samples --cuda_graph_mode 'segmented'   --seed=25130
10: Run vars: id 2042 gpus 2 mparams ''
 2: Run vars: id 2042 gpus 2 mparams ''
27: slurm_job_nodelist=node[0400-0401,0403-0410,0413-0418]
27: MASTER_ADDR=node0400
27: HOSTNAME=node0400
27:      python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/tf2_ckpt/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples=10000     --cache_eval_data     --output_dir=/results     --fp16     --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     --bert_config_path=/workspace/phase1/bert_co
27: nfig.json  --local_rank=1  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --pad_fmha --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --packed_samples --cuda_graph_mode 'segmented'   --seed=30640
 9: Run vars: id 2042 gpus 2 mparams ''
21: Run vars: id 2042 gpus 2 mparams ''
14: slurm_job_nodelist=node[0400-0401,0403-0410,0413-0418]
14: MASTER_ADDR=node0400
14: HOSTNAME=node0400
14:      python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/tf2_ckpt/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples=10000     --cache_eval_data     --output_dir=/results     --fp16     --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     --bert_config_path=/workspace/phase1/bert_co
14: nfig.json  --local_rank=0  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --pad_fmha --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --packed_samples --cuda_graph_mode 'segmented'   --seed=26333
 1: Run vars: id 2042 gpus 2 mparams ''
 5: STARTING TIMING RUN AT 2023-09-29 02:24:23 PM
 5: WORLD_SIZE=32
 2: STARTING TIMING RUN AT 2023-09-29 02:24:23 PM
 2: WORLD_SIZE=32
31: Run vars: id 2042 gpus 2 mparams ''
10: STARTING TIMING RUN AT 2023-09-29 02:24:23 PM
10: WORLD_SIZE=32
 2: slurm_job_nodelist=node[0400-0401,0403-0410,0413-0418]
 2: MASTER_ADDR=node0400
 2: HOSTNAME=node0400
 2:      python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/tf2_ckpt/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples=10000     --cache_eval_data     --output_dir=/results     --fp16     --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     --bert_config_path=/workspace/phase1/bert_co
 2: nfig.json  --local_rank=0  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --pad_fmha --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --packed_samples --cuda_graph_mode 'segmented'   --seed=5734
21: STARTING TIMING RUN AT 2023-09-29 02:24:23 PM
21: WORLD_SIZE=32
 5: slurm_job_nodelist=node[0400-0401,0403-0410,0413-0418]
 5: MASTER_ADDR=node0400
 5: HOSTNAME=node0400
 5:      python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/tf2_ckpt/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples=10000     --cache_eval_data     --output_dir=/results     --fp16     --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     --bert_config_path=/workspace/phase1/bert_co
 5: nfig.json  --local_rank=1  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --pad_fmha --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --packed_samples --cuda_graph_mode 'segmented'   --seed=18056
 9: STARTING TIMING RUN AT 2023-09-29 02:24:23 PM
 9: WORLD_SIZE=32
 1: STARTING TIMING RUN AT 2023-09-29 02:24:23 PM
 1: WORLD_SIZE=32
10: slurm_job_nodelist=node[0400-0401,0403-0410,0413-0418]
10: MASTER_ADDR=node0400
10: HOSTNAME=node0400
10:      python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/tf2_ckpt/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples=10000     --cache_eval_data     --output_dir=/results     --fp16     --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     --bert_config_path=/workspace/phase1/bert_co
10: nfig.json  --local_rank=0  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --pad_fmha --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --packed_samples --cuda_graph_mode 'segmented'   --seed=11251
31: STARTING TIMING RUN AT 2023-09-29 02:24:23 PM
31: WORLD_SIZE=32
21: slurm_job_nodelist=node[0400-0401,0403-0410,0413-0418]
21: MASTER_ADDR=node0400
21: HOSTNAME=node0400
21:      python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/tf2_ckpt/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples=10000     --cache_eval_data     --output_dir=/results     --fp16     --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     --bert_config_path=/workspace/phase1/bert_co
21: nfig.json  --local_rank=1  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --pad_fmha --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --packed_samples --cuda_graph_mode 'segmented'   --seed=12036
24: Run vars: id 2042 gpus 2 mparams ''
26: Run vars: id 2042 gpus 2 mparams ''
 1: slurm_job_nodelist=node[0400-0401,0403-0410,0413-0418]
 1: MASTER_ADDR=node0400
 1: HOSTNAME=node0400
 1:      python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/tf2_ckpt/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples=10000     --cache_eval_data     --output_dir=/results     --fp16     --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     --bert_config_path=/workspace/phase1/bert_co
 1: nfig.json  --local_rank=1  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --pad_fmha --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --packed_samples --cuda_graph_mode 'segmented'   --seed=6729
12: Run vars: id 2042 gpus 2 mparams ''
31: slurm_job_nodelist=node[0400-0401,0403-0410,0413-0418]
31: MASTER_ADDR=node0400
31: HOSTNAME=node0400
31:      python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/tf2_ckpt/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples=10000     --cache_eval_data     --output_dir=/results     --fp16     --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     --bert_config_path=/workspace/phase1/bert_co
31: nfig.json  --local_rank=1  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --pad_fmha --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --packed_samples --cuda_graph_mode 'segmented'   --seed=16362
 9: slurm_job_nodelist=node[0400-0401,0403-0410,0413-0418]
 9: MASTER_ADDR=node0400
 9: HOSTNAME=node0400
 9:      python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/tf2_ckpt/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples=10000     --cache_eval_data     --output_dir=/results     --fp16     --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     --bert_config_path=/workspace/phase1/bert_co
 9: nfig.json  --local_rank=1  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --pad_fmha --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --packed_samples --cuda_graph_mode 'segmented'   --seed=19679
26: STARTING TIMING RUN AT 2023-09-29 02:24:23 PM
26: WORLD_SIZE=32
12: STARTING TIMING RUN AT 2023-09-29 02:24:23 PM
12: WORLD_SIZE=32
24: STARTING TIMING RUN AT 2023-09-29 02:24:23 PM
24: WORLD_SIZE=32
15: Run vars: id 2042 gpus 2 mparams ''
26: slurm_job_nodelist=node[0400-0401,0403-0410,0413-0418]
26: MASTER_ADDR=node0400
26: HOSTNAME=node0400
26:      python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/tf2_ckpt/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples=10000     --cache_eval_data     --output_dir=/results     --fp16     --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     --bert_config_path=/workspace/phase1/bert_co
26: nfig.json  --local_rank=0  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --pad_fmha --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --packed_samples --cuda_graph_mode 'segmented'   --seed=2081
 4: Run vars: id 2042 gpus 2 mparams ''
12: slurm_job_nodelist=node[0400-0401,0403-0410,0413-0418]
12: MASTER_ADDR=node0400
12: HOSTNAME=node0400
12:      python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/tf2_ckpt/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples=10000     --cache_eval_data     --output_dir=/results     --fp16     --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     --bert_config_path=/workspace/phase1/bert_co
12: nfig.json  --local_rank=0  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --pad_fmha --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --packed_samples --cuda_graph_mode 'segmented'   --seed=8783
24: slurm_job_nodelist=node[0400-0401,0403-0410,0413-0418]
24: MASTER_ADDR=node0400
24: HOSTNAME=node0400
24:      python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/tf2_ckpt/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples=10000     --cache_eval_data     --output_dir=/results     --fp16     --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     --bert_config_path=/workspace/phase1/bert_co
24: nfig.json  --local_rank=0  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --pad_fmha --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --packed_samples --cuda_graph_mode 'segmented'   --seed=20283
15: STARTING TIMING RUN AT 2023-09-29 02:24:23 PM
15: WORLD_SIZE=32
11: Run vars: id 2042 gpus 2 mparams ''
15: slurm_job_nodelist=node[0400-0401,0403-0410,0413-0418]
15: MASTER_ADDR=node0400
 4: STARTING TIMING RUN AT 2023-09-29 02:24:23 PM
15: HOSTNAME=node0400
 4: WORLD_SIZE=32
15:      python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/tf2_ckpt/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples=10000     --cache_eval_data     --output_dir=/results     --fp16     --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     --bert_config_path=/workspace/phase1/bert_co
15: nfig.json  --local_rank=1  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --pad_fmha --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --packed_samples --cuda_graph_mode 'segmented'   --seed=2840
20: Run vars: id 2042 gpus 2 mparams ''
30: Run vars: id 2042 gpus 2 mparams ''
11: STARTING TIMING RUN AT 2023-09-29 02:24:23 PM
11: WORLD_SIZE=32
 0: Run vars: id 2042 gpus 2 mparams ''
 4: slurm_job_nodelist=node[0400-0401,0403-0410,0413-0418]
 4: MASTER_ADDR=node0400
 4: HOSTNAME=node0400
 4:      python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/tf2_ckpt/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples=10000     --cache_eval_data     --output_dir=/results     --fp16     --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     --bert_config_path=/workspace/phase1/bert_co
 4: nfig.json  --local_rank=0  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --pad_fmha --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --packed_samples --cuda_graph_mode 'segmented'   --seed=28505
11: slurm_job_nodelist=node[0400-0401,0403-0410,0413-0418]
11: MASTER_ADDR=node0400
11: HOSTNAME=node0400
11:      python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/tf2_ckpt/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples=10000     --cache_eval_data     --output_dir=/results     --fp16     --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     --bert_config_path=/workspace/phase1/bert_co
11: nfig.json  --local_rank=1  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --pad_fmha --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --packed_samples --cuda_graph_mode 'segmented'   --seed=31562
20: STARTING TIMING RUN AT 2023-09-29 02:24:23 PM
20: WORLD_SIZE=32
 0: STARTING TIMING RUN AT 2023-09-29 02:24:23 PM
 0: WORLD_SIZE=32
 8: Run vars: id 2042 gpus 2 mparams ''
30: STARTING TIMING RUN AT 2023-09-29 02:24:23 PM
30: WORLD_SIZE=32
20: slurm_job_nodelist=node[0400-0401,0403-0410,0413-0418]
20: MASTER_ADDR=node0400
20: HOSTNAME=node0400
20:      python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/tf2_ckpt/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples=10000     --cache_eval_data     --output_dir=/results     --fp16     --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     --bert_config_path=/workspace/phase1/bert_co
20: nfig.json  --local_rank=0  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --pad_fmha --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --packed_samples --cuda_graph_mode 'segmented'   --seed=2248
 0: slurm_job_nodelist=node[0400-0401,0403-0410,0413-0418]
 0: MASTER_ADDR=node0400
 0: HOSTNAME=node0400
 0:      python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/tf2_ckpt/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples=10000     --cache_eval_data     --output_dir=/results     --fp16     --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     --bert_config_path=/workspace/phase1/bert_co
 0: nfig.json  --local_rank=0  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --pad_fmha --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --packed_samples --cuda_graph_mode 'segmented'   --seed=31900
30: slurm_job_nodelist=node[0400-0401,0403-0410,0413-0418]
30: MASTER_ADDR=node0400
30: HOSTNAME=node0400
30:      python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/tf2_ckpt/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples=10000     --cache_eval_data     --output_dir=/results     --fp16     --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     --bert_config_path=/workspace/phase1/bert_co
30: nfig.json  --local_rank=0  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --pad_fmha --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --packed_samples --cuda_graph_mode 'segmented'   --seed=24876
 8: STARTING TIMING RUN AT 2023-09-29 02:24:23 PM
 8: WORLD_SIZE=32
25: Run vars: id 2042 gpus 2 mparams ''
16: Run vars: id 2042 gpus 2 mparams ''
 8: slurm_job_nodelist=node[0400-0401,0403-0410,0413-0418]
 8: MASTER_ADDR=node0400
 8: HOSTNAME=node0400
 8:      python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/tf2_ckpt/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples=10000     --cache_eval_data     --output_dir=/results     --fp16     --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     --bert_config_path=/workspace/phase1/bert_co
 8: nfig.json  --local_rank=0  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --pad_fmha --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --packed_samples --cuda_graph_mode 'segmented'   --seed=24608
18: Run vars: id 2042 gpus 2 mparams ''
25: STARTING TIMING RUN AT 2023-09-29 02:24:23 PM
25: WORLD_SIZE=32
25: slurm_job_nodelist=node[0400-0401,0403-0410,0413-0418]
25: MASTER_ADDR=node0400
25: HOSTNAME=node0400
25:      python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/tf2_ckpt/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples=10000     --cache_eval_data     --output_dir=/results     --fp16     --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     --bert_config_path=/workspace/phase1/bert_co
25: nfig.json  --local_rank=1  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --pad_fmha --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --packed_samples --cuda_graph_mode 'segmented'   --seed=19862
16: STARTING TIMING RUN AT 2023-09-29 02:24:23 PM
16: WORLD_SIZE=32
 7: STARTING TIMING RUN AT 2023-09-29 02:24:23 PM
 7: WORLD_SIZE=32
16: slurm_job_nodelist=node[0400-0401,0403-0410,0413-0418]
16: MASTER_ADDR=node0400
16: HOSTNAME=node0400
16:      python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/tf2_ckpt/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples=10000     --cache_eval_data     --output_dir=/results     --fp16     --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     --bert_config_path=/workspace/phase1/bert_co
16: nfig.json  --local_rank=0  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --pad_fmha --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --packed_samples --cuda_graph_mode 'segmented'   --seed=7160
18: STARTING TIMING RUN AT 2023-09-29 02:24:23 PM
18: WORLD_SIZE=32
 7: slurm_job_nodelist=node[0400-0401,0403-0410,0413-0418]
 7: MASTER_ADDR=node0400
 7: HOSTNAME=node0400
 7:      python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/tf2_ckpt/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples=10000     --cache_eval_data     --output_dir=/results     --fp16     --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     --bert_config_path=/workspace/phase1/bert_co
 7: nfig.json  --local_rank=1  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --pad_fmha --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --packed_samples --cuda_graph_mode 'segmented'   --seed=21910
18: slurm_job_nodelist=node[0400-0401,0403-0410,0413-0418]
18: MASTER_ADDR=node0400
18: HOSTNAME=node0400
18:      python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/tf2_ckpt/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples=10000     --cache_eval_data     --output_dir=/results     --fp16     --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     --bert_config_path=/workspace/phase1/bert_co
18: nfig.json  --local_rank=0  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --pad_fmha --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --packed_samples --cuda_graph_mode 'segmented'   --seed=12398
17: Run vars: id 2042 gpus 2 mparams ''
19: Run vars: id 2042 gpus 2 mparams ''
19: STARTING TIMING RUN AT 2023-09-29 02:24:23 PM
19: WORLD_SIZE=32
17: STARTING TIMING RUN AT 2023-09-29 02:24:23 PM
17: WORLD_SIZE=32
17: slurm_job_nodelist=node[0400-0401,0403-0410,0413-0418]
17: MASTER_ADDR=node0400
17: HOSTNAME=node0400
19: slurm_job_nodelist=node[0400-0401,0403-0410,0413-0418]
19: MASTER_ADDR=node0400
19: HOSTNAME=node0400
17:      python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/tf2_ckpt/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples=10000     --cache_eval_data     --output_dir=/results     --fp16     --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     --bert_config_path=/workspace/phase1/bert_co
17: nfig.json  --local_rank=1  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --pad_fmha --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --packed_samples --cuda_graph_mode 'segmented'   --seed=19632
19:      python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/tf2_ckpt/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples=10000     --cache_eval_data     --output_dir=/results     --fp16     --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     --bert_config_path=/workspace/phase1/bert_co
19: nfig.json  --local_rank=1  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --pad_fmha --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --packed_samples --cuda_graph_mode 'segmented'   --seed=23162
 6: Run vars: id 2042 gpus 2 mparams ''
 6: STARTING TIMING RUN AT 2023-09-29 02:24:23 PM
 6: WORLD_SIZE=32
 6: slurm_job_nodelist=node[0400-0401,0403-0410,0413-0418]
 6: MASTER_ADDR=node0400
 6: HOSTNAME=node0400
 6:      python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/tf2_ckpt/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples=10000     --cache_eval_data     --output_dir=/results     --fp16     --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     --bert_config_path=/workspace/phase1/bert_co
 6: nfig.json  --local_rank=0  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --pad_fmha --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --packed_samples --cuda_graph_mode 'segmented'   --seed=14512
23: Run vars: id 2042 gpus 2 mparams ''
23: STARTING TIMING RUN AT 2023-09-29 02:24:23 PM
23: WORLD_SIZE=32
23: slurm_job_nodelist=node[0400-0401,0403-0410,0413-0418]
23: MASTER_ADDR=node0400
23: HOSTNAME=node0400
23:      python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/tf2_ckpt/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples=10000     --cache_eval_data     --output_dir=/results     --fp16     --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     --bert_config_path=/workspace/phase1/bert_co
23: nfig.json  --local_rank=1  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --pad_fmha --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --packed_samples --cuda_graph_mode 'segmented'   --seed=31193
22: Run vars: id 2042 gpus 2 mparams ''
22: STARTING TIMING RUN AT 2023-09-29 02:24:23 PM
22: WORLD_SIZE=32
22: slurm_job_nodelist=node[0400-0401,0403-0410,0413-0418]
22: MASTER_ADDR=node0400
22: HOSTNAME=node0400
22:      python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/tf2_ckpt/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples=10000     --cache_eval_data     --output_dir=/results     --fp16     --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     --bert_config_path=/workspace/phase1/bert_co
22: nfig.json  --local_rank=0  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --pad_fmha --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --packed_samples --cuda_graph_mode 'segmented'   --seed=4852
30: /usr/local/lib/python3.8/dist-packages/apex/__init__.py:68: DeprecatedFeatureWarning: apex.amp is deprecated and will be removed by the end of February 2023. Use [PyTorch AMP](https://pytorch.org/docs/stable/amp.html)
30:   warnings.warn(msg, DeprecatedFeatureWarning)
31: /usr/local/lib/python3.8/dist-packages/apex/__init__.py:68: DeprecatedFeatureWarning: apex.amp is deprecated and will be removed by the end of February 2023. Use [PyTorch AMP](https://pytorch.org/docs/stable/amp.html)
31:   warnings.warn(msg, DeprecatedFeatureWarning)
 4: /usr/local/lib/python3.8/dist-packages/apex/__init__.py:68: DeprecatedFeatureWarning: apex.amp is deprecated and will be removed by the end of February 2023. Use [PyTorch AMP](https://pytorch.org/docs/stable/amp.html)
 4:   warnings.warn(msg, DeprecatedFeatureWarning)
 5: /usr/local/lib/python3.8/dist-packages/apex/__init__.py:68: DeprecatedFeatureWarning: apex.amp is deprecated and will be removed by the end of February 2023. Use [PyTorch AMP](https://pytorch.org/docs/stable/amp.html)
 5:   warnings.warn(msg, DeprecatedFeatureWarning)
24: /usr/local/lib/python3.8/dist-packages/apex/__init__.py:68: DeprecatedFeatureWarning: apex.amp is deprecated and will be removed by the end of February 2023. Use [PyTorch AMP](https://pytorch.org/docs/stable/amp.html)
24:   warnings.warn(msg, DeprecatedFeatureWarning)
25: /usr/local/lib/python3.8/dist-packages/apex/__init__.py:68: DeprecatedFeatureWarning: apex.amp is deprecated and will be removed by the end of February 2023. Use [PyTorch AMP](https://pytorch.org/docs/stable/amp.html)
25:   warnings.warn(msg, DeprecatedFeatureWarning)
12: /usr/local/lib/python3.8/dist-packages/apex/__init__.py:68: DeprecatedFeatureWarning: apex.amp is deprecated and will be removed by the end of February 2023. Use [PyTorch AMP](https://pytorch.org/docs/stable/amp.html)
12:   warnings.warn(msg, DeprecatedFeatureWarning)
13: /usr/local/lib/python3.8/dist-packages/apex/__init__.py:68: DeprecatedFeatureWarning: apex.amp is deprecated and will be removed by the end of February 2023. Use [PyTorch AMP](https://pytorch.org/docs/stable/amp.html)
13:   warnings.warn(msg, DeprecatedFeatureWarning)
29: /usr/local/lib/python3.8/dist-packages/apex/__init__.py:68: DeprecatedFeatureWarning: apex.amp is deprecated and will be removed by the end of February 2023. Use [PyTorch AMP](https://pytorch.org/docs/stable/amp.html)
29:   warnings.warn(msg, DeprecatedFeatureWarning)
28: /usr/local/lib/python3.8/dist-packages/apex/__init__.py:68: DeprecatedFeatureWarning: apex.amp is deprecated and will be removed by the end of February 2023. Use [PyTorch AMP](https://pytorch.org/docs/stable/amp.html)
28:   warnings.warn(msg, DeprecatedFeatureWarning)
 2: /usr/local/lib/python3.8/dist-packages/apex/__init__.py:68: DeprecatedFeatureWarning: apex.amp is deprecated and will be removed by the end of February 2023. Use [PyTorch AMP](https://pytorch.org/docs/stable/amp.html)
 2:   warnings.warn(msg, DeprecatedFeatureWarning)
 3: /usr/local/lib/python3.8/dist-packages/apex/__init__.py:68: DeprecatedFeatureWarning: apex.amp is deprecated and will be removed by the end of February 2023. Use [PyTorch AMP](https://pytorch.org/docs/stable/amp.html)
 3:   warnings.warn(msg, DeprecatedFeatureWarning)
14: /usr/local/lib/python3.8/dist-packages/apex/__init__.py:68: DeprecatedFeatureWarning: apex.amp is deprecated and will be removed by the end of February 2023. Use [PyTorch AMP](https://pytorch.org/docs/stable/amp.html)
14:   warnings.warn(msg, DeprecatedFeatureWarning)
15: /usr/local/lib/python3.8/dist-packages/apex/__init__.py:68: DeprecatedFeatureWarning: apex.amp is deprecated and will be removed by the end of February 2023. Use [PyTorch AMP](https://pytorch.org/docs/stable/amp.html)
15:   warnings.warn(msg, DeprecatedFeatureWarning)
10: /usr/local/lib/python3.8/dist-packages/apex/__init__.py:68: DeprecatedFeatureWarning: apex.amp is deprecated and will be removed by the end of February 2023. Use [PyTorch AMP](https://pytorch.org/docs/stable/amp.html)
10:   warnings.warn(msg, DeprecatedFeatureWarning)
11: /usr/local/lib/python3.8/dist-packages/apex/__init__.py:68: DeprecatedFeatureWarning: apex.amp is deprecated and will be removed by the end of February 2023. Use [PyTorch AMP](https://pytorch.org/docs/stable/amp.html)
11:   warnings.warn(msg, DeprecatedFeatureWarning)
18: /usr/local/lib/python3.8/dist-packages/apex/__init__.py:68: DeprecatedFeatureWarning: apex.amp is deprecated and will be removed by the end of February 2023. Use [PyTorch AMP](https://pytorch.org/docs/stable/amp.html)
18:   warnings.warn(msg, DeprecatedFeatureWarning)
19: /usr/local/lib/python3.8/dist-packages/apex/__init__.py:68: DeprecatedFeatureWarning: apex.amp is deprecated and will be removed by the end of February 2023. Use [PyTorch AMP](https://pytorch.org/docs/stable/amp.html)
19:   warnings.warn(msg, DeprecatedFeatureWarning)
22: /usr/local/lib/python3.8/dist-packages/apex/__init__.py:68: DeprecatedFeatureWarning: apex.amp is deprecated and will be removed by the end of February 2023. Use [PyTorch AMP](https://pytorch.org/docs/stable/amp.html)
22:   warnings.warn(msg, DeprecatedFeatureWarning)
23: /usr/local/lib/python3.8/dist-packages/apex/__init__.py:68: DeprecatedFeatureWarning: apex.amp is deprecated and will be removed by the end of February 2023. Use [PyTorch AMP](https://pytorch.org/docs/stable/amp.html)
23:   warnings.warn(msg, DeprecatedFeatureWarning)
 6: /usr/local/lib/python3.8/dist-packages/apex/__init__.py:68: DeprecatedFeatureWarning: apex.amp is deprecated and will be removed by the end of February 2023. Use [PyTorch AMP](https://pytorch.org/docs/stable/amp.html)
 6:   warnings.warn(msg, DeprecatedFeatureWarning)
 0: /usr/local/lib/python3.8/dist-packages/apex/__init__.py:68: DeprecatedFeatureWarning: apex.amp is deprecated and will be removed by the end of February 2023. Use [PyTorch AMP](https://pytorch.org/docs/stable/amp.html)
 0:   warnings.warn(msg, DeprecatedFeatureWarning)
 1: /usr/local/lib/python3.8/dist-packages/apex/__init__.py:68: DeprecatedFeatureWarning: apex.amp is deprecated and will be removed by the end of February 2023. Use [PyTorch AMP](https://pytorch.org/docs/stable/amp.html)
 1:   warnings.warn(msg, DeprecatedFeatureWarning)
20: /usr/local/lib/python3.8/dist-packages/apex/__init__.py:68: DeprecatedFeatureWarning: apex.amp is deprecated and will be removed by the end of February 2023. Use [PyTorch AMP](https://pytorch.org/docs/stable/amp.html)
20:   warnings.warn(msg, DeprecatedFeatureWarning)
21: /usr/local/lib/python3.8/dist-packages/apex/__init__.py:68: DeprecatedFeatureWarning: apex.amp is deprecated and will be removed by the end of February 2023. Use [PyTorch AMP](https://pytorch.org/docs/stable/amp.html)
21:   warnings.warn(msg, DeprecatedFeatureWarning)
26: /usr/local/lib/python3.8/dist-packages/apex/__init__.py:68: DeprecatedFeatureWarning: apex.amp is deprecated and will be removed by the end of February 2023. Use [PyTorch AMP](https://pytorch.org/docs/stable/amp.html)
26:   warnings.warn(msg, DeprecatedFeatureWarning)
27: /usr/local/lib/python3.8/dist-packages/apex/__init__.py:68: DeprecatedFeatureWarning: apex.amp is deprecated and will be removed by the end of February 2023. Use [PyTorch AMP](https://pytorch.org/docs/stable/amp.html)
27:   warnings.warn(msg, DeprecatedFeatureWarning)
16: /usr/local/lib/python3.8/dist-packages/apex/__init__.py:68: DeprecatedFeatureWarning: apex.amp is deprecated and will be removed by the end of February 2023. Use [PyTorch AMP](https://pytorch.org/docs/stable/amp.html)
16:   warnings.warn(msg, DeprecatedFeatureWarning)
17: /usr/local/lib/python3.8/dist-packages/apex/__init__.py:68: DeprecatedFeatureWarning: apex.amp is deprecated and will be removed by the end of February 2023. Use [PyTorch AMP](https://pytorch.org/docs/stable/amp.html)
17:   warnings.warn(msg, DeprecatedFeatureWarning)
 7: /usr/local/lib/python3.8/dist-packages/apex/__init__.py:68: DeprecatedFeatureWarning: apex.amp is deprecated and will be removed by the end of February 2023. Use [PyTorch AMP](https://pytorch.org/docs/stable/amp.html)
 7:   warnings.warn(msg, DeprecatedFeatureWarning)
 8: /usr/local/lib/python3.8/dist-packages/apex/__init__.py:68: DeprecatedFeatureWarning: apex.amp is deprecated and will be removed by the end of February 2023. Use [PyTorch AMP](https://pytorch.org/docs/stable/amp.html)
 8:   warnings.warn(msg, DeprecatedFeatureWarning)
 9: /usr/local/lib/python3.8/dist-packages/apex/__init__.py:68: DeprecatedFeatureWarning: apex.amp is deprecated and will be removed by the end of February 2023. Use [PyTorch AMP](https://pytorch.org/docs/stable/amp.html)
 9:   warnings.warn(msg, DeprecatedFeatureWarning)
25: :::MLLOG {"namespace": "", "time_ms": 1696011878561, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1263}}
24: :::MLLOG {"namespace": "", "time_ms": 1696011878561, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1263}}
 4: :::MLLOG {"namespace": "", "time_ms": 1696011878591, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1263}}
 5: :::MLLOG {"namespace": "", "time_ms": 1696011878586, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1263}}
22: :::MLLOG {"namespace": "", "time_ms": 1696011878567, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1263}}
23: :::MLLOG {"namespace": "", "time_ms": 1696011878568, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1263}}
30: :::MLLOG {"namespace": "", "time_ms": 1696011878554, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1263}}
31: :::MLLOG {"namespace": "", "time_ms": 1696011878554, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1263}}
13: :::MLLOG {"namespace": "", "time_ms": 1696011878569, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1263}}
12: :::MLLOG {"namespace": "", "time_ms": 1696011878569, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1263}}
14: :::MLLOG {"namespace": "", "time_ms": 1696011878633, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1263}}
15: :::MLLOG {"namespace": "", "time_ms": 1696011878633, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1263}}
 8: :::MLLOG {"namespace": "", "time_ms": 1696011878593, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1263}}
 9: :::MLLOG {"namespace": "", "time_ms": 1696011878593, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1263}}
 3: :::MLLOG {"namespace": "", "time_ms": 1696011878621, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1263}}
 2: :::MLLOG {"namespace": "", "time_ms": 1696011878621, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1263}}
18: :::MLLOG {"namespace": "", "time_ms": 1696011878645, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1263}}
19: :::MLLOG {"namespace": "", "time_ms": 1696011878645, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1263}}
29: :::MLLOG {"namespace": "", "time_ms": 1696011878671, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1263}}
28: :::MLLOG {"namespace": "", "time_ms": 1696011878670, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1263}}
20: :::MLLOG {"namespace": "", "time_ms": 1696011878685, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1263}}
21: :::MLLOG {"namespace": "", "time_ms": 1696011878685, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1263}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011878675, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1263}}
 1: :::MLLOG {"namespace": "", "time_ms": 1696011878675, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1263}}
 6: :::MLLOG {"namespace": "", "time_ms": 1696011878700, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1263}}
 7: :::MLLOG {"namespace": "", "time_ms": 1696011878700, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1263}}
10: :::MLLOG {"namespace": "", "time_ms": 1696011878635, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1263}}
11: :::MLLOG {"namespace": "", "time_ms": 1696011878635, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1263}}
17: :::MLLOG {"namespace": "", "time_ms": 1696011878725, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1263}}
16: :::MLLOG {"namespace": "", "time_ms": 1696011878725, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1263}}
26: :::MLLOG {"namespace": "", "time_ms": 1696011878736, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1263}}
27: :::MLLOG {"namespace": "", "time_ms": 1696011878736, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1263}}
 0: device: cuda:0 n_gpu: 32, distributed training: True, 16-bits training: True
 0: :::MLLOG {"namespace": "", "time_ms": 1696011880833, "event_type": "POINT_IN_TIME", "key": "submission_benchmark", "value": "bert", "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1270}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011880834, "event_type": "POINT_IN_TIME", "key": "submission_org", "value": "Clemson Research Computing and Data", "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1270}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011880834, "event_type": "POINT_IN_TIME", "key": "submission_division", "value": "closed", "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1270}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011880834, "event_type": "POINT_IN_TIME", "key": "submission_status", "value": "onprem", "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1270}}
22: device: cuda:0 n_gpu: 32, distributed training: True, 16-bits training: True
29: device: cuda:1 n_gpu: 32, distributed training: True, 16-bits training: True
 0: :::MLLOG {"namespace": "", "time_ms": 1696011880834, "event_type": "POINT_IN_TIME", "key": "submission_platform", "value": "16xpacked_config_16xR750xax2A100-80GB-PCIe", "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1270}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011880834, "event_type": "POINT_IN_TIME", "key": "seed", "value": 31900, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1272}}
28: device: cuda:0 n_gpu: 32, distributed training: True, 16-bits training: True
 0: :::MLLOG {"namespace": "", "time_ms": 1696011880834, "event_type": "POINT_IN_TIME", "key": "global_batch_size", "value": 3072, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1274}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011880834, "event_type": "POINT_IN_TIME", "key": "d_batch_size", "value": 48, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1276}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011880834, "event_type": "POINT_IN_TIME", "key": "gradient_accumulation_steps", "value": 1, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1278}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011880834, "event_type": "POINT_IN_TIME", "key": "max_predictions_per_seq", "value": 76, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1280}}
23: device: cuda:1 n_gpu: 32, distributed training: True, 16-bits training: True
 0: :::MLLOG {"namespace": "", "time_ms": 1696011880834, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_training_steps", "value": 2254.0, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1282}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011880835, "event_type": "POINT_IN_TIME", "key": "num_warmup_steps", "value": 0, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1284}}
26: device: cuda:0 n_gpu: 32, distributed training: True, 16-bits training: True
 0: parsed args:
27: device: cuda:1 n_gpu: 32, distributed training: True, 16-bits training: True
 0: Namespace(allreduce_post_accumulation=True, allreduce_post_accumulation_fp16=True, average_packing_rate=2, bert_config_path='/workspace/phase1/bert_config.json', bert_model='bert-large-uncased', bypass_amp=False, cache_eval_data=True, checkpoint_activations=False, cuda_graph_mode='segmented', ddp_type='apex', dense_seq_output=True, device=device(type='cuda', index=0), disable_apex_softmax=False, disable_fuse_mask=False, disable_fuse_qkv=False, disable_fuse_scale=False, distributed_lamb=True, do_train=True, dwu_e5m2_allgather=False, dwu_group_size=0, dwu_num_ag_pg=1, dwu_num_ar_pg=1, dwu_num_blocks=1, dwu_num_chunks=1, dwu_num_rs_pg=1, dwu_overlap_reductions=False, enable_fuse_dropout=False, enable_stream=False, eval_batch_size=16, eval_dir='/workspace/evaldata', eval_iter_samples=175000, eval_iter_start_samples=175000, exchange_padding=False, fp16=True, fused_bias_fc=True, fused_bias_fc_loss_head=False, fused_bias_mha=True, fused_dropout_add=True, fused_gelu_bias=False, fused_gemm_gelu=True, fused_mha=False, 
 0: gradient_accumulation_steps=1, init_checkpoint='/workspace/phase1/tf2_ckpt/model.ckpt-28252.pt', init_tf_checkpoint=None, input_dir='/workspace/data_phase2', keep_n_most_recent_checkpoints=20, learning_rate=0.002, local_rank=0, log_freq=0.0, loss_scale=0.0, max_iterations_per_graph=4, max_pack_factor=3, max_predictions_per_seq=76, max_samples_termination=4500000.0, max_seq_length=512, max_steps=2254.0, min_samples_to_start_checkpoints=3000000, n_gpu=32, num_epochs_to_generate_seeds_for=2, num_eval_examples=10000, num_samples_per_checkpoint=500000, opt_lamb_beta_1=0.66, opt_lamb_beta_2=0.996, order_samples=False, output_dir='/results', packed_samples=True, pad=False, pad_fmha=True, phase2=True, resume_from_checkpoint=False, seed=31900, skip_checkpoint=True, start_warmup_step=0.0, synthetic_input=False, target_mlm_accuracy=0.72, train_batch_size=48, train_mlm_accuracy_window_size=0, unpad=False, unpad_fmha=False, use_cuda_graph=False, use_ddp=False, use_env=False, use_gradient_as_bucket_view=False, use_transfor
 0: mer_engine2=False, warmup_proportion=0.0, warmup_steps=0.0, weight_decay_rate=0.01)
 4: device: cuda:0 n_gpu: 32, distributed training: True, 16-bits training: True
12: device: cuda:0 n_gpu: 32, distributed training: True, 16-bits training: True
 5: device: cuda:1 n_gpu: 32, distributed training: True, 16-bits training: True
13: device: cuda:1 n_gpu: 32, distributed training: True, 16-bits training: True
14: device: cuda:0 n_gpu: 32, distributed training: True, 16-bits training: True
 2: device: cuda:0 n_gpu: 32, distributed training: True, 16-bits training: True
 3: device: cuda:1 n_gpu: 32, distributed training: True, 16-bits training: True
15: device: cuda:1 n_gpu: 32, distributed training: True, 16-bits training: True
 7: device: cuda:1 n_gpu: 32, distributed training: True, 16-bits training: True
16: device: cuda:0 n_gpu: 32, distributed training: True, 16-bits training: True
 6: device: cuda:0 n_gpu: 32, distributed training: True, 16-bits training: True
17: device: cuda:1 n_gpu: 32, distributed training: True, 16-bits training: True
 1: device: cuda:1 n_gpu: 32, distributed training: True, 16-bits training: True
10: device: cuda:0 n_gpu: 32, distributed training: True, 16-bits training: True
20: device: cuda:0 n_gpu: 32, distributed training: True, 16-bits training: True
21: device: cuda:1 n_gpu: 32, distributed training: True, 16-bits training: True
18: device: cuda:0 n_gpu: 32, distributed training: True, 16-bits training: True
19: device: cuda:1 n_gpu: 32, distributed training: True, 16-bits training: True
11: device: cuda:1 n_gpu: 32, distributed training: True, 16-bits training: True
30: device: cuda:0 n_gpu: 32, distributed training: True, 16-bits training: True
31: device: cuda:1 n_gpu: 32, distributed training: True, 16-bits training: True
24: device: cuda:0 n_gpu: 32, distributed training: True, 16-bits training: True
 8: device: cuda:0 n_gpu: 32, distributed training: True, 16-bits training: True
 9: device: cuda:1 n_gpu: 32, distributed training: True, 16-bits training: True
25: device: cuda:1 n_gpu: 32, distributed training: True, 16-bits training: True
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885240, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/embeddings/word_embeddings"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885241, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/embeddings/position_embeddings"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885241, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/embeddings/token_type_embeddings"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885241, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/embeddings/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885241, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/embeddings/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885241, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_0/attention/self/query/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885241, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_0/attention/self/query/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885241, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_0/attention/self/key/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885241, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_0/attention/self/key/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885241, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_0/attention/self/value/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885241, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_0/attention/self/value/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885241, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_0/attention/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885241, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_0/attention/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885241, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_0/attention/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885241, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_0/attention/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885241, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_0/intermediate/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885242, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_0/intermediate/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885242, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_0/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885242, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_0/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885242, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_0/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885242, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_0/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885242, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_1/attention/self/query/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885242, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_1/attention/self/query/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885242, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_1/attention/self/key/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885242, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_1/attention/self/key/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885242, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_1/attention/self/value/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885242, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_1/attention/self/value/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885242, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_1/attention/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885242, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_1/attention/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885242, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_1/attention/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885242, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_1/attention/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885242, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_1/intermediate/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885242, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_1/intermediate/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885242, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_1/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885242, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_1/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885243, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_1/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885243, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_1/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885243, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_2/attention/self/query/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885243, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_2/attention/self/query/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885243, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_2/attention/self/key/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885243, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_2/attention/self/key/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885243, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_2/attention/self/value/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885243, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_2/attention/self/value/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885243, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_2/attention/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885243, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_2/attention/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885243, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_2/attention/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885243, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_2/attention/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885243, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_2/intermediate/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885243, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_2/intermediate/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885243, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_2/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885243, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_2/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885243, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_2/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885243, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_2/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885244, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_3/attention/self/query/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885244, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_3/attention/self/query/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885244, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_3/attention/self/key/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885244, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_3/attention/self/key/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885244, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_3/attention/self/value/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885244, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_3/attention/self/value/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885244, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_3/attention/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885244, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_3/attention/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885244, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_3/attention/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885244, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_3/attention/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885244, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_3/intermediate/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885244, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_3/intermediate/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885244, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_3/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885244, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_3/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885244, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_3/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885244, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_3/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885244, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_4/attention/self/query/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885244, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_4/attention/self/query/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885244, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_4/attention/self/key/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885245, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_4/attention/self/key/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885245, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_4/attention/self/value/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885245, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_4/attention/self/value/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885245, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_4/attention/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885245, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_4/attention/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885245, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_4/attention/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885245, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_4/attention/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885245, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_4/intermediate/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885245, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_4/intermediate/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885245, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_4/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885245, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_4/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885245, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_4/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885245, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_4/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885245, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_5/attention/self/query/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885245, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_5/attention/self/query/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885245, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_5/attention/self/key/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885245, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_5/attention/self/key/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885245, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_5/attention/self/value/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885246, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_5/attention/self/value/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885246, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_5/attention/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885246, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_5/attention/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885246, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_5/attention/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885246, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_5/attention/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885246, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_5/intermediate/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885246, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_5/intermediate/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885246, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_5/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885246, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_5/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885246, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_5/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885246, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_5/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885246, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_6/attention/self/query/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885246, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_6/attention/self/query/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885246, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_6/attention/self/key/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885246, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_6/attention/self/key/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885246, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_6/attention/self/value/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885246, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_6/attention/self/value/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885246, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_6/attention/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885246, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_6/attention/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885247, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_6/attention/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885247, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_6/attention/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885247, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_6/intermediate/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885247, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_6/intermediate/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885247, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_6/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885247, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_6/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885247, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_6/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885247, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_6/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885247, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_7/attention/self/query/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885247, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_7/attention/self/query/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885247, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_7/attention/self/key/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885247, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_7/attention/self/key/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885247, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_7/attention/self/value/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885247, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_7/attention/self/value/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885247, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_7/attention/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885247, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_7/attention/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885247, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_7/attention/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885247, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_7/attention/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885248, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_7/intermediate/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885248, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_7/intermediate/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885248, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_7/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885248, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_7/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885248, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_7/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885248, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_7/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885248, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_8/attention/self/query/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885248, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_8/attention/self/query/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885248, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_8/attention/self/key/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885248, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_8/attention/self/key/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885248, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_8/attention/self/value/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885248, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_8/attention/self/value/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885248, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_8/attention/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885248, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_8/attention/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885248, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_8/attention/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885248, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_8/attention/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885248, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_8/intermediate/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885248, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_8/intermediate/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885248, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_8/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885249, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_8/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885249, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_8/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885249, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_8/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885249, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_9/attention/self/query/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885249, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_9/attention/self/query/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885249, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_9/attention/self/key/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885249, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_9/attention/self/key/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885249, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_9/attention/self/value/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885249, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_9/attention/self/value/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885249, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_9/attention/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885249, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_9/attention/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885249, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_9/attention/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885249, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_9/attention/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885249, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_9/intermediate/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885249, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_9/intermediate/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885249, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_9/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885249, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_9/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885249, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_9/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885250, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_9/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885250, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_10/attention/self/query/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885250, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_10/attention/self/query/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885250, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_10/attention/self/key/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885250, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_10/attention/self/key/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885250, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_10/attention/self/value/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885250, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_10/attention/self/value/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885250, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_10/attention/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885250, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_10/attention/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885250, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_10/attention/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885250, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_10/attention/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885250, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_10/intermediate/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885250, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_10/intermediate/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885250, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_10/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885250, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_10/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885250, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_10/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885250, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_10/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885250, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_11/attention/self/query/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885251, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_11/attention/self/query/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885251, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_11/attention/self/key/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885251, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_11/attention/self/key/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885251, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_11/attention/self/value/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885251, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_11/attention/self/value/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885251, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_11/attention/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885251, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_11/attention/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885251, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_11/attention/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885251, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_11/attention/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885251, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_11/intermediate/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885251, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_11/intermediate/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885251, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_11/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885251, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_11/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885251, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_11/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885251, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_11/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885251, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_12/attention/self/query/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885251, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_12/attention/self/query/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885251, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_12/attention/self/key/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885251, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_12/attention/self/key/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885252, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_12/attention/self/value/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885252, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_12/attention/self/value/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885252, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_12/attention/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885252, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_12/attention/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885252, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_12/attention/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885252, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_12/attention/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885252, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_12/intermediate/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885252, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_12/intermediate/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885252, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_12/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885252, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_12/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885252, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_12/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885252, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_12/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885252, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_13/attention/self/query/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885252, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_13/attention/self/query/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885252, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_13/attention/self/key/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885252, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_13/attention/self/key/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885252, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_13/attention/self/value/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885252, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_13/attention/self/value/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885253, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_13/attention/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885253, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_13/attention/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885253, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_13/attention/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885253, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_13/attention/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885253, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_13/intermediate/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885253, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_13/intermediate/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885253, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_13/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885253, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_13/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885253, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_13/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885253, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_13/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885253, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_14/attention/self/query/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885253, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_14/attention/self/query/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885253, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_14/attention/self/key/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885253, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_14/attention/self/key/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885253, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_14/attention/self/value/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885253, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_14/attention/self/value/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885253, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_14/attention/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885253, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_14/attention/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885254, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_14/attention/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885254, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_14/attention/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885254, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_14/intermediate/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885254, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_14/intermediate/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885254, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_14/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885254, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_14/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885254, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_14/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885254, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_14/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885254, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_15/attention/self/query/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885254, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_15/attention/self/query/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885254, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_15/attention/self/key/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885254, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_15/attention/self/key/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885254, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_15/attention/self/value/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885254, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_15/attention/self/value/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885254, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_15/attention/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885254, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_15/attention/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885254, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_15/attention/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885254, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_15/attention/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885255, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_15/intermediate/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885255, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_15/intermediate/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885255, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_15/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885255, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_15/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885255, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_15/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885255, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_15/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885255, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_16/attention/self/query/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885255, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_16/attention/self/query/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885255, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_16/attention/self/key/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885255, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_16/attention/self/key/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885255, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_16/attention/self/value/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885255, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_16/attention/self/value/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885255, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_16/attention/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885255, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_16/attention/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885255, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_16/attention/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885255, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_16/attention/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885255, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_16/intermediate/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885255, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_16/intermediate/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885256, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_16/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885256, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_16/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885256, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_16/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885256, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_16/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885256, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_17/attention/self/query/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885256, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_17/attention/self/query/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885256, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_17/attention/self/key/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885256, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_17/attention/self/key/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885256, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_17/attention/self/value/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885256, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_17/attention/self/value/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885256, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_17/attention/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885256, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_17/attention/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885256, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_17/attention/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885256, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_17/attention/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885256, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_17/intermediate/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885256, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_17/intermediate/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885256, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_17/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885256, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_17/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885257, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_17/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885257, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_17/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885257, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_18/attention/self/query/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885257, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_18/attention/self/query/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885257, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_18/attention/self/key/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885257, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_18/attention/self/key/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885257, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_18/attention/self/value/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885257, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_18/attention/self/value/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885257, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_18/attention/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885257, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_18/attention/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885257, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_18/attention/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885257, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_18/attention/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885257, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_18/intermediate/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885257, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_18/intermediate/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885257, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_18/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885257, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_18/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885257, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_18/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885257, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_18/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885258, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_19/attention/self/query/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885258, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_19/attention/self/query/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885258, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_19/attention/self/key/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885258, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_19/attention/self/key/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885258, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_19/attention/self/value/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885258, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_19/attention/self/value/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885258, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_19/attention/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885258, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_19/attention/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885258, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_19/attention/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885258, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_19/attention/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885258, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_19/intermediate/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885258, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_19/intermediate/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885258, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_19/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885258, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_19/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885258, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_19/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885258, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_19/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885258, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_20/attention/self/query/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885258, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_20/attention/self/query/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885259, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_20/attention/self/key/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885259, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_20/attention/self/key/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885259, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_20/attention/self/value/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885259, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_20/attention/self/value/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885259, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_20/attention/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885259, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_20/attention/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885259, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_20/attention/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885259, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_20/attention/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885259, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_20/intermediate/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885259, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_20/intermediate/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885259, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_20/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885259, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_20/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885259, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_20/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885259, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_20/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885259, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_21/attention/self/query/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885259, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_21/attention/self/query/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885259, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_21/attention/self/key/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885259, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_21/attention/self/key/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885260, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_21/attention/self/value/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885260, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_21/attention/self/value/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885260, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_21/attention/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885260, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_21/attention/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885260, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_21/attention/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885260, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_21/attention/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885260, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_21/intermediate/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885260, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_21/intermediate/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885260, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_21/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885260, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_21/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885260, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_21/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885260, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_21/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885260, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_22/attention/self/query/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885260, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_22/attention/self/query/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885260, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_22/attention/self/key/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885260, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_22/attention/self/key/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885260, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_22/attention/self/value/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885260, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_22/attention/self/value/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885261, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_22/attention/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885261, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_22/attention/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885261, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_22/attention/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885261, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_22/attention/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885261, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_22/intermediate/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885261, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_22/intermediate/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885261, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_22/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885261, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_22/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885261, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_22/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885261, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_22/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885261, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_23/attention/self/query/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885261, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_23/attention/self/query/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885261, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_23/attention/self/key/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885261, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_23/attention/self/key/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885261, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_23/attention/self/value/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885261, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_23/attention/self/value/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885261, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_23/attention/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885261, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_23/attention/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885261, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_23/attention/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885262, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_23/attention/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885262, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_23/intermediate/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885262, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_23/intermediate/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885262, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_23/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885262, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_23/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885262, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_23/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885262, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/encoder/layer_23/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885262, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/pooler/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885262, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "bert/pooler/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885262, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "cls/predictions/output_bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885262, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "cls/predictions/transform/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885262, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "cls/predictions/transform/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885262, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "cls/predictions/transform/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885262, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "cls/predictions/transform/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885262, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "cls/seq_relationship/output_weights"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885262, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 868, "tensor": "cls/seq_relationship/output_bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011885506, "event_type": "POINT_IN_TIME", "key": "opt_base_learning_rate", "value": 0.002, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 898}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011890170, "event_type": "POINT_IN_TIME", "key": "opt_lamb_epsilon", "value": 1e-06, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 937}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011890170, "event_type": "POINT_IN_TIME", "key": "opt_epsilon", "value": 1e-06, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 938}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011890170, "event_type": "POINT_IN_TIME", "key": "opt_lamb_beta_1", "value": 0.66, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 940}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011890170, "event_type": "POINT_IN_TIME", "key": "opt_lamb_beta_2", "value": 0.996, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 941}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011890170, "event_type": "POINT_IN_TIME", "key": "opt_lamb_weight_decay_rate", "value": 0.01, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 942}}
 1: /workspace/bert/run_pretraining.py:1000: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
 1:   param_storage = optimizer._new_params.storage()
 0: :::MLLOG {"namespace": "", "time_ms": 1696011890454, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_warmup_steps", "value": 0, "metadata": {"file": "/workspace/bert/schedulers.py", "lineno": 86}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011890469, "event_type": "POINT_IN_TIME", "key": "opt_lamb_learning_rate_decay_poly_power", "value": 1.0, "metadata": {"file": "/workspace/bert/schedulers.py", "lineno": 87}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011890469, "event_type": "POINT_IN_TIME", "key": "start_warmup_step", "value": 0, "metadata": {"file": "/workspace/bert/schedulers.py", "lineno": 88}}
 2: /workspace/bert/run_pretraining.py:1000: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
 2:   param_storage = optimizer._new_params.storage()
 3: /workspace/bert/run_pretraining.py:1000: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
 3:   param_storage = optimizer._new_params.storage()
 0: /workspace/bert/run_pretraining.py:1000: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
 0:   param_storage = optimizer._new_params.storage()
16: /workspace/bert/run_pretraining.py:1000: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
16:   param_storage = optimizer._new_params.storage()
12: /workspace/bert/run_pretraining.py:1000: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
12:   param_storage = optimizer._new_params.storage()
 8: /workspace/bert/run_pretraining.py:1000: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
 8:   param_storage = optimizer._new_params.storage()
13: /workspace/bert/run_pretraining.py:1000: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
13:   param_storage = optimizer._new_params.storage()
23: /workspace/bert/run_pretraining.py:1000: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
23:   param_storage = optimizer._new_params.storage()
17: /workspace/bert/run_pretraining.py:1000: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
17:   param_storage = optimizer._new_params.storage()
11: /workspace/bert/run_pretraining.py:1000: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
11:   param_storage = optimizer._new_params.storage()
10: /workspace/bert/run_pretraining.py:1000: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
10:   param_storage = optimizer._new_params.storage()
 4: /workspace/bert/run_pretraining.py:1000: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
 4:   param_storage = optimizer._new_params.storage()
22: /workspace/bert/run_pretraining.py:1000: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
22:   param_storage = optimizer._new_params.storage()
31: /workspace/bert/run_pretraining.py:1000: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
31:   param_storage = optimizer._new_params.storage()
20: /workspace/bert/run_pretraining.py:1000: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
20:   param_storage = optimizer._new_params.storage()
30: /workspace/bert/run_pretraining.py:1000: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
30:   param_storage = optimizer._new_params.storage()
28: /workspace/bert/run_pretraining.py:1000: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
28:   param_storage = optimizer._new_params.storage()
29: /workspace/bert/run_pretraining.py:1000: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
29:   param_storage = optimizer._new_params.storage()
 5: /workspace/bert/run_pretraining.py:1000: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
 5:   param_storage = optimizer._new_params.storage()
 9: /workspace/bert/run_pretraining.py:1000: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
 9:   param_storage = optimizer._new_params.storage()
21: /workspace/bert/run_pretraining.py:1000: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
21:   param_storage = optimizer._new_params.storage()
24: /workspace/bert/run_pretraining.py:1000: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
24:   param_storage = optimizer._new_params.storage()
25: /workspace/bert/run_pretraining.py:1000: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
25:   param_storage = optimizer._new_params.storage()
14: /workspace/bert/run_pretraining.py:1000: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
14:   param_storage = optimizer._new_params.storage()
15: /workspace/bert/run_pretraining.py:1000: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
15:   param_storage = optimizer._new_params.storage()
27: /workspace/bert/run_pretraining.py:1000: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
27:   param_storage = optimizer._new_params.storage()
26: /workspace/bert/run_pretraining.py:1000: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
26:   param_storage = optimizer._new_params.storage()
 7: /workspace/bert/run_pretraining.py:1000: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
 7:   param_storage = optimizer._new_params.storage()
 6: /workspace/bert/run_pretraining.py:1000: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
 6:   param_storage = optimizer._new_params.storage()
18: /workspace/bert/run_pretraining.py:1000: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
18:   param_storage = optimizer._new_params.storage()
19: /workspace/bert/run_pretraining.py:1000: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
19:   param_storage = optimizer._new_params.storage()
 0: Torch distributed is available.
 0: Torch distributed is initialized.
22: Torch distributed is available.
22: Torch distributed is initialized.
 4: Torch distributed is available.
 4: Torch distributed is initialized.
17: Torch distributed is available.
17: Torch distributed is initialized.
 3: Torch distributed is available.
 3: Torch distributed is initialized.
20: Torch distributed is available.
20: Torch distributed is initialized.
23: Torch distributed is available.
23: Torch distributed is initialized.
16: Torch distributed is available.
16: Torch distributed is initialized.
 2: Torch distributed is available.
 2: Torch distributed is initialized.
 8: Torch distributed is available.
 8: Torch distributed is initialized.
21: Torch distributed is available.
21: Torch distributed is initialized.
12: Torch distributed is available.
12: Torch distributed is initialized.
13: Torch distributed is available.
13: Torch distributed is initialized.
 5: Torch distributed is available.
 5: Torch distributed is initialized.
 9: Torch distributed is available.
 9: Torch distributed is initialized.
11: Torch distributed is available.
11: Torch distributed is initialized.
31: Torch distributed is available.
31: Torch distributed is initialized.
28: Torch distributed is available.
28: Torch distributed is initialized.
10: Torch distributed is available.
10: Torch distributed is initialized.
29: Torch distributed is available.
29: Torch distributed is initialized.
30: Torch distributed is available.
30: Torch distributed is initialized.
 6: Torch distributed is available.
 6: Torch distributed is initialized.
 7: Torch distributed is available.
 7: Torch distributed is initialized.
18: Torch distributed is available.
18: Torch distributed is initialized.
19: Torch distributed is available.
19: Torch distributed is initialized.
24: Torch distributed is available.
24: Torch distributed is initialized.
27: Torch distributed is available.
27: Torch distributed is initialized.
 1: Torch distributed is available.
 1: Torch distributed is initialized.
25: Torch distributed is available.
25: Torch distributed is initialized.
14: Torch distributed is available.
14: Torch distributed is initialized.
15: Torch distributed is available.
15: Torch distributed is initialized.
26: Torch distributed is available.
26: Torch distributed is initialized.
 2: /workspace/bert/fmha.py:77: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
 2:   Wtmp.set_(Wqkv.storage(), Wqkv.storage_offset(), Wqkv.size(), Wqkv.stride())
 2: /workspace/bert/fmha.py:81: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
 2:   Btmp.set_(Bqkv.storage(), Bqkv.storage_offset(), Bqkv.size(), Bqkv.stride())
 3: /workspace/bert/fmha.py:77: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
 3:   Wtmp.set_(Wqkv.storage(), Wqkv.storage_offset(), Wqkv.size(), Wqkv.stride())
 3: /workspace/bert/fmha.py:81: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
 3:   Btmp.set_(Bqkv.storage(), Bqkv.storage_offset(), Bqkv.size(), Bqkv.stride())
22: /workspace/bert/fmha.py:77: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
22:   Wtmp.set_(Wqkv.storage(), Wqkv.storage_offset(), Wqkv.size(), Wqkv.stride())
22: /workspace/bert/fmha.py:81: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
22:   Btmp.set_(Bqkv.storage(), Bqkv.storage_offset(), Bqkv.size(), Bqkv.stride())
11: /workspace/bert/fmha.py:77: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
11:   Wtmp.set_(Wqkv.storage(), Wqkv.storage_offset(), Wqkv.size(), Wqkv.stride())
11: /workspace/bert/fmha.py:81: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
11:   Btmp.set_(Bqkv.storage(), Bqkv.storage_offset(), Bqkv.size(), Bqkv.stride())
 5: /workspace/bert/fmha.py:77: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
 5:   Wtmp.set_(Wqkv.storage(), Wqkv.storage_offset(), Wqkv.size(), Wqkv.stride())
 5: /workspace/bert/fmha.py:81: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
 5:   Btmp.set_(Bqkv.storage(), Bqkv.storage_offset(), Bqkv.size(), Bqkv.stride())
23: /workspace/bert/fmha.py:77: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
23:   Wtmp.set_(Wqkv.storage(), Wqkv.storage_offset(), Wqkv.size(), Wqkv.stride())
23: /workspace/bert/fmha.py:81: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
23:   Btmp.set_(Bqkv.storage(), Bqkv.storage_offset(), Bqkv.size(), Bqkv.stride())
 4: /workspace/bert/fmha.py:77: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
 4:   Wtmp.set_(Wqkv.storage(), Wqkv.storage_offset(), Wqkv.size(), Wqkv.stride())
 4: /workspace/bert/fmha.py:81: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
 4:   Btmp.set_(Bqkv.storage(), Bqkv.storage_offset(), Bqkv.size(), Bqkv.stride())
 1: /workspace/bert/fmha.py:77: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
 1:   Wtmp.set_(Wqkv.storage(), Wqkv.storage_offset(), Wqkv.size(), Wqkv.stride())
 1: /workspace/bert/fmha.py:81: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
 1:   Btmp.set_(Bqkv.storage(), Bqkv.storage_offset(), Bqkv.size(), Bqkv.stride())
30: /workspace/bert/fmha.py:77: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
30:   Wtmp.set_(Wqkv.storage(), Wqkv.storage_offset(), Wqkv.size(), Wqkv.stride())
30: /workspace/bert/fmha.py:81: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
30:   Btmp.set_(Bqkv.storage(), Bqkv.storage_offset(), Bqkv.size(), Bqkv.stride())
28: /workspace/bert/fmha.py:77: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
28:   Wtmp.set_(Wqkv.storage(), Wqkv.storage_offset(), Wqkv.size(), Wqkv.stride())
28: /workspace/bert/fmha.py:81: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
28:   Btmp.set_(Bqkv.storage(), Bqkv.storage_offset(), Bqkv.size(), Bqkv.stride())
21: /workspace/bert/fmha.py:77: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
21:   Wtmp.set_(Wqkv.storage(), Wqkv.storage_offset(), Wqkv.size(), Wqkv.stride())
21: /workspace/bert/fmha.py:81: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
21:   Btmp.set_(Bqkv.storage(), Bqkv.storage_offset(), Bqkv.size(), Bqkv.stride())
15: /workspace/bert/fmha.py:77: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
15:   Wtmp.set_(Wqkv.storage(), Wqkv.storage_offset(), Wqkv.size(), Wqkv.stride())
15: /workspace/bert/fmha.py:81: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
15:   Btmp.set_(Bqkv.storage(), Bqkv.storage_offset(), Bqkv.size(), Bqkv.stride())
26: /workspace/bert/fmha.py:77: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
26:   Wtmp.set_(Wqkv.storage(), Wqkv.storage_offset(), Wqkv.size(), Wqkv.stride())
26: /workspace/bert/fmha.py:81: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
26:   Btmp.set_(Bqkv.storage(), Bqkv.storage_offset(), Bqkv.size(), Bqkv.stride())
31: /workspace/bert/fmha.py:77: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
31:   Wtmp.set_(Wqkv.storage(), Wqkv.storage_offset(), Wqkv.size(), Wqkv.stride())
31: /workspace/bert/fmha.py:81: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
31:   Btmp.set_(Bqkv.storage(), Bqkv.storage_offset(), Bqkv.size(), Bqkv.stride())
29: /workspace/bert/fmha.py:77: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
29:   Wtmp.set_(Wqkv.storage(), Wqkv.storage_offset(), Wqkv.size(), Wqkv.stride())
29: /workspace/bert/fmha.py:81: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
29:   Btmp.set_(Bqkv.storage(), Bqkv.storage_offset(), Bqkv.size(), Bqkv.stride())
 0: /workspace/bert/fmha.py:77: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
 0:   Wtmp.set_(Wqkv.storage(), Wqkv.storage_offset(), Wqkv.size(), Wqkv.stride())
 0: /workspace/bert/fmha.py:81: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
 0:   Btmp.set_(Bqkv.storage(), Bqkv.storage_offset(), Bqkv.size(), Bqkv.stride())
20: /workspace/bert/fmha.py:77: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
20:   Wtmp.set_(Wqkv.storage(), Wqkv.storage_offset(), Wqkv.size(), Wqkv.stride())
20: /workspace/bert/fmha.py:81: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
20:   Btmp.set_(Bqkv.storage(), Bqkv.storage_offset(), Bqkv.size(), Bqkv.stride())
27: /workspace/bert/fmha.py:77: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
27:   Wtmp.set_(Wqkv.storage(), Wqkv.storage_offset(), Wqkv.size(), Wqkv.stride())
27: /workspace/bert/fmha.py:81: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
27:   Btmp.set_(Bqkv.storage(), Bqkv.storage_offset(), Bqkv.size(), Bqkv.stride())
14: /workspace/bert/fmha.py:77: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
14:   Wtmp.set_(Wqkv.storage(), Wqkv.storage_offset(), Wqkv.size(), Wqkv.stride())
14: /workspace/bert/fmha.py:81: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
14:   Btmp.set_(Bqkv.storage(), Bqkv.storage_offset(), Bqkv.size(), Bqkv.stride())
25: /workspace/bert/fmha.py:77: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
25:   Wtmp.set_(Wqkv.storage(), Wqkv.storage_offset(), Wqkv.size(), Wqkv.stride())
25: /workspace/bert/fmha.py:81: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
25:   Btmp.set_(Bqkv.storage(), Bqkv.storage_offset(), Bqkv.size(), Bqkv.stride())
18: /workspace/bert/fmha.py:77: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
18:   Wtmp.set_(Wqkv.storage(), Wqkv.storage_offset(), Wqkv.size(), Wqkv.stride())
18: /workspace/bert/fmha.py:81: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
18:   Btmp.set_(Bqkv.storage(), Bqkv.storage_offset(), Bqkv.size(), Bqkv.stride())
17: /workspace/bert/fmha.py:77: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
17:   Wtmp.set_(Wqkv.storage(), Wqkv.storage_offset(), Wqkv.size(), Wqkv.stride())
17: /workspace/bert/fmha.py:81: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
17:   Btmp.set_(Bqkv.storage(), Bqkv.storage_offset(), Bqkv.size(), Bqkv.stride())
19: /workspace/bert/fmha.py:77: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
19:   Wtmp.set_(Wqkv.storage(), Wqkv.storage_offset(), Wqkv.size(), Wqkv.stride())
19: /workspace/bert/fmha.py:81: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
19:   Btmp.set_(Bqkv.storage(), Bqkv.storage_offset(), Bqkv.size(), Bqkv.stride())
12: /workspace/bert/fmha.py:77: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
12:   Wtmp.set_(Wqkv.storage(), Wqkv.storage_offset(), Wqkv.size(), Wqkv.stride())
12: /workspace/bert/fmha.py:81: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
12:   Btmp.set_(Bqkv.storage(), Bqkv.storage_offset(), Bqkv.size(), Bqkv.stride())
13: /workspace/bert/fmha.py:77: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
13:   Wtmp.set_(Wqkv.storage(), Wqkv.storage_offset(), Wqkv.size(), Wqkv.stride())
13: /workspace/bert/fmha.py:81: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
13:   Btmp.set_(Bqkv.storage(), Bqkv.storage_offset(), Bqkv.size(), Bqkv.stride())
 8: /workspace/bert/fmha.py:77: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
 8:   Wtmp.set_(Wqkv.storage(), Wqkv.storage_offset(), Wqkv.size(), Wqkv.stride())
 8: /workspace/bert/fmha.py:81: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
 8:   Btmp.set_(Bqkv.storage(), Bqkv.storage_offset(), Bqkv.size(), Bqkv.stride())
16: /workspace/bert/fmha.py:77: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
16:   Wtmp.set_(Wqkv.storage(), Wqkv.storage_offset(), Wqkv.size(), Wqkv.stride())
16: /workspace/bert/fmha.py:81: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
16:   Btmp.set_(Bqkv.storage(), Bqkv.storage_offset(), Bqkv.size(), Bqkv.stride())
10: /workspace/bert/fmha.py:77: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
10:   Wtmp.set_(Wqkv.storage(), Wqkv.storage_offset(), Wqkv.size(), Wqkv.stride())
10: /workspace/bert/fmha.py:81: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
10:   Btmp.set_(Bqkv.storage(), Bqkv.storage_offset(), Bqkv.size(), Bqkv.stride())
24: /workspace/bert/fmha.py:77: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
24:   Wtmp.set_(Wqkv.storage(), Wqkv.storage_offset(), Wqkv.size(), Wqkv.stride())
24: /workspace/bert/fmha.py:81: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
24:   Btmp.set_(Bqkv.storage(), Bqkv.storage_offset(), Bqkv.size(), Bqkv.stride())
 7: /workspace/bert/fmha.py:77: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
 7:   Wtmp.set_(Wqkv.storage(), Wqkv.storage_offset(), Wqkv.size(), Wqkv.stride())
 7: /workspace/bert/fmha.py:81: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
 7:   Btmp.set_(Bqkv.storage(), Bqkv.storage_offset(), Bqkv.size(), Bqkv.stride())
 6: /workspace/bert/fmha.py:77: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
 6:   Wtmp.set_(Wqkv.storage(), Wqkv.storage_offset(), Wqkv.size(), Wqkv.stride())
 6: /workspace/bert/fmha.py:81: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
 6:   Btmp.set_(Bqkv.storage(), Bqkv.storage_offset(), Bqkv.size(), Bqkv.stride())
 9: /workspace/bert/fmha.py:77: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
 9:   Wtmp.set_(Wqkv.storage(), Wqkv.storage_offset(), Wqkv.size(), Wqkv.stride())
 9: /workspace/bert/fmha.py:81: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
 9:   Btmp.set_(Bqkv.storage(), Bqkv.storage_offset(), Bqkv.size(), Bqkv.stride())
 1: /usr/local/lib/python3.8/dist-packages/torch/cuda/amp/grad_scaler.py:342: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
 1:   warnings.warn(
 0: /usr/local/lib/python3.8/dist-packages/torch/cuda/amp/grad_scaler.py:342: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
 0:   warnings.warn(
24: /usr/local/lib/python3.8/dist-packages/torch/cuda/amp/grad_scaler.py:342: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
24:   warnings.warn(
25: /usr/local/lib/python3.8/dist-packages/torch/cuda/amp/grad_scaler.py:342: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
25:   warnings.warn(
10: /usr/local/lib/python3.8/dist-packages/torch/cuda/amp/grad_scaler.py:342: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
10:   warnings.warn(
14: /usr/local/lib/python3.8/dist-packages/torch/cuda/amp/grad_scaler.py:342: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
14:   warnings.warn(
16: /usr/local/lib/python3.8/dist-packages/torch/cuda/amp/grad_scaler.py:342: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
16:   warnings.warn(
15: /usr/local/lib/python3.8/dist-packages/torch/cuda/amp/grad_scaler.py:342: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
15:   warnings.warn(
 2: /usr/local/lib/python3.8/dist-packages/torch/cuda/amp/grad_scaler.py:342: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
 2:   warnings.warn(
11: /usr/local/lib/python3.8/dist-packages/torch/cuda/amp/grad_scaler.py:342: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
11:   warnings.warn(
30: /usr/local/lib/python3.8/dist-packages/torch/cuda/amp/grad_scaler.py:342: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
30:   warnings.warn(
22: /usr/local/lib/python3.8/dist-packages/torch/cuda/amp/grad_scaler.py:342: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
22:   warnings.warn(
17: /usr/local/lib/python3.8/dist-packages/torch/cuda/amp/grad_scaler.py:342: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
17:   warnings.warn(
 3: /usr/local/lib/python3.8/dist-packages/torch/cuda/amp/grad_scaler.py:342: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
 3:   warnings.warn(
 8: /usr/local/lib/python3.8/dist-packages/torch/cuda/amp/grad_scaler.py:342: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
 8:   warnings.warn(
31: /usr/local/lib/python3.8/dist-packages/torch/cuda/amp/grad_scaler.py:342: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
31:   warnings.warn(
23: /usr/local/lib/python3.8/dist-packages/torch/cuda/amp/grad_scaler.py:342: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
23:   warnings.warn(
 4: /usr/local/lib/python3.8/dist-packages/torch/cuda/amp/grad_scaler.py:342: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
 4:   warnings.warn(
 9: /usr/local/lib/python3.8/dist-packages/torch/cuda/amp/grad_scaler.py:342: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
 9:   warnings.warn(
 5: /usr/local/lib/python3.8/dist-packages/torch/cuda/amp/grad_scaler.py:342: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
 5:   warnings.warn(
12: /usr/local/lib/python3.8/dist-packages/torch/cuda/amp/grad_scaler.py:342: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
12:   warnings.warn(
18: /usr/local/lib/python3.8/dist-packages/torch/cuda/amp/grad_scaler.py:342: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
18:   warnings.warn(
19: /usr/local/lib/python3.8/dist-packages/torch/cuda/amp/grad_scaler.py:342: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
19:   warnings.warn(
13: /usr/local/lib/python3.8/dist-packages/torch/cuda/amp/grad_scaler.py:342: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
13:   warnings.warn(
20: /usr/local/lib/python3.8/dist-packages/torch/cuda/amp/grad_scaler.py:342: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
20:   warnings.warn(
21: /usr/local/lib/python3.8/dist-packages/torch/cuda/amp/grad_scaler.py:342: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
21:   warnings.warn(
28: /usr/local/lib/python3.8/dist-packages/torch/cuda/amp/grad_scaler.py:342: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
28:   warnings.warn(
29: /usr/local/lib/python3.8/dist-packages/torch/cuda/amp/grad_scaler.py:342: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
29:   warnings.warn(
26: /usr/local/lib/python3.8/dist-packages/torch/cuda/amp/grad_scaler.py:342: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
26:   warnings.warn(
27: /usr/local/lib/python3.8/dist-packages/torch/cuda/amp/grad_scaler.py:342: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
27:   warnings.warn(
 6: /usr/local/lib/python3.8/dist-packages/torch/cuda/amp/grad_scaler.py:342: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
 6:   warnings.warn(
 7: /usr/local/lib/python3.8/dist-packages/torch/cuda/amp/grad_scaler.py:342: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
 7:   warnings.warn(
 0: :::MLLOG {"namespace": "", "time_ms": 1696011896984, "event_type": "INTERVAL_END", "key": "init_stop", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1606}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011896984, "event_type": "INTERVAL_START", "key": "run_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1606}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011896999, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1619, "epoch_num": 0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011897000, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1621, "first_epoch_num": 1, "epoch_count": 1}}
 0: parsed args:
 0: Namespace(allreduce_post_accumulation=True, allreduce_post_accumulation_fp16=True, average_packing_rate=2, bert_config_path='/workspace/phase1/bert_config.json', bert_model='bert-large-uncased', bypass_amp=False, cache_eval_data=True, checkpoint_activations=False, cuda_graph_mode='segmented', ddp_type='apex', dense_seq_output=True, device=device(type='cuda', index=0), disable_apex_softmax=False, disable_fuse_mask=False, disable_fuse_qkv=False, disable_fuse_scale=False, distributed_lamb=True, do_train=True, dwu_e5m2_allgather=False, dwu_group_size=0, dwu_num_ag_pg=1, dwu_num_ar_pg=1, dwu_num_blocks=1, dwu_num_chunks=1, dwu_num_rs_pg=1, dwu_overlap_reductions=False, enable_fuse_dropout=False, enable_stream=False, eval_batch_size=16, eval_dir='/workspace/evaldata', eval_iter_samples=175000, eval_iter_start_samples=175000, exchange_padding=False, fp16=True, fused_bias_fc=True, fused_bias_fc_loss_head=False, fused_bias_mha=True, fused_dropout_add=True, fused_gelu_bias=False, fused_gemm_gelu=True, fused_mha=False, 
 0: gradient_accumulation_steps=1, init_checkpoint='/workspace/phase1/tf2_ckpt/model.ckpt-28252.pt', init_tf_checkpoint=None, input_dir='/workspace/data_phase2', keep_n_most_recent_checkpoints=20, learning_rate=0.002, local_rank=0, log_freq=0.0, loss_scale=0.0, max_iterations_per_graph=4, max_pack_factor=3, max_predictions_per_seq=76, max_samples_termination=4500000.0, max_seq_length=512, max_steps=2254.0, min_samples_to_start_checkpoints=3000000, n_gpu=32, num_epochs_to_generate_seeds_for=2, num_eval_examples=10000, num_samples_per_checkpoint=500000, opt_lamb_beta_1=0.66, opt_lamb_beta_2=0.996, order_samples=False, output_dir='/results', packed_samples=True, pad=False, pad_fmha=True, phase2=True, resume_from_checkpoint=False, resume_step=0, seed=31900, skip_checkpoint=True, start_warmup_step=0.0, synthetic_input=False, target_mlm_accuracy=0.72, train_batch_size=48, train_mlm_accuracy_window_size=0, unpad=False, unpad_fmha=False, use_cuda_graph=False, use_ddp=False, use_env=False, use_gradient_as_bucket_view=Fals
 0: e, use_transformer_engine2=False, warmup_proportion=0.0, warmup_steps=0.0, weight_decay_rate=0.01)
 0: epoch: 1
 0: :::MLLOG {"namespace": "", "time_ms": 1696011897001, "event_type": "POINT_IN_TIME", "key": "data_file", "value": "/workspace/data_phase2/part_03096.hdf5", "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1655}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011924318, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.3692108392715454, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1836, "epoch_num": 175331}}
 0: {'global_steps': 57, 'eval_loss': 4.139103412628174, 'eval_mlm_accuracy': 0.3692108392715454}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011950477, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.38501057028770447, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1836, "epoch_num": 350420}}
 0: {'global_steps': 114, 'eval_loss': 4.006965637207031, 'eval_mlm_accuracy': 0.38501057028770447}
 0: :::MLLOG {"namespace": "", "time_ms": 1696011976621, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.41356730461120605, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1836, "epoch_num": 525139}}
 0: {'global_steps': 171, 'eval_loss': 3.743912696838379, 'eval_mlm_accuracy': 0.41356730461120605}
 0: :::MLLOG {"namespace": "", "time_ms": 1696012002819, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.4869335889816284, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1836, "epoch_num": 700353}}
 0: {'global_steps': 228, 'eval_loss': 3.1030280590057373, 'eval_mlm_accuracy': 0.4869335889816284}
 0: :::MLLOG {"namespace": "", "time_ms": 1696012029020, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.5991009473800659, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1836, "epoch_num": 875364}}
 0: {'global_steps': 285, 'eval_loss': 2.170912265777588, 'eval_mlm_accuracy': 0.5991009473800659}
 0: :::MLLOG {"namespace": "", "time_ms": 1696012055260, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.697918176651001, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1836, "epoch_num": 1050429}}
 0: {'global_steps': 342, 'eval_loss': 1.445589303970337, 'eval_mlm_accuracy': 0.697918176651001}
 0: :::MLLOG {"namespace": "", "time_ms": 1696012081802, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7072938680648804, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1836, "epoch_num": 1225278}}
 0: {'global_steps': 399, 'eval_loss': 1.3832762241363525, 'eval_mlm_accuracy': 0.7072938680648804}
 0: :::MLLOG {"namespace": "", "time_ms": 1696012108055, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7100633978843689, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1836, "epoch_num": 1399925}}
 0: {'global_steps': 456, 'eval_loss': 1.3688900470733643, 'eval_mlm_accuracy': 0.7100633978843689}
 0: :::MLLOG {"namespace": "", "time_ms": 1696012134329, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7118661403656006, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1836, "epoch_num": 1574695}}
 0: {'global_steps': 513, 'eval_loss': 1.361204743385315, 'eval_mlm_accuracy': 0.7118661403656006}
 0: :::MLLOG {"namespace": "", "time_ms": 1696012160587, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7128515839576721, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1836, "epoch_num": 1749839}}
 0: {'global_steps': 570, 'eval_loss': 1.3479406833648682, 'eval_mlm_accuracy': 0.7128515839576721}
 0: :::MLLOG {"namespace": "", "time_ms": 1696012186878, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7144815325737, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1836, "epoch_num": 1924437}}
 0: {'global_steps': 627, 'eval_loss': 1.345578908920288, 'eval_mlm_accuracy': 0.7144815325737}
 0: :::MLLOG {"namespace": "", "time_ms": 1696012213171, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7150256037712097, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1836, "epoch_num": 2099598}}
 0: {'global_steps': 684, 'eval_loss': 1.3380463123321533, 'eval_mlm_accuracy': 0.7150256037712097}
 0: :::MLLOG {"namespace": "", "time_ms": 1696012239443, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7159573435783386, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1836, "epoch_num": 2274504}}
 0: {'global_steps': 741, 'eval_loss': 1.330244779586792, 'eval_mlm_accuracy': 0.7159573435783386}
 0: :::MLLOG {"namespace": "", "time_ms": 1696012265873, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7165785431861877, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1836, "epoch_num": 2449772}}
 0: {'global_steps': 798, 'eval_loss': 1.3275426626205444, 'eval_mlm_accuracy': 0.7165785431861877}
 0: :::MLLOG {"namespace": "", "time_ms": 1696012292157, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7166041731834412, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1836, "epoch_num": 2624520}}
 0: {'global_steps': 855, 'eval_loss': 1.3253774642944336, 'eval_mlm_accuracy': 0.7166041731834412}
 0: :::MLLOG {"namespace": "", "time_ms": 1696012318440, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7176036238670349, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1836, "epoch_num": 2800038}}
 0: {'global_steps': 912, 'eval_loss': 1.3209174871444702, 'eval_mlm_accuracy': 0.7176036238670349}
 0: :::MLLOG {"namespace": "", "time_ms": 1696012344726, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7180006504058838, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1836, "epoch_num": 2974961}}
 0: {'global_steps': 969, 'eval_loss': 1.3204702138900757, 'eval_mlm_accuracy': 0.7180006504058838}
 0: :::MLLOG {"namespace": "", "time_ms": 1696012371203, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7188576459884644, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1836, "epoch_num": 3149919}}
 0: {'global_steps': 1026, 'eval_loss': 1.3166922330856323, 'eval_mlm_accuracy': 0.7188576459884644}
 0: :::MLLOG {"namespace": "", "time_ms": 1696012397493, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.719355046749115, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1836, "epoch_num": 3325014}}
 0: {'global_steps': 1083, 'eval_loss': 1.3124208450317383, 'eval_mlm_accuracy': 0.719355046749115}
 0: :::MLLOG {"namespace": "", "time_ms": 1696012424008, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7193573713302612, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1836, "epoch_num": 3500357}}
 0: {'global_steps': 1140, 'eval_loss': 1.3086519241333008, 'eval_mlm_accuracy': 0.7193573713302612}
 0: :::MLLOG {"namespace": "", "time_ms": 1696012450289, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7200532555580139, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1836, "epoch_num": 3675095}}
 0: {'global_steps': 1197, 'eval_loss': 1.309625506401062, 'eval_mlm_accuracy': 0.7200532555580139}
 0: 0.720053 > 0.720000, Target MLM Accuracy reached at 1197
 0: (1, 1197.0) {'final_loss': 0.0}
 0: :::MLLOG {"namespace": "", "time_ms": 1696012450297, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1966, "first_epoch_num": 1}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696012450297, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1969, "epoch_num": 3675095}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696012450297, "event_type": "POINT_IN_TIME", "key": "train_samples", "value": 3675095, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1977}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696012450297, "event_type": "POINT_IN_TIME", "key": "eval_samples", "value": 10000, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1980}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696012450297, "event_type": "INTERVAL_END", "key": "run_stop", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1983, "status": "success"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1696012450297, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 6641.987674633211, "epoch_num": 3675095}, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1987, "step": [2, 1197]}}
 0: {'e2e_time': 571.7701358795166, 'training_sequences_per_second': 12402.449830517002, 'final_loss': 0.0, 'raw_train_time': 558.3000209331512}
 2: ENDING TIMING RUN AT 2023-09-29 02:34:13 PM
 2: RESULT,bert,5734,590,nnisbet,2023-09-29 02:24:23 PM
 9: ENDING TIMING RUN AT 2023-09-29 02:34:13 PM
 9: RESULT,bert,19679,590,nnisbet,2023-09-29 02:24:23 PM
19: ENDING TIMING RUN AT 2023-09-29 02:34:13 PM
19: RESULT,bert,23162,590,nnisbet,2023-09-29 02:24:23 PM
 4: ENDING TIMING RUN AT 2023-09-29 02:34:13 PM
 4: RESULT,bert,28505,590,nnisbet,2023-09-29 02:24:23 PM
 0: ENDING TIMING RUN AT 2023-09-29 02:34:13 PM
 0: RESULT,bert,31900,590,nnisbet,2023-09-29 02:24:23 PM
22: ENDING TIMING RUN AT 2023-09-29 02:34:13 PM
22: RESULT,bert,4852,590,nnisbet,2023-09-29 02:24:23 PM
14: ENDING TIMING RUN AT 2023-09-29 02:34:13 PM
14: RESULT,bert,26333,590,nnisbet,2023-09-29 02:24:23 PM
28: ENDING TIMING RUN AT 2023-09-29 02:34:13 PM
28: RESULT,bert,22031,590,nnisbet,2023-09-29 02:24:23 PM
16: ENDING TIMING RUN AT 2023-09-29 02:34:13 PM
16: RESULT,bert,7160,590,nnisbet,2023-09-29 02:24:23 PM
11: ENDING TIMING RUN AT 2023-09-29 02:34:13 PM
11: RESULT,bert,31562,590,nnisbet,2023-09-29 02:24:23 PM
13: ENDING TIMING RUN AT 2023-09-29 02:34:13 PM
13: RESULT,bert,25130,590,nnisbet,2023-09-29 02:24:23 PM
20: ENDING TIMING RUN AT 2023-09-29 02:34:13 PM
20: RESULT,bert,2248,590,nnisbet,2023-09-29 02:24:23 PM
 6: ENDING TIMING RUN AT 2023-09-29 02:34:13 PM
 6: RESULT,bert,14512,590,nnisbet,2023-09-29 02:24:23 PM
24: ENDING TIMING RUN AT 2023-09-29 02:34:13 PM
24: RESULT,bert,20283,590,nnisbet,2023-09-29 02:24:23 PM
26: ENDING TIMING RUN AT 2023-09-29 02:34:13 PM
26: RESULT,bert,2081,590,nnisbet,2023-09-29 02:24:23 PM
30: ENDING TIMING RUN AT 2023-09-29 02:34:13 PM
30: RESULT,bert,24876,590,nnisbet,2023-09-29 02:24:23 PM
 1: ENDING TIMING RUN AT 2023-09-29 02:34:13 PM
 1: RESULT,bert,6729,590,nnisbet,2023-09-29 02:24:23 PM
18: ENDING TIMING RUN AT 2023-09-29 02:34:13 PM
18: RESULT,bert,12398,590,nnisbet,2023-09-29 02:24:23 PM
 8: ENDING TIMING RUN AT 2023-09-29 02:34:13 PM
 8: RESULT,bert,24608,590,nnisbet,2023-09-29 02:24:23 PM
 5: ENDING TIMING RUN AT 2023-09-29 02:34:13 PM
 5: RESULT,bert,18056,590,nnisbet,2023-09-29 02:24:23 PM
 3: ENDING TIMING RUN AT 2023-09-29 02:34:13 PM
 3: RESULT,bert,5631,590,nnisbet,2023-09-29 02:24:23 PM
23: ENDING TIMING RUN AT 2023-09-29 02:34:13 PM
23: RESULT,bert,31193,590,nnisbet,2023-09-29 02:24:23 PM
15: ENDING TIMING RUN AT 2023-09-29 02:34:13 PM
15: RESULT,bert,2840,590,nnisbet,2023-09-29 02:24:23 PM
29: ENDING TIMING RUN AT 2023-09-29 02:34:13 PM
29: RESULT,bert,24903,590,nnisbet,2023-09-29 02:24:23 PM
10: ENDING TIMING RUN AT 2023-09-29 02:34:13 PM
10: RESULT,bert,11251,590,nnisbet,2023-09-29 02:24:23 PM
17: ENDING TIMING RUN AT 2023-09-29 02:34:13 PM
17: RESULT,bert,19632,590,nnisbet,2023-09-29 02:24:23 PM
21: ENDING TIMING RUN AT 2023-09-29 02:34:13 PM
21: RESULT,bert,12036,590,nnisbet,2023-09-29 02:24:23 PM
25: ENDING TIMING RUN AT 2023-09-29 02:34:13 PM
25: RESULT,bert,19862,590,nnisbet,2023-09-29 02:24:23 PM
 7: ENDING TIMING RUN AT 2023-09-29 02:34:13 PM
 7: RESULT,bert,21910,590,nnisbet,2023-09-29 02:24:23 PM
12: ENDING TIMING RUN AT 2023-09-29 02:34:13 PM
12: RESULT,bert,8783,590,nnisbet,2023-09-29 02:24:23 PM
31: ENDING TIMING RUN AT 2023-09-29 02:34:13 PM
31: RESULT,bert,16362,590,nnisbet,2023-09-29 02:24:23 PM
27: ENDING TIMING RUN AT 2023-09-29 02:34:13 PM
27: RESULT,bert,30640,590,nnisbet,2023-09-29 02:24:23 PM
