{
    "submitter": "Azure+NVIDIA",
    "division": "closed",
    "status": "Available Cloud",
    "system_name": "ND_H100_v5 x1344",
    "number_of_nodes": "1344",
    "host_processors_per_node": "2",
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processor_core_count": "48",
    "host_processor_vcpu_count": "96",
    "host_processor_frequency": "3.8GHz",
    "host_processor_caches": "N/A",
    "host_processor_interconnect": "",
    "host_memory_capacity": "1.8 TB",
    "host_storage_type": "NVMe SSD",
    "host_storage_capacity": "8x 4TB NVMe SSD",
    "host_networking": "1x Ethernet 100Gb/Sec, 8x NVIDIA Quantum-2 CX7 InfiniBand (400Gb/s)",
    "host_networking_topology": "",
    "host_memory_configuration": "",
    "accelerators_per_node": "8",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerator_host_interconnect": "",
    "accelerator_frequency": "",
    "accelerator_on-chip_memories": "",
    "accelerator_memory_configuration": "HBM3",
    "accelerator_memory_capacity": "80 GB",
    "accelerator_interconnect": "NVLINK 4.0",
    "accelerator_interconnect_topology": "",
    "cooling": "",
    "hw_notes": "",
    "framework": "PyTorch NVIDIA Release 23.09",
    "other_software_stack": {
        "cuda_version": "12.2.1.020",
        "cuda_driver_version": "535.86.10",
        "nccl_version": "2.18.5-fix-4365458757e4107ecbf629b2fd6e0e19a5d237c2",
        "cublas_version": "12.2.5.6",
        "cudnn_version": "8.9.5.27",
        "trt_version": "8.6.1.6+cuda12.0.1.011",
        "dali_version": "1.29.0",
        "mofed_version": "5.4-rdmacore39.0",
        "openmpi_version": "4.1.5rc2",
	"kernel_version": "Linux 5.15.0-1041-azure",
        "nvidia_kernel_driver": "535.86.10"
    },
    "operating_system": "Ubuntu 22.04.2 LTS",
    "sw_notes": "This result was obtained in partnership between Azure AI Production and NVIDIA"
}
