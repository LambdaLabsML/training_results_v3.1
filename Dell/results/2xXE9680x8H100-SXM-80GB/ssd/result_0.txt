+ echo 'Beginning trial 1 of 5'
Beginning trial 1 of 5
+ echo ':::DLPAL dockerd://mlperf-dell:single_stage_detector 106 2 xe9680node[30,70] '\''unknown'\'' XE9680_002x08x016'
:::DLPAL dockerd://mlperf-dell:single_stage_detector 106 2 xe9680node[30,70] 'unknown' XE9680_002x08x016
+ srun -N1 -n1 --container-name=single_stage_detector_106 python -c ''
+ '[' 1 -eq 1 ']'
+ srun --ntasks=2 bash -c 'echo -n '\''Clearing cache on '\'' && hostname && sync && sudo /sbin/sysctl vm.drop_caches=3'
Clearing cache on xe9680node30
Clearing cache on xe9680node70
vm.drop_caches = 3
vm.drop_caches = 3
+ srun --ntasks=2 --container-name=single_stage_detector_106 python -c '
from mlperf_logger import mllogger
mllogger.event(key=mllogger.constants.CACHE_CLEAR, value=True)'
:::MLLOG {"namespace": "", "time_ms": 1696359776990, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1696359776994, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
+ sleep 30
+ srun --ntasks=16 --ntasks-per-node=8 --container-name=single_stage_detector_106 --container-mounts=/xe9680_nvme1n1/training_datasets_v3.0/ssd:/datasets/open-images-v6,/root/mlperf_training/ssd/:/results,/xe9680_nvme1n1/training_datasets_v3.0/ssd/train/:/root/.cache/torch --container-workdir=/workspace/ssd slurm2pytorch ./run_and_time.sh
STARTING TIMING RUN AT 2023-10-03 07:03:27 PM
STARTING TIMING RUN AT 2023-10-03 07:03:27 PM
RANK 8: LOCAL_RANK 0, MASTER_ADDR xe9680node30, MASTER_PORT 49258, WORLD_SIZE 16, MLPERF_SLURM_FIRSTNODE xe9680node30, SLURM_JOB_ID 106, SLURM_NTASKS 16, SLURM_PROCID 8, SLURM_LOCALID 0, OMP_NUM_THREADS 1
running benchmark
RANK 14: LOCAL_RANK 6, MASTER_ADDR xe9680node30, MASTER_PORT 49258, WORLD_SIZE 16, MLPERF_SLURM_FIRSTNODE xe9680node30, SLURM_JOB_ID 106, SLURM_NTASKS 16, SLURM_PROCID 14, SLURM_LOCALID 6, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2023-10-03 07:03:27 PM
RANK 12: LOCAL_RANK 4, MASTER_ADDR xe9680node30, MASTER_PORT 49258, WORLD_SIZE 16, MLPERF_SLURM_FIRSTNODE xe9680node30, SLURM_JOB_ID 106, SLURM_NTASKS 16, SLURM_PROCID 12, SLURM_LOCALID 4, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2023-10-03 07:03:27 PM
RANK 11: LOCAL_RANK 3, MASTER_ADDR xe9680node30, MASTER_PORT 49258, WORLD_SIZE 16, MLPERF_SLURM_FIRSTNODE xe9680node30, SLURM_JOB_ID 106, SLURM_NTASKS 16, SLURM_PROCID 11, SLURM_LOCALID 3, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2023-10-03 07:03:27 PM
STARTING TIMING RUN AT 2023-10-03 07:03:27 PM
RANK 15: LOCAL_RANK 7, MASTER_ADDR xe9680node30, MASTER_PORT 49258, WORLD_SIZE 16, MLPERF_SLURM_FIRSTNODE xe9680node30, SLURM_JOB_ID 106, SLURM_NTASKS 16, SLURM_PROCID 15, SLURM_LOCALID 7, OMP_NUM_THREADS 1
running benchmark
RANK 10: LOCAL_RANK 2, MASTER_ADDR xe9680node30, MASTER_PORT 49258, WORLD_SIZE 16, MLPERF_SLURM_FIRSTNODE xe9680node30, SLURM_JOB_ID 106, SLURM_NTASKS 16, SLURM_PROCID 10, SLURM_LOCALID 2, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2023-10-03 07:03:27 PM
STARTING TIMING RUN AT 2023-10-03 07:03:27 PM
RANK 9: LOCAL_RANK 1, MASTER_ADDR xe9680node30, MASTER_PORT 49258, WORLD_SIZE 16, MLPERF_SLURM_FIRSTNODE xe9680node30, SLURM_JOB_ID 106, SLURM_NTASKS 16, SLURM_PROCID 9, SLURM_LOCALID 1, OMP_NUM_THREADS 1
RANK 13: LOCAL_RANK 5, MASTER_ADDR xe9680node30, MASTER_PORT 49258, WORLD_SIZE 16, MLPERF_SLURM_FIRSTNODE xe9680node30, SLURM_JOB_ID 106, SLURM_NTASKS 16, SLURM_PROCID 13, SLURM_LOCALID 5, OMP_NUM_THREADS 1
running benchmark
running benchmark
STARTING TIMING RUN AT 2023-10-03 07:03:27 PM
STARTING TIMING RUN AT 2023-10-03 07:03:27 PM
RANK 3: LOCAL_RANK 3, MASTER_ADDR xe9680node30, MASTER_PORT 49258, WORLD_SIZE 16, MLPERF_SLURM_FIRSTNODE xe9680node30, SLURM_JOB_ID 106, SLURM_NTASKS 16, SLURM_PROCID 3, SLURM_LOCALID 3, OMP_NUM_THREADS 1
running benchmark
RANK 7: LOCAL_RANK 7, MASTER_ADDR xe9680node30, MASTER_PORT 49258, WORLD_SIZE 16, MLPERF_SLURM_FIRSTNODE xe9680node30, SLURM_JOB_ID 106, SLURM_NTASKS 16, SLURM_PROCID 7, SLURM_LOCALID 7, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2023-10-03 07:03:27 PM
RANK 5: LOCAL_RANK 5, MASTER_ADDR xe9680node30, MASTER_PORT 49258, WORLD_SIZE 16, MLPERF_SLURM_FIRSTNODE xe9680node30, SLURM_JOB_ID 106, SLURM_NTASKS 16, SLURM_PROCID 5, SLURM_LOCALID 5, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2023-10-03 07:03:27 PM
RANK 1: LOCAL_RANK 1, MASTER_ADDR xe9680node30, MASTER_PORT 49258, WORLD_SIZE 16, MLPERF_SLURM_FIRSTNODE xe9680node30, SLURM_JOB_ID 106, SLURM_NTASKS 16, SLURM_PROCID 1, SLURM_LOCALID 1, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2023-10-03 07:03:27 PM
RANK 4: LOCAL_RANK 4, MASTER_ADDR xe9680node30, MASTER_PORT 49258, WORLD_SIZE 16, MLPERF_SLURM_FIRSTNODE xe9680node30, SLURM_JOB_ID 106, SLURM_NTASKS 16, SLURM_PROCID 4, SLURM_LOCALID 4, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2023-10-03 07:03:27 PM
RANK 0: LOCAL_RANK 0, MASTER_ADDR xe9680node30, MASTER_PORT 49258, WORLD_SIZE 16, MLPERF_SLURM_FIRSTNODE xe9680node30, SLURM_JOB_ID 106, SLURM_NTASKS 16, SLURM_PROCID 0, SLURM_LOCALID 0, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2023-10-03 07:03:27 PM
RANK 6: LOCAL_RANK 6, MASTER_ADDR xe9680node30, MASTER_PORT 49258, WORLD_SIZE 16, MLPERF_SLURM_FIRSTNODE xe9680node30, SLURM_JOB_ID 106, SLURM_NTASKS 16, SLURM_PROCID 6, SLURM_LOCALID 6, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2023-10-03 07:03:27 PM
RANK 2: LOCAL_RANK 2, MASTER_ADDR xe9680node30, MASTER_PORT 49258, WORLD_SIZE 16, MLPERF_SLURM_FIRSTNODE xe9680node30, SLURM_JOB_ID 106, SLURM_NTASKS 16, SLURM_PROCID 2, SLURM_LOCALID 2, OMP_NUM_THREADS 1
running benchmark
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=52
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=52
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=52
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=52
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=52
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=52
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=52
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=52
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=52
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=52
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=52
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=52
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=52
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=52
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=52
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=52
Matplotlib created a temporary cache directory at /tmp/matplotlib-82k9zc78 because the default path (/root/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
/usr/local/lib/python3.10/dist-packages/torch/jit/annotations.py:386: UserWarning: TorchScript will treat type annotations of Tensor dtype-specific subtypes as if they are normal Tensors. dtype constraints are not enforced in compilation either.
  warnings.warn(
Matplotlib created a temporary cache directory at /tmp/matplotlib-fk5gd2kb because the default path (/root/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
Matplotlib created a temporary cache directory at /tmp/matplotlib-6qwfz6vl because the default path (/root/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
/usr/local/lib/python3.10/dist-packages/torch/jit/annotations.py:386: UserWarning: TorchScript will treat type annotations of Tensor dtype-specific subtypes as if they are normal Tensors. dtype constraints are not enforced in compilation either.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/jit/annotations.py:386: UserWarning: TorchScript will treat type annotations of Tensor dtype-specific subtypes as if they are normal Tensors. dtype constraints are not enforced in compilation either.
  warnings.warn(
Matplotlib created a temporary cache directory at /tmp/matplotlib-ta_quslr because the default path (/root/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
Matplotlib created a temporary cache directory at /tmp/matplotlib-5mapy0_m because the default path (/root/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
/usr/local/lib/python3.10/dist-packages/torch/jit/annotations.py:386: UserWarning: TorchScript will treat type annotations of Tensor dtype-specific subtypes as if they are normal Tensors. dtype constraints are not enforced in compilation either.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/jit/annotations.py:386: UserWarning: TorchScript will treat type annotations of Tensor dtype-specific subtypes as if they are normal Tensors. dtype constraints are not enforced in compilation either.
  warnings.warn(
Matplotlib created a temporary cache directory at /tmp/matplotlib-qeewz7b8 because the default path (/root/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
/usr/local/lib/python3.10/dist-packages/torch/jit/annotations.py:386: UserWarning: TorchScript will treat type annotations of Tensor dtype-specific subtypes as if they are normal Tensors. dtype constraints are not enforced in compilation either.
  warnings.warn(
Matplotlib created a temporary cache directory at /tmp/matplotlib-mt9f9xhi because the default path (/root/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
/usr/local/lib/python3.10/dist-packages/torch/jit/annotations.py:386: UserWarning: TorchScript will treat type annotations of Tensor dtype-specific subtypes as if they are normal Tensors. dtype constraints are not enforced in compilation either.
  warnings.warn(
Matplotlib created a temporary cache directory at /tmp/matplotlib-i1bnmb52 because the default path (/root/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
Matplotlib created a temporary cache directory at /tmp/matplotlib-_qipdyoh because the default path (/root/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
/usr/local/lib/python3.10/dist-packages/torch/jit/annotations.py:386: UserWarning: TorchScript will treat type annotations of Tensor dtype-specific subtypes as if they are normal Tensors. dtype constraints are not enforced in compilation either.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/jit/annotations.py:386: UserWarning: TorchScript will treat type annotations of Tensor dtype-specific subtypes as if they are normal Tensors. dtype constraints are not enforced in compilation either.
  warnings.warn(
Matplotlib created a temporary cache directory at /tmp/matplotlib-82po5vql because the default path (/root/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
Matplotlib created a temporary cache directory at /tmp/matplotlib-nggcrod8 because the default path (/root/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
Matplotlib created a temporary cache directory at /tmp/matplotlib-8cir5j5u because the default path (/root/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
Matplotlib created a temporary cache directory at /tmp/matplotlib-czhapnaw because the default path (/root/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
/usr/local/lib/python3.10/dist-packages/torch/jit/annotations.py:386: UserWarning: TorchScript will treat type annotations of Tensor dtype-specific subtypes as if they are normal Tensors. dtype constraints are not enforced in compilation either.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/jit/annotations.py:386: UserWarning: TorchScript will treat type annotations of Tensor dtype-specific subtypes as if they are normal Tensors. dtype constraints are not enforced in compilation either.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/jit/annotations.py:386: UserWarning: TorchScript will treat type annotations of Tensor dtype-specific subtypes as if they are normal Tensors. dtype constraints are not enforced in compilation either.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/jit/annotations.py:386: UserWarning: TorchScript will treat type annotations of Tensor dtype-specific subtypes as if they are normal Tensors. dtype constraints are not enforced in compilation either.
  warnings.warn(
Matplotlib created a temporary cache directory at /tmp/matplotlib-g4xp344d because the default path (/root/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
Matplotlib created a temporary cache directory at /tmp/matplotlib-4v567thd because the default path (/root/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
Matplotlib created a temporary cache directory at /tmp/matplotlib-ev_qyqcy because the default path (/root/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
/usr/local/lib/python3.10/dist-packages/torch/jit/annotations.py:386: UserWarning: TorchScript will treat type annotations of Tensor dtype-specific subtypes as if they are normal Tensors. dtype constraints are not enforced in compilation either.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/jit/annotations.py:386: UserWarning: TorchScript will treat type annotations of Tensor dtype-specific subtypes as if they are normal Tensors. dtype constraints are not enforced in compilation either.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/jit/annotations.py:386: UserWarning: TorchScript will treat type annotations of Tensor dtype-specific subtypes as if they are normal Tensors. dtype constraints are not enforced in compilation either.
  warnings.warn(
[W init.cpp:842] Warning: Use _jit_set_fusion_strategy, bailout depth is deprecated. Setting to (STATIC, 20) (function operator())
[W init.cpp:842] Warning: Use _jit_set_fusion_strategy, bailout depth is deprecated. Setting to (STATIC, 20) (function operator())
[W init.cpp:842] Warning: Use _jit_set_fusion_strategy, bailout depth is deprecated. Setting to (STATIC, 20) (function operator())
[W init.cpp:842] Warning: Use _jit_set_fusion_strategy, bailout depth is deprecated. Setting to (STATIC, 20) (function operator())
[W init.cpp:842] Warning: Use _jit_set_fusion_strategy, bailout depth is deprecated. Setting to (STATIC, 20) (function operator())
[W init.cpp:842] Warning: Use _jit_set_fusion_strategy, bailout depth is deprecated. Setting to (STATIC, 20) (function operator())
[W init.cpp:842] Warning: Use _jit_set_fusion_strategy, bailout depth is deprecated. Setting to (STATIC, 20) (function operator())
[W init.cpp:842] Warning: Use _jit_set_fusion_strategy, bailout depth is deprecated. Setting to (STATIC, 20) (function operator())
[W init.cpp:842] Warning: Use _jit_set_fusion_strategy, bailout depth is deprecated. Setting to (STATIC, 20) (function operator())
[W init.cpp:842] Warning: Use _jit_set_fusion_strategy, bailout depth is deprecated. Setting to (STATIC, 20) (function operator())
[W init.cpp:842] Warning: Use _jit_set_fusion_strategy, bailout depth is deprecated. Setting to (STATIC, 20) (function operator())
[W init.cpp:842] Warning: Use _jit_set_fusion_strategy, bailout depth is deprecated. Setting to (STATIC, 20) (function operator())
[W init.cpp:842] Warning: Use _jit_set_fusion_strategy, bailout depth is deprecated. Setting to (STATIC, 20) (function operator())
[W init.cpp:842] Warning: Use _jit_set_fusion_strategy, bailout depth is deprecated. Setting to (STATIC, 20) (function operator())
[W init.cpp:842] Warning: Use _jit_set_fusion_strategy, bailout depth is deprecated. Setting to (STATIC, 20) (function operator())
[W init.cpp:842] Warning: Use _jit_set_fusion_strategy, bailout depth is deprecated. Setting to (STATIC, 20) (function operator())
| distributed init (rank 3): env://
[W socket.cpp:663] [c10d] The client socket has failed to connect to [xe9680node30]:49258 (errno: 22 - Invalid argument).
[W socket.cpp:663] [c10d] The client socket has failed to connect to [xe9680node30]:49258 (errno: 22 - Invalid argument).
| distributed init (rank 5): env://
[W socket.cpp:663] [c10d] The client socket has failed to connect to [xe9680node30]:49258 (errno: 22 - Invalid argument).
[W socket.cpp:663] [c10d] The client socket has failed to connect to [xe9680node30]:49258 (errno: 22 - Invalid argument).
| distributed init (rank 0): env://
| distributed init (rank 7): env://
| distributed init (rank 1): env://
| distributed init (rank 2): env://
| distributed init (rank 8): env://
| distributed init (rank 4): env://
| distributed init (rank 10): env://
| distributed init (rank 6): env://
| distributed init (rank 14): env://
| distributed init (rank 12): env://
| distributed init (rank 9): env://
| distributed init (rank 11): env://
| distributed init (rank 13): env://
| distributed init (rank 15): env://
:::MLLOG {"namespace": "", "time_ms": 1696359828528, "event_type": "POINT_IN_TIME", "key": "submission_benchmark", "value": "ssd", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 352}}
:::MLLOG {"namespace": "", "time_ms": 1696359828528, "event_type": "POINT_IN_TIME", "key": "submission_org", "value": "Dell", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 352}}
:::MLLOG {"namespace": "", "time_ms": 1696359828528, "event_type": "POINT_IN_TIME", "key": "submission_division", "value": "closed", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 352}}
:::MLLOG {"namespace": "", "time_ms": 1696359828528, "event_type": "POINT_IN_TIME", "key": "submission_status", "value": "onprem", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 352}}
:::MLLOG {"namespace": "", "time_ms": 1696359828528, "event_type": "POINT_IN_TIME", "key": "submission_platform", "value": "2xXE9680x8H100-SXM-80GB", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 352}}
:::MLLOG {"namespace": "", "time_ms": 1696359828529, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 353}}
:::MLLOG {"namespace": "", "time_ms": 1696359828535, "event_type": "POINT_IN_TIME", "key": "seed", "value": 2895298059, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 368}}
:::MLLOG {"namespace": "", "time_ms": 1696359828559, "event_type": "POINT_IN_TIME", "key": "seed", "value": 2895298061, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 368}}
:::MLLOG {"namespace": "", "time_ms": 1696359828559, "event_type": "POINT_IN_TIME", "key": "seed", "value": 2895298063, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 368}}
:::MLLOG {"namespace": "", "time_ms": 1696359828559, "event_type": "POINT_IN_TIME", "key": "seed", "value": 2895298058, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 368}}
:::MLLOG {"namespace": "", "time_ms": 1696359828559, "event_type": "POINT_IN_TIME", "key": "local_batch_size", "value": 16, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 371}}
:::MLLOG {"namespace": "", "time_ms": 1696359828559, "event_type": "POINT_IN_TIME", "key": "global_batch_size", "value": 256, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 372}}
:::MLLOG {"namespace": "", "time_ms": 1696359828559, "event_type": "POINT_IN_TIME", "key": "epoch_count", "value": 6, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 373}}
:::MLLOG {"namespace": "", "time_ms": 1696359828559, "event_type": "POINT_IN_TIME", "key": "first_epoch_num", "value": 0, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 374}}
:::MLLOG {"namespace": "", "time_ms": 1696359828559, "event_type": "POINT_IN_TIME", "key": "seed", "value": 2895298064, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 368}}
Namespace(backbone='resnext50_32x4d', trainable_backbone_layers=3, sync_bn=False, data_layout='channels_last', amp=True, async_coco=True, async_coco_check_freq=20, num_eval_ranks=16, dataset='openimages-mlperf', dataset_path='/datasets/open-images-v6', num_classes=None, train_data_path=None, train_annotations_file=None, val_data_path=None, val_annotations_file=None, image_size=[800, 800], data_augmentation='hflip', epochs=6, max_iters_per_epoch=None, max_eval_iters_per_epoch=None, start_epoch=0, output_dir=None, target_map=0.34, resume='', pretrained=False, batch_size=16, eval_batch_size=16, lr=8.5e-05, warmup_epochs=0, warmup_factor=0.001, workers=4, print_freq=20, eval_print_freq=20, test_only=False, seed=2895298058, device='cuda', cocoeval='nvidia', coco_threads=8, world_size=16, dist_url='env://', frozen_bn_opt=True, frozen_bn_fp16=True, jit=True, cuda_graphs=True, cuda_graphs_eval=False, cls_head_pad=True, reg_head_pad=True, cuda_graphs_syn=True, model_warmup_epochs=16, master_weights=True, dali=True, dali_matched_idxs=True, dali_eval=True, dali_eval_cache=False, dali_prefetch_queue_depth=2, dali_cpu_decode=True, dali_cmn=0, dali_cmn_hint=0, dali_decoder_hint_height=7360, dali_decoder_hint_width=7360, dali_decoder_hw_load=0.65, dali_input_batch_multiplier=1, dali_eval_cmn_hint=0, dali_eval_decoder_hint_height=0, dali_eval_decoder_hint_width=0, dali_eval_decoder_hw_load=0.65, dali_eval_input_batch_multiplier=1, dali_sync=False, apex_adam=True, apex_focal_loss=True, apex_backbone_fusion=True, apex_head_fusion=True, broadcast_buffers=False, fp16_allreduce=False, ddp_bucket_sz=25, ddp_first_bucket_sz=None, no_gradient_as_bucket_view=False, max_boxes=1000, cudnn_bench=False, deterministic=False, not_graphed_prologues=False, metric_loss=False, syn_dataset=False, sync_after_graph_replay=False, allreduce_barrier=False, skip_eval=False, cuda_profiler=False, cuda_profiler_eval=False, cuda_profiler_start=-1, cuda_profiler_stop=-1, power_benchmark=False, power_sustain_time=600, rank=0, gpu=0, distributed=True, dist_back:::MLLOG {"namespace": "", "time_ms": 1696359828567, "event_type": "POINT_IN_TIME", "key": "seed", "value": 2895298066, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 368}}
:::MLLOG {"namespace": "", "time_ms": 1696359828567, "event_type": "POINT_IN_TIME", "key": "seed", "value": 2895298067, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 368}}
:::MLLOG {"namespace": "", "time_ms": 1696359828567, "event_type": "POINT_IN_TIME", "key": "seed", "value": 2895298068, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 368}}
:::MLLOG {"namespace": "", "time_ms": 1696359828567, "event_type": "POINT_IN_TIME", "key": "seed", "value": 2895298069, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 368}}
:::MLLOG {"namespace": "", "time_ms": 1696359828567, "event_type": "POINT_IN_TIME", "key": "seed", "value": 2895298070, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 368}}
:::MLLOG {"namespace": "", "time_ms": 1696359828567, "event_type": "POINT_IN_TIME", "key": "seed", "value": 2895298071, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 368}}
:::MLLOG {"namespace": "", "time_ms": 1696359828567, "event_type": "POINT_IN_TIME", "key": "seed", "value": 2895298072, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 368}}
:::MLLOG {"namespace": "", "time_ms": 1696359828567, "event_type": "POINT_IN_TIME", "key": "seed", "value": 2895298073, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 368}}
end='nccl', ranks=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], num_train_ranks=16, train_ranks=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], eval_ranks=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], train_rank=0, eval_rank=0)
Getting dataset information
:::MLLOG {"namespace": "", "time_ms": 1696359828559, "event_type": "POINT_IN_TIME", "key": "seed", "value": 2895298065, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 368}}
Creating model
:::MLLOG {"namespace": "", "time_ms": 1696359828559, "event_type": "POINT_IN_TIME", "key": "seed", "value": 2895298062, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 368}}
:::MLLOG {"namespace": "", "time_ms": 1696359828559, "event_type": "POINT_IN_TIME", "key": "seed", "value": 2895298060, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 368}}
:::MLLOG {"namespace": "", "time_ms": 1696359828567, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 209, "tensor": "module.backbone.fpn.extra_blocks.p6.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696359828595, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 211, "tensor": "module.backbone.fpn.extra_blocks.p6.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1696359828595, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 209, "tensor": "module.backbone.fpn.extra_blocks.p7.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696359828598, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 211, "tensor": "module.backbone.fpn.extra_blocks.p7.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1696359828731, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696359828731, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer1.0.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696359828731, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer1.0.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696359828731, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer1.0.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696359828731, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer1.0.downsample.0.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696359828732, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer1.1.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696359828732, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer1.1.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696359828732, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer1.1.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696359828732, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer1.2.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696359828732, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer1.2.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696359828732, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer1.2.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696359828733, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.0.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696359828733, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.0.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696359828733, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.0.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696359828734, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.0.downsample.0.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696359828734, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.1.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696359828735, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.1.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696359828735, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.1.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696359828736, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.2.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696359828736, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.2.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696359828737, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.2.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696359828737, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.3.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696359828738, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.3.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696359828738, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.3.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696359828739, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.0.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696359828740, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.0.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696359828740, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.0.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696359828743, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.0.downsample.0.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696359828745, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.1.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696359828747, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.1.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696359828748, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.1.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696359828750, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.2.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696359828752, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.2.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696359828753, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.2.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696359828755, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.3.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696359828757, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.3.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696359828758, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.3.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696359828760, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.4.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696359828762, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.4.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696359828763, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.4.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696359828765, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.5.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696359828767, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.5.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696359828768, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.5.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696359828770, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer4.0.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696359828775, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer4.0.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696359828776, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer4.0.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696359828785, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer4.0.downsample.0.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696359828794, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer4.1.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696359828802, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer4.1.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696359828804, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer4.1.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696359828813, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer4.2.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696359828822, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer4.2.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696359828823, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer4.2.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696359828925, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 108, "tensor": "module.backbone.fpn.inner_blocks.0.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696359828926, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 110, "tensor": "module.backbone.fpn.inner_blocks.0.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1696359828926, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 108, "tensor": "module.backbone.fpn.inner_blocks.1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696359828927, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 110, "tensor": "module.backbone.fpn.inner_blocks.1.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1696359828927, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 108, "tensor": "module.backbone.fpn.inner_blocks.2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696359828930, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 110, "tensor": "module.backbone.fpn.inner_blocks.2.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1696359828930, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 108, "tensor": "module.backbone.fpn.layer_blocks.0.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696359828932, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 110, "tensor": "module.backbone.fpn.layer_blocks.0.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1696359828932, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 108, "tensor": "module.backbone.fpn.layer_blocks.1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696359828935, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 110, "tensor": "module.backbone.fpn.layer_blocks.1.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1696359828935, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 108, "tensor": "module.backbone.fpn.layer_blocks.2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696359828937, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 110, "tensor": "module.backbone.fpn.layer_blocks.2.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1696359828951, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 142, "tensor": "module.head.classification_head.conv.0.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696359828954, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 144, "tensor": "module.head.classification_head.conv.0.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1696359828954, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 142, "tensor": "module.head.classification_head.conv.2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696359828956, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 144, "tensor": "module.head.classification_head.conv.2.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1696359828956, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 142, "tensor": "module.head.classification_head.conv.4.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696359828959, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 144, "tensor": "module.head.classification_head.conv.4.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1696359828959, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 142, "tensor": "module.head.classification_head.conv.6.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696359828961, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 144, "tensor": "module.head.classification_head.conv.6.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1696359828982, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 148, "tensor": "module.head.classification_head.cls_logits.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696359829005, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 150, "tensor": "module.head.classification_head.cls_logits.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1696359829015, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 317, "tensor": "module.head.regression_head.bbox_reg.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696359829016, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 319, "tensor": "module.head.regression_head.bbox_reg.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1696359829016, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 324, "tensor": "module.head.regression_head.conv.0.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696359829019, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 326, "tensor": "module.head.regression_head.conv.0.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1696359829019, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 324, "tensor": "module.head.regression_head.conv.2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696359829021, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 326, "tensor": "module.head.regression_head.conv.2.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1696359829021, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 324, "tensor": "module.head.regression_head.conv.4.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696359829024, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 326, "tensor": "module.head.regression_head.conv.4.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1696359829024, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 324, "tensor": "module.head.regression_head.conv.6.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696359829027, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 326, "tensor": "module.head.regression_head.conv.6.bias"}}
Casting convolutional layers to half
/usr/local/lib/python3.10/dist-packages/apex/optimizers/fused_adam.py:112: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  self._dummy_overflow_buf = torch.cuda.IntTensor([0])
/usr/local/lib/python3.10/dist-packages/apex/optimizers/fused_adam.py:112: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  self._dummy_overflow_buf = torch.cuda.IntTensor([0])
/usr/local/lib/python3.10/dist-packages/apex/optimizers/fused_adam.py:112: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  self._dummy_overflow_buf = torch.cuda.IntTensor([0])
/usr/local/lib/python3.10/dist-packages/apex/optimizers/fused_adam.py:112: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  self._dummy_overflow_buf = torch.cuda.IntTensor([0])
/usr/local/lib/python3.10/dist-packages/apex/optimizers/fused_adam.py:112: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  self._dummy_overflow_buf = torch.cuda.IntTensor([0])
/usr/local/lib/python3.10/dist-packages/apex/optimizers/fused_adam.py:112: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  self._dummy_overflow_buf = torch.cuda.IntTensor([0])
/usr/local/lib/python3.10/dist-packages/apex/optimizers/fused_adam.py:112: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  self._dummy_overflow_buf = torch.cuda.IntTensor([0])
:::MLLOG {"namespace": "", "time_ms": 1696359829103, "event_type": "POINT_IN_TIME", "key": "opt_name", "value": "adam", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 450}}
:::MLLOG {"namespace": "", "time_ms": 1696359829103, "event_type": "POINT_IN_TIME", "key": "opt_base_learning_rate", "value": 8.5e-05, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 451}}
:::MLLOG {"namespace": "", "time_ms": 1696359829103, "event_type": "POINT_IN_TIME", "key": "opt_weight_decay", "value": 0, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 452}}
:::MLLOG {"namespace": "", "time_ms": 1696359829103, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_warmup_epochs", "value": 0, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 453}}
:::MLLOG {"namespace": "", "time_ms": 1696359829103, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_warmup_factor", "value": 0.001, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 454}}
:::MLLOG {"namespace": "", "time_ms": 1696359829103, "event_type": "POINT_IN_TIME", "key": "gradient_accumulation_steps", "value": 1, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 455}}
/usr/local/lib/python3.10/dist-packages/apex/optimizers/fused_adam.py:112: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  self._dummy_overflow_buf = torch.cuda.IntTensor([0])
/usr/local/lib/python3.10/dist-packages/apex/optimizers/fused_adam.py:112: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  self._dummy_overflow_buf = torch.cuda.IntTensor([0])
/usr/local/lib/python3.10/dist-packages/apex/optimizers/fused_adam.py:112: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  self._dummy_overflow_buf = torch.cuda.IntTensor([0])
/usr/local/lib/python3.10/dist-packages/apex/optimizers/fused_adam.py:112: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  self._dummy_overflow_buf = torch.cuda.IntTensor([0])
/usr/local/lib/python3.10/dist-packages/apex/optimizers/fused_adam.py:112: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  self._dummy_overflow_buf = torch.cuda.IntTensor([0])
/usr/local/lib/python3.10/dist-packages/apex/optimizers/fused_adam.py:112: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  self._dummy_overflow_buf = torch.cuda.IntTensor([0])
/usr/local/lib/python3.10/dist-packages/apex/optimizers/fused_adam.py:112: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  self._dummy_overflow_buf = torch.cuda.IntTensor([0])
/usr/local/lib/python3.10/dist-packages/apex/optimizers/fused_adam.py:112: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  self._dummy_overflow_buf = torch.cuda.IntTensor([0])
/usr/local/lib/python3.10/dist-packages/apex/optimizers/fused_adam.py:112: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  self._dummy_overflow_buf = torch.cuda.IntTensor([0])
/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3516.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3516.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3516.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3516.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3516.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3516.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3516.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3516.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
Model eval warmup
/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3516.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3516.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3516.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3516.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3516.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3516.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3516.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3516.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/workspace/ssd/model/jit_fn.py:40: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  bn_relu_out, relu_mask = fwd_bn_relu_jit(input, scale, bias)
/workspace/ssd/model/jit_fn.py:40: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  bn_relu_out, relu_mask = fwd_bn_relu_jit(input, scale, bias)
/workspace/ssd/model/jit_fn.py:40: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  bn_relu_out, relu_mask = fwd_bn_relu_jit(input, scale, bias)
/workspace/ssd/model/jit_fn.py:40: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  bn_relu_out, relu_mask = fwd_bn_relu_jit(input, scale, bias)
/workspace/ssd/model/jit_fn.py:40: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  bn_relu_out, relu_mask = fwd_bn_relu_jit(input, scale, bias)
/workspace/ssd/model/jit_fn.py:40: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  bn_relu_out, relu_mask = fwd_bn_relu_jit(input, scale, bias)
/workspace/ssd/model/jit_fn.py:40: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  bn_relu_out, relu_mask = fwd_bn_relu_jit(input, scale, bias)
/workspace/ssd/model/jit_fn.py:40: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  bn_relu_out, relu_mask = fwd_bn_relu_jit(input, scale, bias)
/workspace/ssd/model/jit_fn.py:40: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  bn_relu_out, relu_mask = fwd_bn_relu_jit(input, scale, bias)
/workspace/ssd/model/jit_fn.py:40: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  bn_relu_out, relu_mask = fwd_bn_relu_jit(input, scale, bias)
/workspace/ssd/model/jit_fn.py:40: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  bn_relu_out, relu_mask = fwd_bn_relu_jit(input, scale, bias)
/workspace/ssd/model/jit_fn.py:40: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  bn_relu_out, relu_mask = fwd_bn_relu_jit(input, scale, bias)
/workspace/ssd/model/jit_fn.py:40: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  bn_relu_out, relu_mask = fwd_bn_relu_jit(input, scale, bias)
/workspace/ssd/model/jit_fn.py:40: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  bn_relu_out, relu_mask = fwd_bn_relu_jit(input, scale, bias)
/workspace/ssd/model/jit_fn.py:40: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  bn_relu_out, relu_mask = fwd_bn_relu_jit(input, scale, bias)
/workspace/ssd/model/jit_fn.py:40: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  bn_relu_out, relu_mask = fwd_bn_relu_jit(input, scale, bias)
Time: 45.561065673828125 sec
Creating Dali training dataloader
Creating Dali eval dataloader
CUDA graph capture
/usr/local/lib/python3.10/dist-packages/torch/cuda/amp/grad_scaler.py:378: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/cuda/amp/grad_scaler.py:378: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/cuda/amp/grad_scaler.py:378: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/cuda/amp/grad_scaler.py:378: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/cuda/amp/grad_scaler.py:378: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/cuda/amp/grad_scaler.py:378: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/cuda/amp/grad_scaler.py:378: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/cuda/amp/grad_scaler.py:378: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/cuda/amp/grad_scaler.py:378: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/cuda/amp/grad_scaler.py:378: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/cuda/amp/grad_scaler.py:378: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/cuda/amp/grad_scaler.py:378: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/cuda/amp/grad_scaler.py:378: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/cuda/amp/grad_scaler.py:378: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/cuda/amp/grad_scaler.py:378: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/cuda/amp/grad_scaler.py:378: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/cuda/graphs.py:75: UserWarning: Attempting to start graph capture but NCCL ProcessGroup(s) have remaining enqueued work. Waiting for enqueued work to finish... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/cuda/CUDAGraph.cpp:73.)
  super().capture_begin()
/usr/local/lib/python3.10/dist-packages/torch/cuda/graphs.py:75: UserWarning: Attempting to start graph capture but NCCL ProcessGroup(s) have remaining enqueued work. Waiting for enqueued work to finish... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/cuda/CUDAGraph.cpp:73.)
  super().capture_begin()
/usr/local/lib/python3.10/dist-packages/torch/cuda/graphs.py:75: UserWarning: Attempting to start graph capture but NCCL ProcessGroup(s) have remaining enqueued work. Waiting for enqueued work to finish... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/cuda/CUDAGraph.cpp:73.)
  super().capture_begin()
/usr/local/lib/python3.10/dist-packages/torch/cuda/graphs.py:75: UserWarning: Attempting to start graph capture but NCCL ProcessGroup(s) have remaining enqueued work. Waiting for enqueued work to finish... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/cuda/CUDAGraph.cpp:73.)
  super().capture_begin()
/usr/local/lib/python3.10/dist-packages/torch/cuda/graphs.py:75: UserWarning: Attempting to start graph capture but NCCL ProcessGroup(s) have remaining enqueued work. Waiting for enqueued work to finish... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/cuda/CUDAGraph.cpp:73.)
  super().capture_begin()
/usr/local/lib/python3.10/dist-packages/torch/cuda/graphs.py:75: UserWarning: Attempting to start graph capture but NCCL ProcessGroup(s) have remaining enqueued work. Waiting for enqueued work to finish... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/cuda/CUDAGraph.cpp:73.)
  super().capture_begin()
/usr/local/lib/python3.10/dist-packages/torch/cuda/graphs.py:75: UserWarning: Attempting to start graph capture but NCCL ProcessGroup(s) have remaining enqueued work. Waiting for enqueued work to finish... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/cuda/CUDAGraph.cpp:73.)
  super().capture_begin()
/usr/local/lib/python3.10/dist-packages/torch/cuda/graphs.py:75: UserWarning: Attempting to start graph capture but NCCL ProcessGroup(s) have remaining enqueued work. Waiting for enqueued work to finish... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/cuda/CUDAGraph.cpp:73.)
  super().capture_begin()
/usr/local/lib/python3.10/dist-packages/torch/cuda/graphs.py:75: UserWarning: Attempting to start graph capture but NCCL ProcessGroup(s) have remaining enqueued work. Waiting for enqueued work to finish... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/cuda/CUDAGraph.cpp:73.)
  super().capture_begin()
/usr/local/lib/python3.10/dist-packages/torch/cuda/graphs.py:75: UserWarning: Attempting to start graph capture but NCCL ProcessGroup(s) have remaining enqueued work. Waiting for enqueued work to finish... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/cuda/CUDAGraph.cpp:73.)
  super().capture_begin()
/usr/local/lib/python3.10/dist-packages/torch/cuda/graphs.py:75: UserWarning: Attempting to start graph capture but NCCL ProcessGroup(s) have remaining enqueued work. Waiting for enqueued work to finish... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/cuda/CUDAGraph.cpp:73.)
  super().capture_begin()
/usr/local/lib/python3.10/dist-packages/torch/cuda/graphs.py:75: UserWarning: Attempting to start graph capture but NCCL ProcessGroup(s) have remaining enqueued work. Waiting for enqueued work to finish... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/cuda/CUDAGraph.cpp:73.)
  super().capture_begin()
/usr/local/lib/python3.10/dist-packages/torch/cuda/graphs.py:75: UserWarning: Attempting to start graph capture but NCCL ProcessGroup(s) have remaining enqueued work. Waiting for enqueued work to finish... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/cuda/CUDAGraph.cpp:73.)
  super().capture_begin()
/usr/local/lib/python3.10/dist-packages/torch/cuda/graphs.py:75: UserWarning: Attempting to start graph capture but NCCL ProcessGroup(s) have remaining enqueued work. Waiting for enqueued work to finish... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/cuda/CUDAGraph.cpp:73.)
  super().capture_begin()
/usr/local/lib/python3.10/dist-packages/torch/cuda/graphs.py:75: UserWarning: Attempting to start graph capture but NCCL ProcessGroup(s) have remaining enqueued work. Waiting for enqueued work to finish... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/cuda/CUDAGraph.cpp:73.)
  super().capture_begin()
/usr/local/lib/python3.10/dist-packages/torch/cuda/graphs.py:75: UserWarning: Attempting to start graph capture but NCCL ProcessGroup(s) have remaining enqueued work. Waiting for enqueued work to finish... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/cuda/CUDAGraph.cpp:73.)
  super().capture_begin()
:::MLLOG {"namespace": "", "time_ms": 1696359899141, "event_type": "INTERVAL_END", "key": "init_stop", "value": null, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 571}}
:::MLLOG {"namespace": "", "time_ms": 1696359899142, "event_type": "INTERVAL_START", "key": "run_start", "value": null, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 575}}
:::MLLOG {"namespace": "", "time_ms": 1696359899142, "event_type": "POINT_IN_TIME", "key": "train_samples", "value": 4572, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 623}}
:::MLLOG {"namespace": "", "time_ms": 1696359899142, "event_type": "POINT_IN_TIME", "key": "eval_samples", "value": 97, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 626}}
Running ...
:::MLLOG {"namespace": "", "time_ms": 1696359899143, "event_type": "INTERVAL_START", "key": "epoch_start", "value": 0, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 158, "epoch_num": 0}}
Epoch: [0]  [   0/4572]  eta: 0:04:24    time: 0.0578  data: 0.0003  max mem: 10413
Epoch: [0]  [  20/4572]  eta: 0:04:28    time: 0.0591  data: 0.0525  max mem: 10413
Epoch: [0]  [  40/4572]  eta: 0:04:27    time: 0.0590  data: 0.0525  max mem: 10413
Epoch: [0]  [  60/4572]  eta: 0:04:25    time: 0.0587  data: 0.0522  max mem: 10413
Epoch: [0]  [  80/4572]  eta: 0:04:24    time: 0.0588  data: 0.0523  max mem: 10413
Epoch: [0]  [ 100/4572]  eta: 0:04:30    time: 0.0668  data: 0.0604  max mem: 10413
Epoch: [0]  [ 120/4572]  eta: 0:04:28    time: 0.0596  data: 0.0531  max mem: 10413
Epoch: [0]  [ 140/4572]  eta: 0:04:31    time: 0.0672  data: 0.0602  max mem: 10413
Epoch: [0]  [ 160/4572]  eta: 0:04:30    time: 0.0614  data: 0.0549  max mem: 10413
Epoch: [0]  [ 180/4572]  eta: 0:04:28    time: 0.0595  data: 0.0530  max mem: 10413
Epoch: [0]  [ 200/4572]  eta: 0:04:26    time: 0.0589  data: 0.0524  max mem: 10413
Epoch: [0]  [ 220/4572]  eta: 0:04:24    time: 0.0587  data: 0.0522  max mem: 10413
Epoch: [0]  [ 240/4572]  eta: 0:04:22    time: 0.0586  data: 0.0521  max mem: 10413
Epoch: [0]  [ 260/4572]  eta: 0:04:20    time: 0.0588  data: 0.0523  max mem: 10413
Epoch: [0]  [ 280/4572]  eta: 0:04:18    time: 0.0589  data: 0.0525  max mem: 10413
Epoch: [0]  [ 300/4572]  eta: 0:04:17    time: 0.0590  data: 0.0525  max mem: 10413
Epoch: [0]  [ 320/4572]  eta: 0:04:15    time: 0.0591  data: 0.0526  max mem: 10413
Epoch: [0]  [ 340/4572]  eta: 0:04:14    time: 0.0590  data: 0.0524  max mem: 10413
Epoch: [0]  [ 360/4572]  eta: 0:04:12    time: 0.0591  data: 0.0526  max mem: 10413
Epoch: [0]  [ 380/4572]  eta: 0:04:11    time: 0.0591  data: 0.0525  max mem: 10413
Epoch: [0]  [ 400/4572]  eta: 0:04:10    time: 0.0592  data: 0.0526  max mem: 10413
Epoch: [0]  [ 420/4572]  eta: 0:04:09    time: 0.0638  data: 0.0573  max mem: 10413
Epoch: [0]  [ 440/4572]  eta: 0:04:08    time: 0.0590  data: 0.0524  max mem: 10413
Epoch: [0]  [ 460/4572]  eta: 0:04:06    time: 0.0592  data: 0.0527  max mem: 10413
Epoch: [0]  [ 480/4572]  eta: 0:04:05    time: 0.0591  data: 0.0526  max mem: 10413
Epoch: [0]  [ 500/4572]  eta: 0:04:04    time: 0.0623  data: 0.0558  max mem: 10413
Epoch: [0]  [ 520/4572]  eta: 0:04:03    time: 0.0589  data: 0.0523  max mem: 10413
Epoch: [0]  [ 540/4572]  eta: 0:04:01    time: 0.0591  data: 0.0525  max mem: 10413
Epoch: [0]  [ 560/4572]  eta: 0:04:00    time: 0.0592  data: 0.0526  max mem: 10413
Epoch: [0]  [ 580/4572]  eta: 0:03:59    time: 0.0591  data: 0.0526  max mem: 10413
Epoch: [0]  [ 600/4572]  eta: 0:03:59    time: 0.0735  data: 0.0572  max mem: 10413
Epoch: [0]  [ 620/4572]  eta: 0:03:58    time: 0.0590  data: 0.0524  max mem: 10413
Epoch: [0]  [ 640/4572]  eta: 0:03:57    time: 0.0591  data: 0.0526  max mem: 10413
Epoch: [0]  [ 660/4572]  eta: 0:03:55    time: 0.0591  data: 0.0526  max mem: 10413
Epoch: [0]  [ 680/4572]  eta: 0:03:54    time: 0.0638  data: 0.0573  max mem: 10413
Epoch: [0]  [ 700/4572]  eta: 0:03:53    time: 0.0591  data: 0.0525  max mem: 10413
Epoch: [0]  [ 720/4572]  eta: 0:03:53    time: 0.0664  data: 0.0599  max mem: 10413
Epoch: [0]  [ 740/4572]  eta: 0:03:51    time: 0.0593  data: 0.0528  max mem: 10413
Epoch: [0]  [ 760/4572]  eta: 0:03:50    time: 0.0593  data: 0.0527  max mem: 10413
Epoch: [0]  [ 780/4572]  eta: 0:03:49    time: 0.0650  data: 0.0583  max mem: 10413
Epoch: [0]  [ 800/4572]  eta: 0:03:48    time: 0.0666  data: 0.0601  max mem: 10413
Epoch: [0]  [ 820/4572]  eta: 0:03:47    time: 0.0592  data: 0.0526  max mem: 10413
Epoch: [0]  [ 840/4572]  eta: 0:03:46    time: 0.0591  data: 0.0526  max mem: 10413
Epoch: [0]  [ 860/4572]  eta: 0:03:45    time: 0.0703  data: 0.0636  max mem: 10413
Epoch: [0]  [ 880/4572]  eta: 0:03:44    time: 0.0642  data: 0.0577  max mem: 10413
Epoch: [0]  [ 900/4572]  eta: 0:03:43    time: 0.0631  data: 0.0566  max mem: 10413
Epoch: [0]  [ 920/4572]  eta: 0:03:42    time: 0.0593  data: 0.0528  max mem: 10413
Epoch: [0]  [ 940/4572]  eta: 0:03:42    time: 0.0695  data: 0.0630  max mem: 10413
Epoch: [0]  [ 960/4572]  eta: 0:03:40    time: 0.0594  data: 0.0528  max mem: 10413
Epoch: [0]  [ 980/4572]  eta: 0:03:39    time: 0.0600  data: 0.0533  max mem: 10413
Epoch: [0]  [1000/4572]  eta: 0:03:38    time: 0.0675  data: 0.0609  max mem: 10413
Epoch: [0]  [1020/4572]  eta: 0:03:37    time: 0.0596  data: 0.0531  max mem: 10413
Epoch: [0]  [1040/4572]  eta: 0:03:35    time: 0.0593  data: 0.0527  max mem: 10413
Epoch: [0]  [1060/4572]  eta: 0:03:34    time: 0.0593  data: 0.0528  max mem: 10413
Epoch: [0]  [1080/4572]  eta: 0:03:33    time: 0.0595  data: 0.0530  max mem: 10413
Epoch: [0]  [1100/4572]  eta: 0:03:31    time: 0.0594  data: 0.0529  max mem: 10413
Epoch: [0]  [1120/4572]  eta: 0:03:30    time: 0.0592  data: 0.0525  max mem: 10413
Epoch: [0]  [1140/4572]  eta: 0:03:29    time: 0.0618  data: 0.0553  max mem: 10413
Epoch: [0]  [1160/4572]  eta: 0:03:28    time: 0.0592  data: 0.0527  max mem: 10413
Epoch: [0]  [1180/4572]  eta: 0:03:27    time: 0.0697  data: 0.0632  max mem: 10413
Epoch: [0]  [1200/4572]  eta: 0:03:26    time: 0.0591  data: 0.0526  max mem: 10413
Epoch: [0]  [1220/4572]  eta: 0:03:24    time: 0.0592  data: 0.0526  max mem: 10413
Epoch: [0]  [1240/4572]  eta: 0:03:23    time: 0.0592  data: 0.0526  max mem: 10413
Epoch: [0]  [1260/4572]  eta: 0:03:22    time: 0.0592  data: 0.0526  max mem: 10413
Epoch: [0]  [1280/4572]  eta: 0:03:20    time: 0.0593  data: 0.0528  max mem: 10413
Epoch: [0]  [1300/4572]  eta: 0:03:19    time: 0.0592  data: 0.0527  max mem: 10413
Epoch: [0]  [1320/4572]  eta: 0:03:18    time: 0.0593  data: 0.0527  max mem: 10413
Epoch: [0]  [1340/4572]  eta: 0:03:16    time: 0.0623  data: 0.0557  max mem: 10413
Epoch: [0]  [1360/4572]  eta: 0:03:15    time: 0.0593  data: 0.0527  max mem: 10413
Epoch: [0]  [1380/4572]  eta: 0:03:14    time: 0.0592  data: 0.0525  max mem: 10413
Epoch: [0]  [1400/4572]  eta: 0:03:13    time: 0.0594  data: 0.0529  max mem: 10413
Epoch: [0]  [1420/4572]  eta: 0:03:11    time: 0.0592  data: 0.0526  max mem: 10413
Epoch: [0]  [1440/4572]  eta: 0:03:10    time: 0.0591  data: 0.0526  max mem: 10413
Corrupt JPEG data: premature end of data segment
Epoch: [0]  [1460/4572]  eta: 0:03:09    time: 0.0604  data: 0.0540  max mem: 10413
Epoch: [0]  [1480/4572]  eta: 0:03:08    time: 0.0591  data: 0.0526  max mem: 10413
Epoch: [0]  [1500/4572]  eta: 0:03:07    time: 0.0731  data: 0.0666  max mem: 10413
Epoch: [0]  [1520/4572]  eta: 0:03:05    time: 0.0590  data: 0.0525  max mem: 10413
Epoch: [0]  [1540/4572]  eta: 0:03:04    time: 0.0604  data: 0.0537  max mem: 10413
Epoch: [0]  [1560/4572]  eta: 0:03:03    time: 0.0591  data: 0.0526  max mem: 10413
Epoch: [0]  [1580/4572]  eta: 0:03:02    time: 0.0592  data: 0.0527  max mem: 10413
Epoch: [0]  [1600/4572]  eta: 0:03:00    time: 0.0593  data: 0.0527  max mem: 10413
Epoch: [0]  [1620/4572]  eta: 0:02:59    time: 0.0592  data: 0.0527  max mem: 10413
Epoch: [0]  [1640/4572]  eta: 0:02:58    time: 0.0591  data: 0.0526  max mem: 10413
Epoch: [0]  [1660/4572]  eta: 0:02:57    time: 0.0597  data: 0.0532  max mem: 10413
Epoch: [0]  [1680/4572]  eta: 0:02:56    time: 0.0767  data: 0.0700  max mem: 10413
Epoch: [0]  [1700/4572]  eta: 0:02:55    time: 0.0592  data: 0.0527  max mem: 10413
Epoch: [0]  [1720/4572]  eta: 0:02:53    time: 0.0593  data: 0.0527  max mem: 10413
Epoch: [0]  [1740/4572]  eta: 0:02:53    time: 0.0728  data: 0.0663  max mem: 10413
Epoch: [0]  [1760/4572]  eta: 0:02:51    time: 0.0593  data: 0.0527  max mem: 10413
Epoch: [0]  [1780/4572]  eta: 0:02:50    time: 0.0593  data: 0.0527  max mem: 10413
Epoch: [0]  [1800/4572]  eta: 0:02:49    time: 0.0592  data: 0.0527  max mem: 10413
Epoch: [0]  [1820/4572]  eta: 0:02:47    time: 0.0619  data: 0.0554  max mem: 10413
Epoch: [0]  [1840/4572]  eta: 0:02:46    time: 0.0593  data: 0.0527  max mem: 10413
Epoch: [0]  [1860/4572]  eta: 0:02:45    time: 0.0592  data: 0.0526  max mem: 10413
Epoch: [0]  [1880/4572]  eta: 0:02:44    time: 0.0591  data: 0.0526  max mem: 10413
Epoch: [0]  [1900/4572]  eta: 0:02:43    time: 0.0771  data: 0.0704  max mem: 10413
Epoch: [0]  [1920/4572]  eta: 0:02:42    time: 0.0591  data: 0.0525  max mem: 10413
Epoch: [0]  [1940/4572]  eta: 0:02:40    time: 0.0592  data: 0.0527  max mem: 10413
Epoch: [0]  [1960/4572]  eta: 0:02:39    time: 0.0591  data: 0.0526  max mem: 10413
Epoch: [0]  [1980/4572]  eta: 0:02:38    time: 0.0591  data: 0.0525  max mem: 10413
Epoch: [0]  [2000/4572]  eta: 0:02:37    time: 0.0592  data: 0.0526  max mem: 10413
Epoch: [0]  [2020/4572]  eta: 0:02:35    time: 0.0591  data: 0.0525  max mem: 10413
Epoch: [0]  [2040/4572]  eta: 0:02:34    time: 0.0600  data: 0.0534  max mem: 10413
Epoch: [0]  [2060/4572]  eta: 0:02:33    time: 0.0592  data: 0.0526  max mem: 10413
Epoch: [0]  [2080/4572]  eta: 0:02:32    time: 0.0662  data: 0.0598  max mem: 10413
Epoch: [0]  [2100/4572]  eta: 0:02:30    time: 0.0589  data: 0.0524  max mem: 10413
Epoch: [0]  [2120/4572]  eta: 0:02:29    time: 0.0602  data: 0.0535  max mem: 10413
Epoch: [0]  [2140/4572]  eta: 0:02:28    time: 0.0591  data: 0.0526  max mem: 10413
Epoch: [0]  [2160/4572]  eta: 0:02:27    time: 0.0591  data: 0.0525  max mem: 10413
Epoch: [0]  [2180/4572]  eta: 0:02:25    time: 0.0591  data: 0.0525  max mem: 10413
Epoch: [0]  [2200/4572]  eta: 0:02:24    time: 0.0594  data: 0.0529  max mem: 10413
Epoch: [0]  [2220/4572]  eta: 0:02:23    time: 0.0590  data: 0.0524  max mem: 10413
Epoch: [0]  [2240/4572]  eta: 0:02:22    time: 0.0591  data: 0.0526  max mem: 10413
Epoch: [0]  [2260/4572]  eta: 0:02:20    time: 0.0591  data: 0.0526  max mem: 10413
Epoch: [0]  [2280/4572]  eta: 0:02:19    time: 0.0592  data: 0.0526  max mem: 10413
Epoch: [0]  [2300/4572]  eta: 0:02:18    time: 0.0593  data: 0.0528  max mem: 10413
Epoch: [0]  [2320/4572]  eta: 0:02:17    time: 0.0594  data: 0.0529  max mem: 10413
Epoch: [0]  [2340/4572]  eta: 0:02:15    time: 0.0592  data: 0.0527  max mem: 10413
Epoch: [0]  [2360/4572]  eta: 0:02:14    time: 0.0594  data: 0.0529  max mem: 10413
Epoch: [0]  [2380/4572]  eta: 0:02:13    time: 0.0591  data: 0.0526  max mem: 10413
Epoch: [0]  [2400/4572]  eta: 0:02:12    time: 0.0608  data: 0.0543  max mem: 10413
Epoch: [0]  [2420/4572]  eta: 0:02:10    time: 0.0591  data: 0.0525  max mem: 10413
Epoch: [0]  [2440/4572]  eta: 0:02:09    time: 0.0591  data: 0.0526  max mem: 10413
Epoch: [0]  [2460/4572]  eta: 0:02:08    time: 0.0764  data: 0.0698  max mem: 10413
Epoch: [0]  [2480/4572]  eta: 0:02:07    time: 0.0595  data: 0.0529  max mem: 10413
Epoch: [0]  [2500/4572]  eta: 0:02:06    time: 0.0709  data: 0.0644  max mem: 10413
Epoch: [0]  [2520/4572]  eta: 0:02:05    time: 0.0587  data: 0.0523  max mem: 10413
Epoch: [0]  [2540/4572]  eta: 0:02:03    time: 0.0609  data: 0.0542  max mem: 10413
Epoch: [0]  [2560/4572]  eta: 0:02:02    time: 0.0590  data: 0.0525  max mem: 10413
Epoch: [0]  [2580/4572]  eta: 0:02:01    time: 0.0592  data: 0.0527  max mem: 10413
Epoch: [0]  [2600/4572]  eta: 0:02:00    time: 0.0591  data: 0.0526  max mem: 10413
Epoch: [0]  [2620/4572]  eta: 0:01:58    time: 0.0590  data: 0.0524  max mem: 10413
Epoch: [0]  [2640/4572]  eta: 0:01:57    time: 0.0591  data: 0.0525  max mem: 10413
Epoch: [0]  [2660/4572]  eta: 0:01:56    time: 0.0770  data: 0.0704  max mem: 10413
Epoch: [0]  [2680/4572]  eta: 0:01:55    time: 0.0588  data: 0.0523  max mem: 10413
Epoch: [0]  [2700/4572]  eta: 0:01:54    time: 0.0590  data: 0.0525  max mem: 10413
Epoch: [0]  [2720/4572]  eta: 0:01:52    time: 0.0590  data: 0.0524  max mem: 10413
Epoch: [0]  [2740/4572]  eta: 0:01:51    time: 0.0589  data: 0.0524  max mem: 10413
Epoch: [0]  [2760/4572]  eta: 0:01:50    time: 0.0617  data: 0.0552  max mem: 10413
Epoch: [0]  [2780/4572]  eta: 0:01:49    time: 0.0589  data: 0.0524  max mem: 10413
Epoch: [0]  [2800/4572]  eta: 0:01:47    time: 0.0590  data: 0.0524  max mem: 10413
Epoch: [0]  [2820/4572]  eta: 0:01:46    time: 0.0591  data: 0.0526  max mem: 10413
Epoch: [0]  [2840/4572]  eta: 0:01:45    time: 0.0795  data: 0.0730  max mem: 10413
Epoch: [0]  [2860/4572]  eta: 0:01:44    time: 0.0747  data: 0.0683  max mem: 10413
Epoch: [0]  [2880/4572]  eta: 0:01:43    time: 0.0586  data: 0.0522  max mem: 10413
Epoch: [0]  [2900/4572]  eta: 0:01:42    time: 0.0586  data: 0.0521  max mem: 10413
Epoch: [0]  [2920/4572]  eta: 0:01:40    time: 0.0588  data: 0.0522  max mem: 10413
Epoch: [0]  [2940/4572]  eta: 0:01:39    time: 0.0589  data: 0.0524  max mem: 10413
Epoch: [0]  [2960/4572]  eta: 0:01:38    time: 0.0737  data: 0.0672  max mem: 10413
Epoch: [0]  [2980/4572]  eta: 0:01:37    time: 0.0594  data: 0.0529  max mem: 10413
Epoch: [0]  [3000/4572]  eta: 0:01:36    time: 0.0588  data: 0.0523  max mem: 10413
Epoch: [0]  [3020/4572]  eta: 0:01:35    time: 0.0730  data: 0.0522  max mem: 10413
Epoch: [0]  [3040/4572]  eta: 0:01:33    time: 0.0587  data: 0.0522  max mem: 10413
Epoch: [0]  [3060/4572]  eta: 0:01:32    time: 0.0588  data: 0.0523  max mem: 10413
Epoch: [0]  [3080/4572]  eta: 0:01:31    time: 0.0588  data: 0.0523  max mem: 10413
Epoch: [0]  [3100/4572]  eta: 0:01:30    time: 0.0738  data: 0.0673  max mem: 10413
Epoch: [0]  [3120/4572]  eta: 0:01:28    time: 0.0606  data: 0.0541  max mem: 10413
Epoch: [0]  [3140/4572]  eta: 0:01:27    time: 0.0588  data: 0.0538  max mem: 10413
Epoch: [0]  [3160/4572]  eta: 0:01:26    time: 0.0758  data: 0.0694  max mem: 10413
Epoch: [0]  [3180/4572]  eta: 0:01:25    time: 0.0587  data: 0.0522  max mem: 10413
Epoch: [0]  [3200/4572]  eta: 0:01:24    time: 0.0595  data: 0.0531  max mem: 10413
Epoch: [0]  [3220/4572]  eta: 0:01:22    time: 0.0586  data: 0.0522  max mem: 10413
Epoch: [0]  [3240/4572]  eta: 0:01:21    time: 0.0587  data: 0.0522  max mem: 10413
Epoch: [0]  [3260/4572]  eta: 0:01:20    time: 0.0587  data: 0.0522  max mem: 10413
Epoch: [0]  [3280/4572]  eta: 0:01:19    time: 0.0587  data: 0.0522  max mem: 10413
Epoch: [0]  [3300/4572]  eta: 0:01:17    time: 0.0586  data: 0.0522  max mem: 10413
Epoch: [0]  [3320/4572]  eta: 0:01:16    time: 0.0587  data: 0.0523  max mem: 10413
Epoch: [0]  [3340/4572]  eta: 0:01:15    time: 0.0587  data: 0.0522  max mem: 10413
Epoch: [0]  [3360/4572]  eta: 0:01:14    time: 0.0726  data: 0.0661  max mem: 10413
Epoch: [0]  [3380/4572]  eta: 0:01:12    time: 0.0586  data: 0.0522  max mem: 10413
Epoch: [0]  [3400/4572]  eta: 0:01:11    time: 0.0587  data: 0.0523  max mem: 10413
Epoch: [0]  [3420/4572]  eta: 0:01:10    time: 0.0586  data: 0.0521  max mem: 10413
Epoch: [0]  [3440/4572]  eta: 0:01:09    time: 0.0585  data: 0.0520  max mem: 10413
Epoch: [0]  [3460/4572]  eta: 0:01:08    time: 0.0608  data: 0.0543  max mem: 10413
Epoch: [0]  [3480/4572]  eta: 0:01:06    time: 0.0602  data: 0.0537  max mem: 10413
Epoch: [0]  [3500/4572]  eta: 0:01:05    time: 0.0586  data: 0.0522  max mem: 10413
Epoch: [0]  [3520/4572]  eta: 0:01:04    time: 0.0588  data: 0.0523  max mem: 10413
Epoch: [0]  [3540/4572]  eta: 0:01:03    time: 0.0591  data: 0.0526  max mem: 10413
Epoch: [0]  [3560/4572]  eta: 0:01:01    time: 0.0600  data: 0.0536  max mem: 10413
Epoch: [0]  [3580/4572]  eta: 0:01:00    time: 0.0586  data: 0.0522  max mem: 10413
Epoch: [0]  [3600/4572]  eta: 0:00:59    time: 0.0588  data: 0.0523  max mem: 10413
Epoch: [0]  [3620/4572]  eta: 0:00:58    time: 0.0585  data: 0.0521  max mem: 10413
Epoch: [0]  [3640/4572]  eta: 0:00:56    time: 0.0591  data: 0.0525  max mem: 10413
Epoch: [0]  [3660/4572]  eta: 0:00:55    time: 0.0587  data: 0.0522  max mem: 10413
Epoch: [0]  [3680/4572]  eta: 0:00:54    time: 0.0585  data: 0.0520  max mem: 10413
Epoch: [0]  [3700/4572]  eta: 0:00:53    time: 0.0586  data: 0.0522  max mem: 10413
Epoch: [0]  [3720/4572]  eta: 0:00:52    time: 0.0585  data: 0.0521  max mem: 10413
Epoch: [0]  [3740/4572]  eta: 0:00:50    time: 0.0588  data: 0.0538  max mem: 10413
Epoch: [0]  [3760/4572]  eta: 0:00:49    time: 0.0586  data: 0.0521  max mem: 10413
Epoch: [0]  [3780/4572]  eta: 0:00:48    time: 0.0586  data: 0.0521  max mem: 10413
Epoch: [0]  [3800/4572]  eta: 0:00:47    time: 0.0586  data: 0.0521  max mem: 10413
Epoch: [0]  [3820/4572]  eta: 0:00:45    time: 0.0591  data: 0.0527  max mem: 10413
Epoch: [0]  [3840/4572]  eta: 0:00:44    time: 0.0587  data: 0.0522  max mem: 10413
Epoch: [0]  [3860/4572]  eta: 0:00:43    time: 0.0588  data: 0.0522  max mem: 10413
Epoch: [0]  [3880/4572]  eta: 0:00:42    time: 0.0587  data: 0.0521  max mem: 10413
Epoch: [0]  [3900/4572]  eta: 0:00:40    time: 0.0595  data: 0.0521  max mem: 10413
Epoch: [0]  [3920/4572]  eta: 0:00:39    time: 0.0727  data: 0.0663  max mem: 10413
Epoch: [0]  [3940/4572]  eta: 0:00:38    time: 0.0586  data: 0.0521  max mem: 10413
Epoch: [0]  [3960/4572]  eta: 0:00:37    time: 0.0609  data: 0.0544  max mem: 10413
Epoch: [0]  [3980/4572]  eta: 0:00:36    time: 0.0616  data: 0.0550  max mem: 10413
Epoch: [0]  [4000/4572]  eta: 0:00:34    time: 0.0587  data: 0.0522  max mem: 10413
Epoch: [0]  [4020/4572]  eta: 0:00:33    time: 0.0596  data: 0.0532  max mem: 10413
Epoch: [0]  [4040/4572]  eta: 0:00:32    time: 0.0586  data: 0.0521  max mem: 10413
Epoch: [0]  [4060/4572]  eta: 0:00:31    time: 0.0585  data: 0.0521  max mem: 10413
Epoch: [0]  [4080/4572]  eta: 0:00:29    time: 0.0587  data: 0.0522  max mem: 10413
Epoch: [0]  [4100/4572]  eta: 0:00:28    time: 0.0592  data: 0.0528  max mem: 10413
Epoch: [0]  [4120/4572]  eta: 0:00:27    time: 0.0633  data: 0.0569  max mem: 10413
Epoch: [0]  [4140/4572]  eta: 0:00:26    time: 0.0586  data: 0.0521  max mem: 10413
Epoch: [0]  [4160/4572]  eta: 0:00:25    time: 0.0588  data: 0.0523  max mem: 10413
Epoch: [0]  [4180/4572]  eta: 0:00:23    time: 0.0585  data: 0.0521  max mem: 10413
Epoch: [0]  [4200/4572]  eta: 0:00:22    time: 0.0585  data: 0.0520  max mem: 10413
Epoch: [0]  [4220/4572]  eta: 0:00:21    time: 0.0587  data: 0.0522  max mem: 10413
Epoch: [0]  [4240/4572]  eta: 0:00:20    time: 0.0586  data: 0.0521  max mem: 10413
Epoch: [0]  [4260/4572]  eta: 0:00:18    time: 0.0632  data: 0.0567  max mem: 10413
Epoch: [0]  [4280/4572]  eta: 0:00:17    time: 0.0585  data: 0.0520  max mem: 10413
Epoch: [0]  [4300/4572]  eta: 0:00:16    time: 0.0587  data: 0.0522  max mem: 10413
Epoch: [0]  [4320/4572]  eta: 0:00:15    time: 0.0586  data: 0.0521  max mem: 10413
Epoch: [0]  [4340/4572]  eta: 0:00:14    time: 0.0585  data: 0.0520  max mem: 10413
Epoch: [0]  [4360/4572]  eta: 0:00:12    time: 0.0801  data: 0.0737  max mem: 10413
Epoch: [0]  [4380/4572]  eta: 0:00:11    time: 0.0586  data: 0.0521  max mem: 10413
Epoch: [0]  [4400/4572]  eta: 0:00:10    time: 0.0585  data: 0.0521  max mem: 10413
Epoch: [0]  [4420/4572]  eta: 0:00:09    time: 0.0585  data: 0.0521  max mem: 10413
Epoch: [0]  [4440/4572]  eta: 0:00:08    time: 0.0586  data: 0.0521  max mem: 10413
Epoch: [0]  [4460/4572]  eta: 0:00:06    time: 0.0586  data: 0.0520  max mem: 10413
Epoch: [0]  [4480/4572]  eta: 0:00:05    time: 0.0731  data: 0.0666  max mem: 10413
Epoch: [0]  [4500/4572]  eta: 0:00:04    time: 0.0586  data: 0.0521  max mem: 10413
Epoch: [0]  [4520/4572]  eta: 0:00:03    time: 0.0586  data: 0.0521  max mem: 10413
Epoch: [0]  [4540/4572]  eta: 0:00:01    time: 0.0586  data: 0.0521  max mem: 10413
Epoch: [0]  [4560/4572]  eta: 0:00:00    time: 0.0612  data: 0.0548  max mem: 10413
Epoch: [0]  [4571/4572]  eta: 0:00:00    time: 0.0585  data: 0.0521  max mem: 10413
Epoch: [0] Total time: 0:04:38 (0.0609 s / it)
:::MLLOG {"namespace": "", "time_ms": 1696360177650, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": 0, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 330, "epoch_num": 0}}
:::MLLOG {"namespace": "", "time_ms": 1696360177651, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 262.7653822791821}, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 334, "step": 1}}
:::MLLOG {"namespace": "", "time_ms": 1696360177651, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 344, "epoch_num": 1}}
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
Test:  [ 0/97]  eta: 0:00:18  model_time: 0.1924 (0.1924)  evaluator_time: 0.0017 (0.0017)  time: 0.1945  data: 0.0003  max mem: 10413
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
Test:  [20/97]  eta: 0:00:11  model_time: 0.1419 (0.1455)  evaluator_time: 0.0019 (0.0019)  time: 0.1458  data: 0.0006  max mem: 10413
Test:  [40/97]  eta: 0:00:08  model_time: 0.1432 (0.1442)  evaluator_time: 0.0019 (0.0020)  time: 0.1456  data: 0.0006  max mem: 10413
Test:  [60/97]  eta: 0:00:05  model_time: 0.1477 (0.1451)  evaluator_time: 0.0020 (0.0019)  time: 0.1496  data: 0.0006  max mem: 10413
Test:  [80/97]  eta: 0:00:02  model_time: 0.1439 (0.1446)  evaluator_time: 0.0021 (0.0020)  time: 0.1458  data: 0.0006  max mem: 10413
Test:  [96/97]  eta: 0:00:00  model_time: 0.1486 (0.1447)  evaluator_time: 0.0019 (0.0020)  time: 0.1479  data: 0.0006  max mem: 10413
Test: Total time: 0:00:14 (0.1474 s / it)
Averaged stats: model_time: 0.1486 (0.1471)  evaluator_time: 0.0019 (0.0020)
:::MLLOG {"namespace": "", "time_ms": 1696360192805, "event_type": "INTERVAL_START", "key": "epoch_start", "value": 1, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 158, "epoch_num": 1}}
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
Epoch: [1]  [   0/4571]  eta: 0:04:27    time: 0.0584  data: 0.0009  max mem: 10413
Epoch: [1]  [  20/4571]  eta: 0:04:25    time: 0.0584  data: 0.0519  max mem: 10413
Epoch: [1]  [  40/4571]  eta: 0:04:27    time: 0.0597  data: 0.0533  max mem: 10413
/usr/local/lib/python3.10/dist-packages/torch/jit/annotations.py:386: UserWarning: TorchScript will treat type annotations of Tensor dtype-specific subtypes as if they are normal Tensors. dtype constraints are not enforced in compilation either.
  warnings.warn(
Epoch: [1]  [  60/4571]  eta: 0:04:25    time: 0.0584  data: 0.0518  max mem: 10413
Epoch: [1]  [  80/4571]  eta: 0:04:23    time: 0.0583  data: 0.0518  max mem: 10413
Epoch: [1]  [ 100/4571]  eta: 0:04:22    time: 0.0584  data: 0.0519  max mem: 10413
Epoch: [1]  [ 120/4571]  eta: 0:04:20    time: 0.0583  data: 0.0519  max mem: 10413
Epoch: [1]  [ 140/4571]  eta: 0:04:19    time: 0.0584  data: 0.0518  max mem: 10413
Epoch: [1]  [ 160/4571]  eta: 0:04:18    time: 0.0594  data: 0.0529  max mem: 10413
:::MLLOG {"namespace": "", "time_ms": 1696360202607, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.24098658298335812, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 437, "epoch_num": 1}}
:::MLLOG {"namespace": "", "time_ms": 1696360202607, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 438, "epoch_num": 1}}
Epoch: [1]  [ 180/4571]  eta: 0:04:17    time: 0.0583  data: 0.0519  max mem: 10413
Epoch: [1]  [ 200/4571]  eta: 0:04:16    time: 0.0584  data: 0.0520  max mem: 10413
Epoch: [1]  [ 220/4571]  eta: 0:04:14    time: 0.0586  data: 0.0521  max mem: 10413
Epoch: [1]  [ 240/4571]  eta: 0:04:13    time: 0.0582  data: 0.0518  max mem: 10413
Epoch: [1]  [ 260/4571]  eta: 0:04:12    time: 0.0594  data: 0.0530  max mem: 10413
Epoch: [1]  [ 280/4571]  eta: 0:04:11    time: 0.0584  data: 0.0519  max mem: 10413
Epoch: [1]  [ 300/4571]  eta: 0:04:10    time: 0.0584  data: 0.0519  max mem: 10413
Epoch: [1]  [ 320/4571]  eta: 0:04:09    time: 0.0591  data: 0.0527  max mem: 10413
Epoch: [1]  [ 340/4571]  eta: 0:04:08    time: 0.0590  data: 0.0526  max mem: 10413
Epoch: [1]  [ 360/4571]  eta: 0:04:06    time: 0.0585  data: 0.0520  max mem: 10413
Epoch: [1]  [ 380/4571]  eta: 0:04:05    time: 0.0585  data: 0.0520  max mem: 10413
Epoch: [1]  [ 400/4571]  eta: 0:04:04    time: 0.0583  data: 0.0519  max mem: 10413
Epoch: [1]  [ 420/4571]  eta: 0:04:03    time: 0.0584  data: 0.0519  max mem: 10413
Epoch: [1]  [ 440/4571]  eta: 0:04:02    time: 0.0593  data: 0.0529  max mem: 10413
Epoch: [1]  [ 460/4571]  eta: 0:04:01    time: 0.0585  data: 0.0520  max mem: 10413
Epoch: [1]  [ 480/4571]  eta: 0:03:59    time: 0.0585  data: 0.0520  max mem: 10413
Epoch: [1]  [ 500/4571]  eta: 0:03:58    time: 0.0585  data: 0.0520  max mem: 10413
Epoch: [1]  [ 520/4571]  eta: 0:03:57    time: 0.0584  data: 0.0519  max mem: 10413
Epoch: [1]  [ 540/4571]  eta: 0:03:56    time: 0.0583  data: 0.0518  max mem: 10413
Epoch: [1]  [ 560/4571]  eta: 0:03:55    time: 0.0584  data: 0.0519  max mem: 10413
Epoch: [1]  [ 580/4571]  eta: 0:03:53    time: 0.0584  data: 0.0520  max mem: 10413
Epoch: [1]  [ 600/4571]  eta: 0:03:52    time: 0.0585  data: 0.0520  max mem: 10413
Epoch: [1]  [ 620/4571]  eta: 0:03:51    time: 0.0584  data: 0.0519  max mem: 10413
Epoch: [1]  [ 640/4571]  eta: 0:03:50    time: 0.0586  data: 0.0520  max mem: 10413
Epoch: [1]  [ 660/4571]  eta: 0:03:49    time: 0.0584  data: 0.0519  max mem: 10413
Epoch: [1]  [ 680/4571]  eta: 0:03:47    time: 0.0585  data: 0.0520  max mem: 10413
Epoch: [1]  [ 700/4571]  eta: 0:03:46    time: 0.0584  data: 0.0519  max mem: 10413
Epoch: [1]  [ 720/4571]  eta: 0:03:45    time: 0.0584  data: 0.0520  max mem: 10413
Epoch: [1]  [ 740/4571]  eta: 0:03:44    time: 0.0584  data: 0.0519  max mem: 10413
Epoch: [1]  [ 760/4571]  eta: 0:03:47    time: 0.0969  data: 0.0905  max mem: 10413
Epoch: [1]  [ 780/4571]  eta: 0:03:45    time: 0.0583  data: 0.0518  max mem: 10413
Epoch: [1]  [ 800/4571]  eta: 0:03:44    time: 0.0584  data: 0.0519  max mem: 10413
Epoch: [1]  [ 820/4571]  eta: 0:03:43    time: 0.0584  data: 0.0519  max mem: 10413
Epoch: [1]  [ 840/4571]  eta: 0:03:41    time: 0.0595  data: 0.0531  max mem: 10413
Epoch: [1]  [ 860/4571]  eta: 0:03:40    time: 0.0585  data: 0.0520  max mem: 10413
Epoch: [1]  [ 880/4571]  eta: 0:03:39    time: 0.0585  data: 0.0521  max mem: 10413
Epoch: [1]  [ 900/4571]  eta: 0:03:38    time: 0.0625  data: 0.0560  max mem: 10413
Epoch: [1]  [ 920/4571]  eta: 0:03:37    time: 0.0585  data: 0.0520  max mem: 10413
Epoch: [1]  [ 940/4571]  eta: 0:03:35    time: 0.0584  data: 0.0519  max mem: 10413
Epoch: [1]  [ 960/4571]  eta: 0:03:34    time: 0.0584  data: 0.0519  max mem: 10413
Epoch: [1]  [ 980/4571]  eta: 0:03:33    time: 0.0584  data: 0.0519  max mem: 10413
Epoch: [1]  [1000/4571]  eta: 0:03:32    time: 0.0584  data: 0.0520  max mem: 10413
Epoch: [1]  [1020/4571]  eta: 0:03:30    time: 0.0584  data: 0.0519  max mem: 10413
Epoch: [1]  [1040/4571]  eta: 0:03:29    time: 0.0583  data: 0.0518  max mem: 10413
Epoch: [1]  [1060/4571]  eta: 0:03:28    time: 0.0601  data: 0.0537  max mem: 10413
Epoch: [1]  [1080/4571]  eta: 0:03:27    time: 0.0594  data: 0.0529  max mem: 10413
Epoch: [1]  [1100/4571]  eta: 0:03:26    time: 0.0586  data: 0.0521  max mem: 10413
Epoch: [1]  [1120/4571]  eta: 0:03:24    time: 0.0585  data: 0.0520  max mem: 10413
Corrupt JPEG data: premature end of data segment
Epoch: [1]  [1140/4571]  eta: 0:03:23    time: 0.0585  data: 0.0521  max mem: 10413
Epoch: [1]  [1160/4571]  eta: 0:03:22    time: 0.0585  data: 0.0520  max mem: 10413
Epoch: [1]  [1180/4571]  eta: 0:03:21    time: 0.0584  data: 0.0519  max mem: 10413
Epoch: [1]  [1200/4571]  eta: 0:03:19    time: 0.0584  data: 0.0519  max mem: 10413
Epoch: [1]  [1220/4571]  eta: 0:03:18    time: 0.0584  data: 0.0519  max mem: 10413
Epoch: [1]  [1240/4571]  eta: 0:03:17    time: 0.0583  data: 0.0519  max mem: 10413
Epoch: [1]  [1260/4571]  eta: 0:03:16    time: 0.0585  data: 0.0520  max mem: 10413
Epoch: [1]  [1280/4571]  eta: 0:03:15    time: 0.0601  data: 0.0536  max mem: 10413
Epoch: [1]  [1300/4571]  eta: 0:03:13    time: 0.0584  data: 0.0519  max mem: 10413
Epoch: [1]  [1320/4571]  eta: 0:03:12    time: 0.0584  data: 0.0520  max mem: 10413
Epoch: [1]  [1340/4571]  eta: 0:03:11    time: 0.0585  data: 0.0521  max mem: 10413
Epoch: [1]  [1360/4571]  eta: 0:03:10    time: 0.0608  data: 0.0544  max mem: 10413
Epoch: [1]  [1380/4571]  eta: 0:03:09    time: 0.0585  data: 0.0520  max mem: 10413
Epoch: [1]  [1400/4571]  eta: 0:03:07    time: 0.0585  data: 0.0520  max mem: 10413
Epoch: [1]  [1420/4571]  eta: 0:03:06    time: 0.0585  data: 0.0520  max mem: 10413
Epoch: [1]  [1440/4571]  eta: 0:03:05    time: 0.0584  data: 0.0520  max mem: 10413
Epoch: [1]  [1460/4571]  eta: 0:03:04    time: 0.0585  data: 0.0520  max mem: 10413
Epoch: [1]  [1480/4571]  eta: 0:03:02    time: 0.0584  data: 0.0519  max mem: 10413
Epoch: [1]  [1500/4571]  eta: 0:03:01    time: 0.0585  data: 0.0520  max mem: 10413
Epoch: [1]  [1520/4571]  eta: 0:03:00    time: 0.0584  data: 0.0519  max mem: 10413
Epoch: [1]  [1540/4571]  eta: 0:02:59    time: 0.0584  data: 0.0519  max mem: 10413
Epoch: [1]  [1560/4571]  eta: 0:02:58    time: 0.0585  data: 0.0520  max mem: 10413
Epoch: [1]  [1580/4571]  eta: 0:02:58    time: 0.0924  data: 0.0860  max mem: 10413
Epoch: [1]  [1600/4571]  eta: 0:02:56    time: 0.0584  data: 0.0520  max mem: 10413
Epoch: [1]  [1620/4571]  eta: 0:02:55    time: 0.0587  data: 0.0522  max mem: 10413
Epoch: [1]  [1640/4571]  eta: 0:02:54    time: 0.0585  data: 0.0520  max mem: 10413
Epoch: [1]  [1660/4571]  eta: 0:02:53    time: 0.0584  data: 0.0519  max mem: 10413
Epoch: [1]  [1680/4571]  eta: 0:02:52    time: 0.0592  data: 0.0526  max mem: 10413
Epoch: [1]  [1700/4571]  eta: 0:02:50    time: 0.0627  data: 0.0563  max mem: 10413
Epoch: [1]  [1720/4571]  eta: 0:02:49    time: 0.0584  data: 0.0519  max mem: 10413
Epoch: [1]  [1740/4571]  eta: 0:02:48    time: 0.0585  data: 0.0520  max mem: 10413
Epoch: [1]  [1760/4571]  eta: 0:02:47    time: 0.0583  data: 0.0519  max mem: 10413
Epoch: [1]  [1780/4571]  eta: 0:02:46    time: 0.0584  data: 0.0519  max mem: 10413
Epoch: [1]  [1800/4571]  eta: 0:02:44    time: 0.0608  data: 0.0519  max mem: 10413
Epoch: [1]  [1820/4571]  eta: 0:02:43    time: 0.0585  data: 0.0520  max mem: 10413
Epoch: [1]  [1840/4571]  eta: 0:02:42    time: 0.0584  data: 0.0519  max mem: 10413
Epoch: [1]  [1860/4571]  eta: 0:02:41    time: 0.0595  data: 0.0531  max mem: 10413
Epoch: [1]  [1880/4571]  eta: 0:02:40    time: 0.0584  data: 0.0519  max mem: 10413
Epoch: [1]  [1900/4571]  eta: 0:02:38    time: 0.0584  data: 0.0519  max mem: 10413
Epoch: [1]  [1920/4571]  eta: 0:02:37    time: 0.0584  data: 0.0519  max mem: 10413
Epoch: [1]  [1940/4571]  eta: 0:02:36    time: 0.0583  data: 0.0519  max mem: 10413
Epoch: [1]  [1960/4571]  eta: 0:02:35    time: 0.0586  data: 0.0521  max mem: 10413
Epoch: [1]  [1980/4571]  eta: 0:02:33    time: 0.0588  data: 0.0524  max mem: 10413
Epoch: [1]  [2000/4571]  eta: 0:02:32    time: 0.0584  data: 0.0519  max mem: 10413
Epoch: [1]  [2020/4571]  eta: 0:02:31    time: 0.0583  data: 0.0519  max mem: 10413
Epoch: [1]  [2040/4571]  eta: 0:02:30    time: 0.0583  data: 0.0519  max mem: 10413
Epoch: [1]  [2060/4571]  eta: 0:02:29    time: 0.0584  data: 0.0519  max mem: 10413
Epoch: [1]  [2080/4571]  eta: 0:02:27    time: 0.0584  data: 0.0534  max mem: 10413
Epoch: [1]  [2100/4571]  eta: 0:02:26    time: 0.0584  data: 0.0519  max mem: 10413
Epoch: [1]  [2120/4571]  eta: 0:02:25    time: 0.0584  data: 0.0520  max mem: 10413
Epoch: [1]  [2140/4571]  eta: 0:02:24    time: 0.0585  data: 0.0520  max mem: 10413
Epoch: [1]  [2160/4571]  eta: 0:02:23    time: 0.0583  data: 0.0519  max mem: 10413
Epoch: [1]  [2180/4571]  eta: 0:02:21    time: 0.0637  data: 0.0572  max mem: 10413
Epoch: [1]  [2200/4571]  eta: 0:02:20    time: 0.0585  data: 0.0520  max mem: 10413
Epoch: [1]  [2220/4571]  eta: 0:02:19    time: 0.0584  data: 0.0519  max mem: 10413
Epoch: [1]  [2240/4571]  eta: 0:02:18    time: 0.0583  data: 0.0519  max mem: 10413
Epoch: [1]  [2260/4571]  eta: 0:02:17    time: 0.0584  data: 0.0519  max mem: 10413
Epoch: [1]  [2280/4571]  eta: 0:02:15    time: 0.0584  data: 0.0519  max mem: 10413
Epoch: [1]  [2300/4571]  eta: 0:02:14    time: 0.0584  data: 0.0519  max mem: 10413
Epoch: [1]  [2320/4571]  eta: 0:02:13    time: 0.0583  data: 0.0519  max mem: 10413
Epoch: [1]  [2340/4571]  eta: 0:02:12    time: 0.0584  data: 0.0520  max mem: 10413
Epoch: [1]  [2360/4571]  eta: 0:02:11    time: 0.0925  data: 0.0860  max mem: 10413
Epoch: [1]  [2380/4571]  eta: 0:02:10    time: 0.0583  data: 0.0519  max mem: 10413
Epoch: [1]  [2400/4571]  eta: 0:02:09    time: 0.0584  data: 0.0519  max mem: 10413
Epoch: [1]  [2420/4571]  eta: 0:02:08    time: 0.0583  data: 0.0518  max mem: 10413
Epoch: [1]  [2440/4571]  eta: 0:02:06    time: 0.0584  data: 0.0520  max mem: 10413
Epoch: [1]  [2460/4571]  eta: 0:02:05    time: 0.0583  data: 0.0518  max mem: 10413
Epoch: [1]  [2480/4571]  eta: 0:02:04    time: 0.0584  data: 0.0518  max mem: 10413
Epoch: [1]  [2500/4571]  eta: 0:02:03    time: 0.0583  data: 0.0519  max mem: 10413
Epoch: [1]  [2520/4571]  eta: 0:02:02    time: 0.0583  data: 0.0518  max mem: 10413
Epoch: [1]  [2540/4571]  eta: 0:02:00    time: 0.0583  data: 0.0518  max mem: 10413
Epoch: [1]  [2560/4571]  eta: 0:01:59    time: 0.0584  data: 0.0519  max mem: 10413
Epoch: [1]  [2580/4571]  eta: 0:01:58    time: 0.0584  data: 0.0519  max mem: 10413
Epoch: [1]  [2600/4571]  eta: 0:01:57    time: 0.0583  data: 0.0518  max mem: 10413
Epoch: [1]  [2620/4571]  eta: 0:01:56    time: 0.0606  data: 0.0541  max mem: 10413
Epoch: [1]  [2640/4571]  eta: 0:01:54    time: 0.0586  data: 0.0521  max mem: 10413
Epoch: [1]  [2660/4571]  eta: 0:01:53    time: 0.0603  data: 0.0539  max mem: 10413
Epoch: [1]  [2680/4571]  eta: 0:01:52    time: 0.0584  data: 0.0520  max mem: 10413
Epoch: [1]  [2700/4571]  eta: 0:01:51    time: 0.0584  data: 0.0519  max mem: 10413
Epoch: [1]  [2720/4571]  eta: 0:01:50    time: 0.0584  data: 0.0520  max mem: 10413
Epoch: [1]  [2740/4571]  eta: 0:01:48    time: 0.0583  data: 0.0519  max mem: 10413
Epoch: [1]  [2760/4571]  eta: 0:01:47    time: 0.0583  data: 0.0518  max mem: 10413
Epoch: [1]  [2780/4571]  eta: 0:01:46    time: 0.0584  data: 0.0520  max mem: 10413
Epoch: [1]  [2800/4571]  eta: 0:01:45    time: 0.0583  data: 0.0519  max mem: 10413
Epoch: [1]  [2820/4571]  eta: 0:01:44    time: 0.0583  data: 0.0518  max mem: 10413
Epoch: [1]  [2840/4571]  eta: 0:01:42    time: 0.0583  data: 0.0519  max mem: 10413
Epoch: [1]  [2860/4571]  eta: 0:01:41    time: 0.0583  data: 0.0518  max mem: 10413
Epoch: [1]  [2880/4571]  eta: 0:01:40    time: 0.0583  data: 0.0518  max mem: 10413
Epoch: [1]  [2900/4571]  eta: 0:01:39    time: 0.0584  data: 0.0519  max mem: 10413
Epoch: [1]  [2920/4571]  eta: 0:01:38    time: 0.0585  data: 0.0521  max mem: 10413
Epoch: [1]  [2940/4571]  eta: 0:01:36    time: 0.0594  data: 0.0530  max mem: 10413
Epoch: [1]  [2960/4571]  eta: 0:01:35    time: 0.0583  data: 0.0519  max mem: 10413
Epoch: [1]  [2980/4571]  eta: 0:01:34    time: 0.0584  data: 0.0519  max mem: 10413
Epoch: [1]  [3000/4571]  eta: 0:01:33    time: 0.0950  data: 0.0886  max mem: 10413
Epoch: [1]  [3020/4571]  eta: 0:01:32    time: 0.0582  data: 0.0518  max mem: 10413
Epoch: [1]  [3040/4571]  eta: 0:01:31    time: 0.0583  data: 0.0518  max mem: 10413
Epoch: [1]  [3060/4571]  eta: 0:01:30    time: 0.0584  data: 0.0518  max mem: 10413
Epoch: [1]  [3080/4571]  eta: 0:01:28    time: 0.0584  data: 0.0519  max mem: 10413
Epoch: [1]  [3100/4571]  eta: 0:01:27    time: 0.0583  data: 0.0518  max mem: 10413
Epoch: [1]  [3120/4571]  eta: 0:01:26    time: 0.0583  data: 0.0519  max mem: 10413
Epoch: [1]  [3140/4571]  eta: 0:01:25    time: 0.0584  data: 0.0520  max mem: 10413
Epoch: [1]  [3160/4571]  eta: 0:01:24    time: 0.0582  data: 0.0517  max mem: 10413
Epoch: [1]  [3180/4571]  eta: 0:01:22    time: 0.0594  data: 0.0530  max mem: 10413
Epoch: [1]  [3200/4571]  eta: 0:01:21    time: 0.0583  data: 0.0518  max mem: 10413
Epoch: [1]  [3220/4571]  eta: 0:01:20    time: 0.0584  data: 0.0519  max mem: 10413
Epoch: [1]  [3240/4571]  eta: 0:01:19    time: 0.0583  data: 0.0519  max mem: 10413
Epoch: [1]  [3260/4571]  eta: 0:01:18    time: 0.0583  data: 0.0518  max mem: 10413
Epoch: [1]  [3280/4571]  eta: 0:01:16    time: 0.0583  data: 0.0518  max mem: 10413
Epoch: [1]  [3300/4571]  eta: 0:01:15    time: 0.0583  data: 0.0518  max mem: 10413
Epoch: [1]  [3320/4571]  eta: 0:01:14    time: 0.0598  data: 0.0519  max mem: 10413
Epoch: [1]  [3340/4571]  eta: 0:01:13    time: 0.0583  data: 0.0518  max mem: 10413
Epoch: [1]  [3360/4571]  eta: 0:01:12    time: 0.0582  data: 0.0518  max mem: 10413
Epoch: [1]  [3380/4571]  eta: 0:01:10    time: 0.0583  data: 0.0518  max mem: 10413
Epoch: [1]  [3400/4571]  eta: 0:01:09    time: 0.0583  data: 0.0519  max mem: 10413
Epoch: [1]  [3420/4571]  eta: 0:01:08    time: 0.0583  data: 0.0518  max mem: 10413
Epoch: [1]  [3440/4571]  eta: 0:01:07    time: 0.0625  data: 0.0561  max mem: 10413
Epoch: [1]  [3460/4571]  eta: 0:01:06    time: 0.0584  data: 0.0519  max mem: 10413
Epoch: [1]  [3480/4571]  eta: 0:01:05    time: 0.0977  data: 0.0912  max mem: 10413
Epoch: [1]  [3500/4571]  eta: 0:01:03    time: 0.0583  data: 0.0518  max mem: 10413
Epoch: [1]  [3520/4571]  eta: 0:01:02    time: 0.0603  data: 0.0538  max mem: 10413
Epoch: [1]  [3540/4571]  eta: 0:01:01    time: 0.0584  data: 0.0520  max mem: 10413
Epoch: [1]  [3560/4571]  eta: 0:01:00    time: 0.0583  data: 0.0519  max mem: 10413
Epoch: [1]  [3580/4571]  eta: 0:00:59    time: 0.0594  data: 0.0531  max mem: 10413
Epoch: [1]  [3600/4571]  eta: 0:00:57    time: 0.0595  data: 0.0531  max mem: 10413
Epoch: [1]  [3620/4571]  eta: 0:00:56    time: 0.0583  data: 0.0519  max mem: 10413
Epoch: [1]  [3640/4571]  eta: 0:00:55    time: 0.0584  data: 0.0519  max mem: 10413
Epoch: [1]  [3660/4571]  eta: 0:00:54    time: 0.0583  data: 0.0519  max mem: 10413
Epoch: [1]  [3680/4571]  eta: 0:00:53    time: 0.0583  data: 0.0518  max mem: 10413
Epoch: [1]  [3700/4571]  eta: 0:00:51    time: 0.0584  data: 0.0519  max mem: 10413
Epoch: [1]  [3720/4571]  eta: 0:00:50    time: 0.0590  data: 0.0518  max mem: 10413
Epoch: [1]  [3740/4571]  eta: 0:00:49    time: 0.0582  data: 0.0517  max mem: 10413
Epoch: [1]  [3760/4571]  eta: 0:00:48    time: 0.0582  data: 0.0517  max mem: 10413
Epoch: [1]  [3780/4571]  eta: 0:00:47    time: 0.0584  data: 0.0519  max mem: 10413
Epoch: [1]  [3800/4571]  eta: 0:00:45    time: 0.0584  data: 0.0519  max mem: 10413
Epoch: [1]  [3820/4571]  eta: 0:00:44    time: 0.0582  data: 0.0518  max mem: 10413
Epoch: [1]  [3840/4571]  eta: 0:00:43    time: 0.0584  data: 0.0519  max mem: 10413
Epoch: [1]  [3860/4571]  eta: 0:00:42    time: 0.0583  data: 0.0518  max mem: 10413
Epoch: [1]  [3880/4571]  eta: 0:00:41    time: 0.0584  data: 0.0520  max mem: 10413
Epoch: [1]  [3900/4571]  eta: 0:00:39    time: 0.0583  data: 0.0518  max mem: 10413
Epoch: [1]  [3920/4571]  eta: 0:00:38    time: 0.0583  data: 0.0519  max mem: 10413
Epoch: [1]  [3940/4571]  eta: 0:00:37    time: 0.0584  data: 0.0520  max mem: 10413
Epoch: [1]  [3960/4571]  eta: 0:00:36    time: 0.0584  data: 0.0519  max mem: 10413
Epoch: [1]  [3980/4571]  eta: 0:00:35    time: 0.0583  data: 0.0518  max mem: 10413
Epoch: [1]  [4000/4571]  eta: 0:00:33    time: 0.0584  data: 0.0519  max mem: 10413
Epoch: [1]  [4020/4571]  eta: 0:00:32    time: 0.0583  data: 0.0518  max mem: 10413
Epoch: [1]  [4040/4571]  eta: 0:00:31    time: 0.0582  data: 0.0518  max mem: 10413
Epoch: [1]  [4060/4571]  eta: 0:00:30    time: 0.0583  data: 0.0518  max mem: 10413
Epoch: [1]  [4080/4571]  eta: 0:00:29    time: 0.0583  data: 0.0517  max mem: 10413
Epoch: [1]  [4100/4571]  eta: 0:00:28    time: 0.0583  data: 0.0518  max mem: 10413
Epoch: [1]  [4120/4571]  eta: 0:00:26    time: 0.0608  data: 0.0543  max mem: 10413
Epoch: [1]  [4140/4571]  eta: 0:00:25    time: 0.0584  data: 0.0520  max mem: 10413
Epoch: [1]  [4160/4571]  eta: 0:00:24    time: 0.0583  data: 0.0518  max mem: 10413
Epoch: [1]  [4180/4571]  eta: 0:00:23    time: 0.0582  data: 0.0518  max mem: 10413
Epoch: [1]  [4200/4571]  eta: 0:00:22    time: 0.0583  data: 0.0519  max mem: 10413
Epoch: [1]  [4220/4571]  eta: 0:00:20    time: 0.0940  data: 0.0876  max mem: 10413
Epoch: [1]  [4240/4571]  eta: 0:00:19    time: 0.0905  data: 0.0840  max mem: 10413
Epoch: [1]  [4260/4571]  eta: 0:00:18    time: 0.0583  data: 0.0518  max mem: 10413
Epoch: [1]  [4280/4571]  eta: 0:00:17    time: 0.0934  data: 0.0870  max mem: 10413
Epoch: [1]  [4300/4571]  eta: 0:00:16    time: 0.0582  data: 0.0518  max mem: 10413
Epoch: [1]  [4320/4571]  eta: 0:00:15    time: 0.0582  data: 0.0518  max mem: 10413
Epoch: [1]  [4340/4571]  eta: 0:00:13    time: 0.0594  data: 0.0529  max mem: 10413
Epoch: [1]  [4360/4571]  eta: 0:00:12    time: 0.0583  data: 0.0518  max mem: 10413
Epoch: [1]  [4380/4571]  eta: 0:00:11    time: 0.0583  data: 0.0518  max mem: 10413
Epoch: [1]  [4400/4571]  eta: 0:00:10    time: 0.0582  data: 0.0518  max mem: 10413
Epoch: [1]  [4420/4571]  eta: 0:00:09    time: 0.0583  data: 0.0519  max mem: 10413
Epoch: [1]  [4440/4571]  eta: 0:00:07    time: 0.0582  data: 0.0518  max mem: 10413
Epoch: [1]  [4460/4571]  eta: 0:00:06    time: 0.0583  data: 0.0518  max mem: 10413
Epoch: [1]  [4480/4571]  eta: 0:00:05    time: 0.0582  data: 0.0518  max mem: 10413
Epoch: [1]  [4500/4571]  eta: 0:00:04    time: 0.0591  data: 0.0527  max mem: 10413
Epoch: [1]  [4520/4571]  eta: 0:00:03    time: 0.0584  data: 0.0520  max mem: 10413
Epoch: [1]  [4540/4571]  eta: 0:00:01    time: 0.0582  data: 0.0518  max mem: 10413
Epoch: [1]  [4560/4571]  eta: 0:00:00    time: 0.0584  data: 0.0519  max mem: 10413
Epoch: [1]  [4570/4571]  eta: 0:00:00    time: 0.0582  data: 0.0517  max mem: 10413
Epoch: [1] Total time: 0:04:33 (0.0598 s / it)
:::MLLOG {"namespace": "", "time_ms": 1696360466529, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": 1, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 330, "epoch_num": 1}}
:::MLLOG {"namespace": "", "time_ms": 1696360466529, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 267.3105647224823}, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 334, "step": 2}}
:::MLLOG {"namespace": "", "time_ms": 1696360466529, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 344, "epoch_num": 2}}
Test:  [ 0/97]  eta: 0:00:13  model_time: 0.1388 (0.1388)  evaluator_time: 0.0019 (0.0019)  time: 0.1414  data: 0.0006  max mem: 10413
Test:  [20/97]  eta: 0:00:11  model_time: 0.1388 (0.1416)  evaluator_time: 0.0019 (0.0019)  time: 0.1443  data: 0.0006  max mem: 10413
Test:  [40/97]  eta: 0:00:08  model_time: 0.1408 (0.1401)  evaluator_time: 0.0019 (0.0019)  time: 0.1413  data: 0.0006  max mem: 10413
Test:  [60/97]  eta: 0:00:05  model_time: 0.1417 (0.1400)  evaluator_time: 0.0020 (0.0029)  time: 0.1450  data: 0.0006  max mem: 10413
Test:  [80/97]  eta: 0:00:02  model_time: 0.1428 (0.1406)  evaluator_time: 0.0020 (0.0026)  time: 0.1453  data: 0.0006  max mem: 10413
Test:  [96/97]  eta: 0:00:00  model_time: 0.1428 (0.1404)  evaluator_time: 0.0019 (0.0025)  time: 0.1428  data: 0.0006  max mem: 10413
Test: Total time: 0:00:13 (0.1437 s / it)
Averaged stats: model_time: 0.1428 (0.1421)  evaluator_time: 0.0019 (0.0026)
:::MLLOG {"namespace": "", "time_ms": 1696360481663, "event_type": "INTERVAL_START", "key": "epoch_start", "value": 2, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 158, "epoch_num": 2}}
Epoch: [2]  [   0/4572]  eta: 0:04:27    time: 0.0585  data: 0.0008  max mem: 10413
Epoch: [2]  [  20/4572]  eta: 0:04:23    time: 0.0579  data: 0.0514  max mem: 10413
Epoch: [2]  [  40/4572]  eta: 0:04:22    time: 0.0579  data: 0.0514  max mem: 10413
Epoch: [2]  [  60/4572]  eta: 0:04:21    time: 0.0580  data: 0.0515  max mem: 10413
Epoch: [2]  [  80/4572]  eta: 0:04:20    time: 0.0583  data: 0.0517  max mem: 10413
:::MLLOG {"namespace": "", "time_ms": 1696360487007, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.2995053345135007, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 437, "epoch_num": 2}}
:::MLLOG {"namespace": "", "time_ms": 1696360487007, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 438, "epoch_num": 2}}
Epoch: [2]  [ 100/4572]  eta: 0:04:19    time: 0.0581  data: 0.0516  max mem: 10413
Epoch: [2]  [ 120/4572]  eta: 0:04:18    time: 0.0580  data: 0.0516  max mem: 10413
Epoch: [2]  [ 140/4572]  eta: 0:04:20    time: 0.0628  data: 0.0564  max mem: 10413
Epoch: [2]  [ 160/4572]  eta: 0:04:18    time: 0.0586  data: 0.0522  max mem: 10413
Epoch: [2]  [ 180/4572]  eta: 0:04:32    time: 0.0898  data: 0.0861  max mem: 10413
Epoch: [2]  [ 200/4572]  eta: 0:04:30    time: 0.0593  data: 0.0528  max mem: 10413
Epoch: [2]  [ 220/4572]  eta: 0:04:27    time: 0.0582  data: 0.0518  max mem: 10413
Epoch: [2]  [ 240/4572]  eta: 0:04:26    time: 0.0602  data: 0.0538  max mem: 10413
Epoch: [2]  [ 260/4572]  eta: 0:04:23    time: 0.0581  data: 0.0516  max mem: 10413
Epoch: [2]  [ 280/4572]  eta: 0:04:21    time: 0.0581  data: 0.0517  max mem: 10413
Epoch: [2]  [ 300/4572]  eta: 0:04:19    time: 0.0580  data: 0.0516  max mem: 10413
Epoch: [2]  [ 320/4572]  eta: 0:04:17    time: 0.0581  data: 0.0516  max mem: 10413
Epoch: [2]  [ 340/4572]  eta: 0:04:16    time: 0.0594  data: 0.0530  max mem: 10413
Epoch: [2]  [ 360/4572]  eta: 0:04:14    time: 0.0581  data: 0.0516  max mem: 10413
Epoch: [2]  [ 380/4572]  eta: 0:04:12    time: 0.0582  data: 0.0517  max mem: 10413
Epoch: [2]  [ 400/4572]  eta: 0:04:10    time: 0.0581  data: 0.0517  max mem: 10413
Epoch: [2]  [ 420/4572]  eta: 0:04:09    time: 0.0583  data: 0.0518  max mem: 10413
Epoch: [2]  [ 440/4572]  eta: 0:04:08    time: 0.0598  data: 0.0533  max mem: 10413
Epoch: [2]  [ 460/4572]  eta: 0:04:06    time: 0.0583  data: 0.0518  max mem: 10413
Epoch: [2]  [ 480/4572]  eta: 0:04:05    time: 0.0582  data: 0.0518  max mem: 10413
Epoch: [2]  [ 500/4572]  eta: 0:04:09    time: 0.0943  data: 0.0879  max mem: 10413
Epoch: [2]  [ 520/4572]  eta: 0:04:08    time: 0.0597  data: 0.0532  max mem: 10413
Epoch: [2]  [ 540/4572]  eta: 0:04:06    time: 0.0581  data: 0.0516  max mem: 10413
Epoch: [2]  [ 560/4572]  eta: 0:04:04    time: 0.0582  data: 0.0517  max mem: 10413
Epoch: [2]  [ 580/4572]  eta: 0:04:03    time: 0.0582  data: 0.0518  max mem: 10413
Epoch: [2]  [ 600/4572]  eta: 0:04:06    time: 0.0935  data: 0.0870  max mem: 10413
Epoch: [2]  [ 620/4572]  eta: 0:04:04    time: 0.0584  data: 0.0520  max mem: 10413
Epoch: [2]  [ 640/4572]  eta: 0:04:02    time: 0.0582  data: 0.0517  max mem: 10413
Epoch: [2]  [ 660/4572]  eta: 0:04:01    time: 0.0582  data: 0.0518  max mem: 10413
Epoch: [2]  [ 680/4572]  eta: 0:03:59    time: 0.0582  data: 0.0517  max mem: 10413
Epoch: [2]  [ 700/4572]  eta: 0:03:57    time: 0.0581  data: 0.0517  max mem: 10413
Epoch: [2]  [ 720/4572]  eta: 0:03:56    time: 0.0584  data: 0.0518  max mem: 10413
Epoch: [2]  [ 740/4572]  eta: 0:03:54    time: 0.0583  data: 0.0519  max mem: 10413
Epoch: [2]  [ 760/4572]  eta: 0:03:53    time: 0.0582  data: 0.0517  max mem: 10413
Epoch: [2]  [ 780/4572]  eta: 0:03:51    time: 0.0583  data: 0.0518  max mem: 10413
Epoch: [2]  [ 800/4572]  eta: 0:03:50    time: 0.0582  data: 0.0517  max mem: 10413
Epoch: [2]  [ 820/4572]  eta: 0:03:48    time: 0.0601  data: 0.0536  max mem: 10413
Epoch: [2]  [ 840/4572]  eta: 0:03:47    time: 0.0584  data: 0.0518  max mem: 10413
Epoch: [2]  [ 860/4572]  eta: 0:03:46    time: 0.0582  data: 0.0517  max mem: 10413
Epoch: [2]  [ 880/4572]  eta: 0:03:44    time: 0.0583  data: 0.0519  max mem: 10413
Epoch: [2]  [ 900/4572]  eta: 0:03:43    time: 0.0583  data: 0.0519  max mem: 10413
Epoch: [2]  [ 920/4572]  eta: 0:03:41    time: 0.0582  data: 0.0517  max mem: 10413
Epoch: [2]  [ 940/4572]  eta: 0:03:40    time: 0.0584  data: 0.0519  max mem: 10413
Epoch: [2]  [ 960/4572]  eta: 0:03:39    time: 0.0583  data: 0.0519  max mem: 10413
Epoch: [2]  [ 980/4572]  eta: 0:03:37    time: 0.0582  data: 0.0517  max mem: 10413
Epoch: [2]  [1000/4572]  eta: 0:03:36    time: 0.0583  data: 0.0518  max mem: 10413
Epoch: [2]  [1020/4572]  eta: 0:03:34    time: 0.0582  data: 0.0518  max mem: 10413
Epoch: [2]  [1040/4572]  eta: 0:03:33    time: 0.0584  data: 0.0519  max mem: 10413
Epoch: [2]  [1060/4572]  eta: 0:03:32    time: 0.0587  data: 0.0523  max mem: 10413
Epoch: [2]  [1080/4572]  eta: 0:03:30    time: 0.0583  data: 0.0518  max mem: 10413
Epoch: [2]  [1100/4572]  eta: 0:03:31    time: 0.0907  data: 0.0842  max mem: 10413
Epoch: [2]  [1120/4572]  eta: 0:03:30    time: 0.0645  data: 0.0579  max mem: 10413
Epoch: [2]  [1140/4572]  eta: 0:03:29    time: 0.0582  data: 0.0518  max mem: 10413
Epoch: [2]  [1160/4572]  eta: 0:03:27    time: 0.0583  data: 0.0518  max mem: 10413
Epoch: [2]  [1180/4572]  eta: 0:03:26    time: 0.0583  data: 0.0518  max mem: 10413
Epoch: [2]  [1200/4572]  eta: 0:03:25    time: 0.0582  data: 0.0517  max mem: 10413
Epoch: [2]  [1220/4572]  eta: 0:03:23    time: 0.0582  data: 0.0518  max mem: 10413
Epoch: [2]  [1240/4572]  eta: 0:03:22    time: 0.0582  data: 0.0517  max mem: 10413
Epoch: [2]  [1260/4572]  eta: 0:03:20    time: 0.0583  data: 0.0518  max mem: 10413
Epoch: [2]  [1280/4572]  eta: 0:03:19    time: 0.0583  data: 0.0519  max mem: 10413
Epoch: [2]  [1300/4572]  eta: 0:03:18    time: 0.0583  data: 0.0519  max mem: 10413
Epoch: [2]  [1320/4572]  eta: 0:03:17    time: 0.0582  data: 0.0517  max mem: 10413
Epoch: [2]  [1340/4572]  eta: 0:03:15    time: 0.0583  data: 0.0518  max mem: 10413
Epoch: [2]  [1360/4572]  eta: 0:03:14    time: 0.0582  data: 0.0517  max mem: 10413
Epoch: [2]  [1380/4572]  eta: 0:03:13    time: 0.0583  data: 0.0520  max mem: 10413
Epoch: [2]  [1400/4572]  eta: 0:03:11    time: 0.0582  data: 0.0517  max mem: 10413
Epoch: [2]  [1420/4572]  eta: 0:03:10    time: 0.0598  data: 0.0534  max mem: 10413
Epoch: [2]  [1440/4572]  eta: 0:03:09    time: 0.0582  data: 0.0518  max mem: 10413
Epoch: [2]  [1460/4572]  eta: 0:03:07    time: 0.0605  data: 0.0541  max mem: 10413
Epoch: [2]  [1480/4572]  eta: 0:03:06    time: 0.0582  data: 0.0517  max mem: 10413
Epoch: [2]  [1500/4572]  eta: 0:03:05    time: 0.0582  data: 0.0517  max mem: 10413
Epoch: [2]  [1520/4572]  eta: 0:03:04    time: 0.0583  data: 0.0518  max mem: 10413
Epoch: [2]  [1540/4572]  eta: 0:03:02    time: 0.0583  data: 0.0519  max mem: 10413
Epoch: [2]  [1560/4572]  eta: 0:03:01    time: 0.0582  data: 0.0518  max mem: 10413
Epoch: [2]  [1580/4572]  eta: 0:03:00    time: 0.0583  data: 0.0518  max mem: 10413
Epoch: [2]  [1600/4572]  eta: 0:02:58    time: 0.0582  data: 0.0518  max mem: 10413
Epoch: [2]  [1620/4572]  eta: 0:02:57    time: 0.0583  data: 0.0518  max mem: 10413
Epoch: [2]  [1640/4572]  eta: 0:02:56    time: 0.0583  data: 0.0517  max mem: 10413
Epoch: [2]  [1660/4572]  eta: 0:02:55    time: 0.0582  data: 0.0518  max mem: 10413
Epoch: [2]  [1680/4572]  eta: 0:02:53    time: 0.0583  data: 0.0518  max mem: 10413
Epoch: [2]  [1700/4572]  eta: 0:02:52    time: 0.0583  data: 0.0518  max mem: 10413
Epoch: [2]  [1720/4572]  eta: 0:02:51    time: 0.0606  data: 0.0542  max mem: 10413
Epoch: [2]  [1740/4572]  eta: 0:02:50    time: 0.0593  data: 0.0528  max mem: 10413
Epoch: [2]  [1760/4572]  eta: 0:02:48    time: 0.0583  data: 0.0518  max mem: 10413
Epoch: [2]  [1780/4572]  eta: 0:02:47    time: 0.0584  data: 0.0519  max mem: 10413
Epoch: [2]  [1800/4572]  eta: 0:02:46    time: 0.0608  data: 0.0543  max mem: 10413
Epoch: [2]  [1820/4572]  eta: 0:02:45    time: 0.0583  data: 0.0519  max mem: 10413
Epoch: [2]  [1840/4572]  eta: 0:02:43    time: 0.0582  data: 0.0517  max mem: 10413
Epoch: [2]  [1860/4572]  eta: 0:02:42    time: 0.0582  data: 0.0517  max mem: 10413
Epoch: [2]  [1880/4572]  eta: 0:02:41    time: 0.0584  data: 0.0519  max mem: 10413
Epoch: [2]  [1900/4572]  eta: 0:02:40    time: 0.0583  data: 0.0519  max mem: 10413
Epoch: [2]  [1920/4572]  eta: 0:02:39    time: 0.0583  data: 0.0518  max mem: 10413
Epoch: [2]  [1940/4572]  eta: 0:02:37    time: 0.0583  data: 0.0519  max mem: 10413
Epoch: [2]  [1960/4572]  eta: 0:02:36    time: 0.0584  data: 0.0519  max mem: 10413
Epoch: [2]  [1980/4572]  eta: 0:02:35    time: 0.0620  data: 0.0532  max mem: 10413
Epoch: [2]  [2000/4572]  eta: 0:02:34    time: 0.0606  data: 0.0542  max mem: 10413
Epoch: [2]  [2020/4572]  eta: 0:02:32    time: 0.0585  data: 0.0520  max mem: 10413
Epoch: [2]  [2040/4572]  eta: 0:02:31    time: 0.0582  data: 0.0518  max mem: 10413
Epoch: [2]  [2060/4572]  eta: 0:02:30    time: 0.0583  data: 0.0519  max mem: 10413
Epoch: [2]  [2080/4572]  eta: 0:02:29    time: 0.0582  data: 0.0517  max mem: 10413
Epoch: [2]  [2100/4572]  eta: 0:02:28    time: 0.0583  data: 0.0519  max mem: 10413
Epoch: [2]  [2120/4572]  eta: 0:02:26    time: 0.0583  data: 0.0519  max mem: 10413
Epoch: [2]  [2140/4572]  eta: 0:02:25    time: 0.0583  data: 0.0518  max mem: 10413
Epoch: [2]  [2160/4572]  eta: 0:02:24    time: 0.0583  data: 0.0518  max mem: 10413
Epoch: [2]  [2180/4572]  eta: 0:02:23    time: 0.0582  data: 0.0518  max mem: 10413
Corrupt JPEG data: premature end of data segment
Epoch: [2]  [2200/4572]  eta: 0:02:21    time: 0.0588  data: 0.0524  max mem: 10413
Epoch: [2]  [2220/4572]  eta: 0:02:20    time: 0.0583  data: 0.0518  max mem: 10413
Epoch: [2]  [2240/4572]  eta: 0:02:19    time: 0.0583  data: 0.0518  max mem: 10413
Epoch: [2]  [2260/4572]  eta: 0:02:18    time: 0.0951  data: 0.0886  max mem: 10413
Epoch: [2]  [2280/4572]  eta: 0:02:17    time: 0.0582  data: 0.0517  max mem: 10413
Epoch: [2]  [2300/4572]  eta: 0:02:16    time: 0.0583  data: 0.0518  max mem: 10413
Epoch: [2]  [2320/4572]  eta: 0:02:15    time: 0.0584  data: 0.0519  max mem: 10413
Epoch: [2]  [2340/4572]  eta: 0:02:13    time: 0.0582  data: 0.0517  max mem: 10413
Epoch: [2]  [2360/4572]  eta: 0:02:12    time: 0.0582  data: 0.0517  max mem: 10413
Epoch: [2]  [2380/4572]  eta: 0:02:11    time: 0.0583  data: 0.0518  max mem: 10413
Epoch: [2]  [2400/4572]  eta: 0:02:10    time: 0.0609  data: 0.0517  max mem: 10413
Epoch: [2]  [2420/4572]  eta: 0:02:09    time: 0.0581  data: 0.0516  max mem: 10413
Epoch: [2]  [2440/4572]  eta: 0:02:07    time: 0.0583  data: 0.0518  max mem: 10413
Epoch: [2]  [2460/4572]  eta: 0:02:06    time: 0.0582  data: 0.0518  max mem: 10413
Epoch: [2]  [2480/4572]  eta: 0:02:05    time: 0.0583  data: 0.0518  max mem: 10413
Epoch: [2]  [2500/4572]  eta: 0:02:04    time: 0.0583  data: 0.0518  max mem: 10413
Epoch: [2]  [2520/4572]  eta: 0:02:02    time: 0.0583  data: 0.0518  max mem: 10413
Epoch: [2]  [2540/4572]  eta: 0:02:01    time: 0.0583  data: 0.0518  max mem: 10413
Epoch: [2]  [2560/4572]  eta: 0:02:00    time: 0.0622  data: 0.0556  max mem: 10413
Epoch: [2]  [2580/4572]  eta: 0:01:59    time: 0.0583  data: 0.0518  max mem: 10413
Epoch: [2]  [2600/4572]  eta: 0:01:58    time: 0.0583  data: 0.0518  max mem: 10413
Epoch: [2]  [2620/4572]  eta: 0:01:56    time: 0.0604  data: 0.0539  max mem: 10413
Epoch: [2]  [2640/4572]  eta: 0:01:55    time: 0.0582  data: 0.0517  max mem: 10413
Epoch: [2]  [2660/4572]  eta: 0:01:54    time: 0.0583  data: 0.0517  max mem: 10413
Epoch: [2]  [2680/4572]  eta: 0:01:53    time: 0.0648  data: 0.0584  max mem: 10413
Epoch: [2]  [2700/4572]  eta: 0:01:52    time: 0.0582  data: 0.0517  max mem: 10413
Epoch: [2]  [2720/4572]  eta: 0:01:50    time: 0.0583  data: 0.0518  max mem: 10413
Epoch: [2]  [2740/4572]  eta: 0:01:49    time: 0.0582  data: 0.0516  max mem: 10413
Epoch: [2]  [2760/4572]  eta: 0:01:48    time: 0.0583  data: 0.0518  max mem: 10413
Epoch: [2]  [2780/4572]  eta: 0:01:47    time: 0.0586  data: 0.0517  max mem: 10413
Epoch: [2]  [2800/4572]  eta: 0:01:46    time: 0.0583  data: 0.0518  max mem: 10413
Epoch: [2]  [2820/4572]  eta: 0:01:44    time: 0.0582  data: 0.0517  max mem: 10413
Epoch: [2]  [2840/4572]  eta: 0:01:43    time: 0.0583  data: 0.0518  max mem: 10413
Epoch: [2]  [2860/4572]  eta: 0:01:42    time: 0.0582  data: 0.0517  max mem: 10413
Epoch: [2]  [2880/4572]  eta: 0:01:41    time: 0.0583  data: 0.0518  max mem: 10413
Epoch: [2]  [2900/4572]  eta: 0:01:39    time: 0.0592  data: 0.0527  max mem: 10413
Epoch: [2]  [2920/4572]  eta: 0:01:38    time: 0.0582  data: 0.0518  max mem: 10413
Epoch: [2]  [2940/4572]  eta: 0:01:37    time: 0.0583  data: 0.0517  max mem: 10413
Epoch: [2]  [2960/4572]  eta: 0:01:36    time: 0.0583  data: 0.0518  max mem: 10413
Epoch: [2]  [2980/4572]  eta: 0:01:35    time: 0.0583  data: 0.0518  max mem: 10413
Epoch: [2]  [3000/4572]  eta: 0:01:33    time: 0.0598  data: 0.0533  max mem: 10413
Epoch: [2]  [3020/4572]  eta: 0:01:32    time: 0.0586  data: 0.0522  max mem: 10413
Epoch: [2]  [3040/4572]  eta: 0:01:31    time: 0.0592  data: 0.0519  max mem: 10413
Epoch: [2]  [3060/4572]  eta: 0:01:30    time: 0.0581  data: 0.0516  max mem: 10413
Epoch: [2]  [3080/4572]  eta: 0:01:29    time: 0.0582  data: 0.0516  max mem: 10413
Epoch: [2]  [3100/4572]  eta: 0:01:27    time: 0.0633  data: 0.0569  max mem: 10413
Epoch: [2]  [3120/4572]  eta: 0:01:26    time: 0.0592  data: 0.0527  max mem: 10413
Epoch: [2]  [3140/4572]  eta: 0:01:25    time: 0.0583  data: 0.0518  max mem: 10413
Epoch: [2]  [3160/4572]  eta: 0:01:24    time: 0.0581  data: 0.0516  max mem: 10413
Epoch: [2]  [3180/4572]  eta: 0:01:23    time: 0.0588  data: 0.0523  max mem: 10413
Epoch: [2]  [3200/4572]  eta: 0:01:21    time: 0.0583  data: 0.0518  max mem: 10413
Epoch: [2]  [3220/4572]  eta: 0:01:20    time: 0.0582  data: 0.0517  max mem: 10413
Epoch: [2]  [3240/4572]  eta: 0:01:19    time: 0.0582  data: 0.0517  max mem: 10413
Epoch: [2]  [3260/4572]  eta: 0:01:18    time: 0.0583  data: 0.0518  max mem: 10413
Epoch: [2]  [3280/4572]  eta: 0:01:17    time: 0.0583  data: 0.0517  max mem: 10413
Epoch: [2]  [3300/4572]  eta: 0:01:15    time: 0.0582  data: 0.0517  max mem: 10413
Epoch: [2]  [3320/4572]  eta: 0:01:14    time: 0.0583  data: 0.0518  max mem: 10413
Epoch: [2]  [3340/4572]  eta: 0:01:13    time: 0.0583  data: 0.0518  max mem: 10413
Epoch: [2]  [3360/4572]  eta: 0:01:12    time: 0.0583  data: 0.0517  max mem: 10413
Epoch: [2]  [3380/4572]  eta: 0:01:11    time: 0.0582  data: 0.0517  max mem: 10413
Epoch: [2]  [3400/4572]  eta: 0:01:09    time: 0.0583  data: 0.0517  max mem: 10413
Epoch: [2]  [3420/4572]  eta: 0:01:08    time: 0.0581  data: 0.0516  max mem: 10413
Epoch: [2]  [3440/4572]  eta: 0:01:07    time: 0.0583  data: 0.0517  max mem: 10413
Epoch: [2]  [3460/4572]  eta: 0:01:06    time: 0.0583  data: 0.0518  max mem: 10413
Epoch: [2]  [3480/4572]  eta: 0:01:05    time: 0.0582  data: 0.0517  max mem: 10413
Epoch: [2]  [3500/4572]  eta: 0:01:03    time: 0.0587  data: 0.0522  max mem: 10413
Epoch: [2]  [3520/4572]  eta: 0:01:02    time: 0.0582  data: 0.0517  max mem: 10413
Epoch: [2]  [3540/4572]  eta: 0:01:01    time: 0.0582  data: 0.0517  max mem: 10413
Epoch: [2]  [3560/4572]  eta: 0:01:00    time: 0.0582  data: 0.0517  max mem: 10413
Epoch: [2]  [3580/4572]  eta: 0:00:59    time: 0.0582  data: 0.0517  max mem: 10413
Epoch: [2]  [3600/4572]  eta: 0:00:57    time: 0.0583  data: 0.0518  max mem: 10413
Epoch: [2]  [3620/4572]  eta: 0:00:56    time: 0.0582  data: 0.0517  max mem: 10413
Epoch: [2]  [3640/4572]  eta: 0:00:55    time: 0.0581  data: 0.0516  max mem: 10413
Epoch: [2]  [3660/4572]  eta: 0:00:54    time: 0.0596  data: 0.0532  max mem: 10413
Epoch: [2]  [3680/4572]  eta: 0:00:53    time: 0.0582  data: 0.0517  max mem: 10413
Epoch: [2]  [3700/4572]  eta: 0:00:51    time: 0.0581  data: 0.0517  max mem: 10413
Epoch: [2]  [3720/4572]  eta: 0:00:50    time: 0.0583  data: 0.0518  max mem: 10413
Epoch: [2]  [3740/4572]  eta: 0:00:49    time: 0.0582  data: 0.0517  max mem: 10413
Epoch: [2]  [3760/4572]  eta: 0:00:48    time: 0.0583  data: 0.0517  max mem: 10413
Epoch: [2]  [3780/4572]  eta: 0:00:47    time: 0.0582  data: 0.0517  max mem: 10413
Epoch: [2]  [3800/4572]  eta: 0:00:45    time: 0.0582  data: 0.0517  max mem: 10413
Epoch: [2]  [3820/4572]  eta: 0:00:44    time: 0.0582  data: 0.0517  max mem: 10413
Epoch: [2]  [3840/4572]  eta: 0:00:43    time: 0.0581  data: 0.0517  max mem: 10413
Epoch: [2]  [3860/4572]  eta: 0:00:42    time: 0.0582  data: 0.0516  max mem: 10413
Epoch: [2]  [3880/4572]  eta: 0:00:41    time: 0.0582  data: 0.0518  max mem: 10413
Epoch: [2]  [3900/4572]  eta: 0:00:39    time: 0.0582  data: 0.0517  max mem: 10413
Epoch: [2]  [3920/4572]  eta: 0:00:38    time: 0.0583  data: 0.0518  max mem: 10413
Epoch: [2]  [3940/4572]  eta: 0:00:37    time: 0.0582  data: 0.0517  max mem: 10413
Epoch: [2]  [3960/4572]  eta: 0:00:36    time: 0.0583  data: 0.0518  max mem: 10413
Epoch: [2]  [3980/4572]  eta: 0:00:35    time: 0.0583  data: 0.0518  max mem: 10413
Epoch: [2]  [4000/4572]  eta: 0:00:33    time: 0.0582  data: 0.0517  max mem: 10413
Epoch: [2]  [4020/4572]  eta: 0:00:32    time: 0.0589  data: 0.0518  max mem: 10413
Epoch: [2]  [4040/4572]  eta: 0:00:31    time: 0.0598  data: 0.0532  max mem: 10413
Epoch: [2]  [4060/4572]  eta: 0:00:30    time: 0.0581  data: 0.0516  max mem: 10413
Epoch: [2]  [4080/4572]  eta: 0:00:29    time: 0.0585  data: 0.0521  max mem: 10413
Epoch: [2]  [4100/4572]  eta: 0:00:28    time: 0.0582  data: 0.0517  max mem: 10413
Epoch: [2]  [4120/4572]  eta: 0:00:26    time: 0.0953  data: 0.0889  max mem: 10413
Epoch: [2]  [4140/4572]  eta: 0:00:25    time: 0.0582  data: 0.0517  max mem: 10413
Epoch: [2]  [4160/4572]  eta: 0:00:24    time: 0.0581  data: 0.0516  max mem: 10413
Epoch: [2]  [4180/4572]  eta: 0:00:23    time: 0.0582  data: 0.0518  max mem: 10413
Epoch: [2]  [4200/4572]  eta: 0:00:22    time: 0.0583  data: 0.0518  max mem: 10413
Epoch: [2]  [4220/4572]  eta: 0:00:20    time: 0.0582  data: 0.0517  max mem: 10413
Epoch: [2]  [4240/4572]  eta: 0:00:19    time: 0.0582  data: 0.0517  max mem: 10413
Epoch: [2]  [4260/4572]  eta: 0:00:18    time: 0.0582  data: 0.0517  max mem: 10413
Epoch: [2]  [4280/4572]  eta: 0:00:17    time: 0.0582  data: 0.0517  max mem: 10413
Epoch: [2]  [4300/4572]  eta: 0:00:16    time: 0.0580  data: 0.0515  max mem: 10413
Epoch: [2]  [4320/4572]  eta: 0:00:14    time: 0.0582  data: 0.0517  max mem: 10413
Epoch: [2]  [4340/4572]  eta: 0:00:13    time: 0.0582  data: 0.0517  max mem: 10413
Epoch: [2]  [4360/4572]  eta: 0:00:12    time: 0.0585  data: 0.0520  max mem: 10413
Epoch: [2]  [4380/4572]  eta: 0:00:11    time: 0.0582  data: 0.0518  max mem: 10413
Epoch: [2]  [4400/4572]  eta: 0:00:10    time: 0.0583  data: 0.0518  max mem: 10413
Epoch: [2]  [4420/4572]  eta: 0:00:09    time: 0.0581  data: 0.0516  max mem: 10413
Epoch: [2]  [4440/4572]  eta: 0:00:07    time: 0.0582  data: 0.0517  max mem: 10413
Epoch: [2]  [4460/4572]  eta: 0:00:06    time: 0.0583  data: 0.0517  max mem: 10413
Epoch: [2]  [4480/4572]  eta: 0:00:05    time: 0.0581  data: 0.0515  max mem: 10413
Epoch: [2]  [4500/4572]  eta: 0:00:04    time: 0.0582  data: 0.0516  max mem: 10413
Epoch: [2]  [4520/4572]  eta: 0:00:03    time: 0.0581  data: 0.0516  max mem: 10413
Epoch: [2]  [4540/4572]  eta: 0:00:01    time: 0.0582  data: 0.0517  max mem: 10413
Epoch: [2]  [4560/4572]  eta: 0:00:00    time: 0.0630  data: 0.0565  max mem: 10413
Epoch: [2]  [4571/4572]  eta: 0:00:00    time: 0.0581  data: 0.0516  max mem: 10413
Epoch: [2] Total time: 0:04:31 (0.0595 s / it)
:::MLLOG {"namespace": "", "time_ms": 1696360753654, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": 2, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 330, "epoch_num": 2}}
:::MLLOG {"namespace": "", "time_ms": 1696360753654, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 269.06262921869}, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 334, "step": 3}}
:::MLLOG {"namespace": "", "time_ms": 1696360753654, "event_type": "INTERVAL_START", "key": "eval_start", "value": 3, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 344, "epoch_num": 3}}
Test:  [ 0/97]  eta: 0:00:12  model_time: 0.1292 (0.1292)  evaluator_time: 0.0018 (0.0018)  time: 0.1317  data: 0.0006  max mem: 10413
Test:  [20/97]  eta: 0:00:10  model_time: 0.1326 (0.1334)  evaluator_time: 0.0018 (0.0018)  time: 0.1361  data: 0.0006  max mem: 10413
Test:  [40/97]  eta: 0:00:07  model_time: 0.1370 (0.1342)  evaluator_time: 0.0018 (0.0018)  time: 0.1376  data: 0.0006  max mem: 10413
Test:  [60/97]  eta: 0:00:05  model_time: 0.1364 (0.1347)  evaluator_time: 0.0018 (0.0018)  time: 0.1384  data: 0.0006  max mem: 10413
Test:  [80/97]  eta: 0:00:02  model_time: 0.1389 (0.1352)  evaluator_time: 0.0019 (0.0018)  time: 0.1393  data: 0.0006  max mem: 10413
Test:  [96/97]  eta: 0:00:00  model_time: 0.1351 (0.1347)  evaluator_time: 0.0017 (0.0018)  time: 0.1355  data: 0.0006  max mem: 10413
Test: Total time: 0:00:13 (0.1373 s / it)
Averaged stats: model_time: 0.1351 (0.1355)  evaluator_time: 0.0017 (0.0023)
:::MLLOG {"namespace": "", "time_ms": 1696360767627, "event_type": "INTERVAL_START", "key": "epoch_start", "value": 3, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 158, "epoch_num": 3}}
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
Epoch: [3]  [   0/4571]  eta: 0:04:26    time: 0.0583  data: 0.0009  max mem: 10413
Epoch: [3]  [  20/4571]  eta: 0:06:39    time: 0.0893  data: 0.0513  max mem: 10413
Epoch: [3]  [  40/4571]  eta: 0:05:33    time: 0.0585  data: 0.0520  max mem: 10413
Epoch: [3]  [  60/4571]  eta: 0:05:08    time: 0.0579  data: 0.0513  max mem: 10413
:::MLLOG {"namespace": "", "time_ms": 1696360772558, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.3332003419537206, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 437, "epoch_num": 3}}
:::MLLOG {"namespace": "", "time_ms": 1696360772558, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 3, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 438, "epoch_num": 3}}
Epoch: [3]  [  80/4571]  eta: 0:04:55    time: 0.0579  data: 0.0514  max mem: 10413
Epoch: [3]  [ 100/4571]  eta: 0:04:49    time: 0.0599  data: 0.0535  max mem: 10413
Epoch: [3]  [ 120/4571]  eta: 0:04:42    time: 0.0581  data: 0.0516  max mem: 10413
Epoch: [3]  [ 140/4571]  eta: 0:04:38    time: 0.0580  data: 0.0515  max mem: 10413
Epoch: [3]  [ 160/4571]  eta: 0:04:34    time: 0.0580  data: 0.0516  max mem: 10413
Epoch: [3]  [ 180/4571]  eta: 0:04:32    time: 0.0614  data: 0.0549  max mem: 10413
Epoch: [3]  [ 200/4571]  eta: 0:04:29    time: 0.0581  data: 0.0516  max mem: 10413
Epoch: [3]  [ 220/4571]  eta: 0:04:27    time: 0.0580  data: 0.0516  max mem: 10413
Epoch: [3]  [ 240/4571]  eta: 0:04:24    time: 0.0580  data: 0.0515  max mem: 10413
Epoch: [3]  [ 260/4571]  eta: 0:04:22    time: 0.0581  data: 0.0516  max mem: 10413
Epoch: [3]  [ 280/4571]  eta: 0:04:20    time: 0.0581  data: 0.0516  max mem: 10413
Epoch: [3]  [ 300/4571]  eta: 0:04:18    time: 0.0580  data: 0.0515  max mem: 10413
Epoch: [3]  [ 320/4571]  eta: 0:04:16    time: 0.0581  data: 0.0516  max mem: 10413
Epoch: [3]  [ 340/4571]  eta: 0:04:14    time: 0.0580  data: 0.0515  max mem: 10413
Epoch: [3]  [ 360/4571]  eta: 0:04:13    time: 0.0581  data: 0.0516  max mem: 10413
Epoch: [3]  [ 380/4571]  eta: 0:04:11    time: 0.0580  data: 0.0515  max mem: 10413
Epoch: [3]  [ 400/4571]  eta: 0:04:09    time: 0.0580  data: 0.0516  max mem: 10413
Epoch: [3]  [ 420/4571]  eta: 0:04:08    time: 0.0582  data: 0.0518  max mem: 10413
Epoch: [3]  [ 440/4571]  eta: 0:04:06    time: 0.0580  data: 0.0516  max mem: 10413
Epoch: [3]  [ 460/4571]  eta: 0:04:05    time: 0.0583  data: 0.0517  max mem: 10413
Epoch: [3]  [ 480/4571]  eta: 0:04:04    time: 0.0627  data: 0.0563  max mem: 10413
Epoch: [3]  [ 500/4571]  eta: 0:04:03    time: 0.0618  data: 0.0554  max mem: 10413
Epoch: [3]  [ 520/4571]  eta: 0:04:02    time: 0.0581  data: 0.0517  max mem: 10413
Epoch: [3]  [ 540/4571]  eta: 0:04:00    time: 0.0581  data: 0.0516  max mem: 10413
Epoch: [3]  [ 560/4571]  eta: 0:03:59    time: 0.0582  data: 0.0517  max mem: 10413
Epoch: [3]  [ 580/4571]  eta: 0:03:58    time: 0.0593  data: 0.0527  max mem: 10413
Epoch: [3]  [ 600/4571]  eta: 0:03:56    time: 0.0583  data: 0.0517  max mem: 10413
Epoch: [3]  [ 620/4571]  eta: 0:03:55    time: 0.0582  data: 0.0517  max mem: 10413
Epoch: [3]  [ 640/4571]  eta: 0:03:54    time: 0.0581  data: 0.0516  max mem: 10413
Epoch: [3]  [ 660/4571]  eta: 0:03:52    time: 0.0581  data: 0.0516  max mem: 10413
Epoch: [3]  [ 680/4571]  eta: 0:03:51    time: 0.0582  data: 0.0517  max mem: 10413
Epoch: [3]  [ 700/4571]  eta: 0:03:49    time: 0.0581  data: 0.0517  max mem: 10413
Epoch: [3]  [ 720/4571]  eta: 0:03:48    time: 0.0603  data: 0.0538  max mem: 10413
Epoch: [3]  [ 740/4571]  eta: 0:03:47    time: 0.0586  data: 0.0522  max mem: 10413
Epoch: [3]  [ 760/4571]  eta: 0:03:46    time: 0.0582  data: 0.0517  max mem: 10413
Epoch: [3]  [ 780/4571]  eta: 0:03:44    time: 0.0581  data: 0.0516  max mem: 10413
Epoch: [3]  [ 800/4571]  eta: 0:03:43    time: 0.0584  data: 0.0518  max mem: 10413
Epoch: [3]  [ 820/4571]  eta: 0:03:42    time: 0.0582  data: 0.0516  max mem: 10413
Epoch: [3]  [ 840/4571]  eta: 0:03:41    time: 0.0582  data: 0.0517  max mem: 10413
Epoch: [3]  [ 860/4571]  eta: 0:03:39    time: 0.0581  data: 0.0516  max mem: 10413
Epoch: [3]  [ 880/4571]  eta: 0:03:38    time: 0.0581  data: 0.0516  max mem: 10413
Epoch: [3]  [ 900/4571]  eta: 0:03:37    time: 0.0581  data: 0.0516  max mem: 10413
Epoch: [3]  [ 920/4571]  eta: 0:03:36    time: 0.0582  data: 0.0518  max mem: 10413
Epoch: [3]  [ 940/4571]  eta: 0:03:34    time: 0.0582  data: 0.0518  max mem: 10413
Epoch: [3]  [ 960/4571]  eta: 0:03:33    time: 0.0582  data: 0.0517  max mem: 10413
Epoch: [3]  [ 980/4571]  eta: 0:03:32    time: 0.0581  data: 0.0516  max mem: 10413
Epoch: [3]  [1000/4571]  eta: 0:03:31    time: 0.0582  data: 0.0516  max mem: 10413
Epoch: [3]  [1020/4571]  eta: 0:03:29    time: 0.0582  data: 0.0517  max mem: 10413
Epoch: [3]  [1040/4571]  eta: 0:03:28    time: 0.0584  data: 0.0519  max mem: 10413
Epoch: [3]  [1060/4571]  eta: 0:03:27    time: 0.0582  data: 0.0517  max mem: 10413
Epoch: [3]  [1080/4571]  eta: 0:03:26    time: 0.0627  data: 0.0562  max mem: 10413
Epoch: [3]  [1100/4571]  eta: 0:03:25    time: 0.0581  data: 0.0516  max mem: 10413
Epoch: [3]  [1120/4571]  eta: 0:03:23    time: 0.0582  data: 0.0517  max mem: 10413
Epoch: [3]  [1140/4571]  eta: 0:03:22    time: 0.0582  data: 0.0518  max mem: 10413
Epoch: [3]  [1160/4571]  eta: 0:03:21    time: 0.0583  data: 0.0518  max mem: 10413
Epoch: [3]  [1180/4571]  eta: 0:03:20    time: 0.0581  data: 0.0517  max mem: 10413
Epoch: [3]  [1200/4571]  eta: 0:03:18    time: 0.0582  data: 0.0516  max mem: 10413
Epoch: [3]  [1220/4571]  eta: 0:03:17    time: 0.0582  data: 0.0517  max mem: 10413
Epoch: [3]  [1240/4571]  eta: 0:03:16    time: 0.0590  data: 0.0525  max mem: 10413
Epoch: [3]  [1260/4571]  eta: 0:03:15    time: 0.0583  data: 0.0519  max mem: 10413
Epoch: [3]  [1280/4571]  eta: 0:03:14    time: 0.0589  data: 0.0524  max mem: 10413
Epoch: [3]  [1300/4571]  eta: 0:03:12    time: 0.0581  data: 0.0516  max mem: 10413
Epoch: [3]  [1320/4571]  eta: 0:03:11    time: 0.0581  data: 0.0516  max mem: 10413
Epoch: [3]  [1340/4571]  eta: 0:03:10    time: 0.0581  data: 0.0517  max mem: 10413
Epoch: [3]  [1360/4571]  eta: 0:03:09    time: 0.0582  data: 0.0517  max mem: 10413
Epoch: [3]  [1380/4571]  eta: 0:03:08    time: 0.0582  data: 0.0517  max mem: 10413
Epoch: [3]  [1400/4571]  eta: 0:03:06    time: 0.0582  data: 0.0517  max mem: 10413
Epoch: [3]  [1420/4571]  eta: 0:03:05    time: 0.0582  data: 0.0517  max mem: 10413
Epoch: [3]  [1440/4571]  eta: 0:03:04    time: 0.0584  data: 0.0519  max mem: 10413
Epoch: [3]  [1460/4571]  eta: 0:03:03    time: 0.0581  data: 0.0532  max mem: 10413
Epoch: [3]  [1480/4571]  eta: 0:03:02    time: 0.0583  data: 0.0517  max mem: 10413
Epoch: [3]  [1500/4571]  eta: 0:03:00    time: 0.0581  data: 0.0516  max mem: 10413
Epoch: [3]  [1520/4571]  eta: 0:02:59    time: 0.0581  data: 0.0516  max mem: 10413
Epoch: [3]  [1540/4571]  eta: 0:02:58    time: 0.0582  data: 0.0517  max mem: 10413
Epoch: [3]  [1560/4571]  eta: 0:02:57    time: 0.0588  data: 0.0523  max mem: 10413
Epoch: [3]  [1580/4571]  eta: 0:02:56    time: 0.0582  data: 0.0517  max mem: 10413
Epoch: [3]  [1600/4571]  eta: 0:02:54    time: 0.0582  data: 0.0517  max mem: 10413
Epoch: [3]  [1620/4571]  eta: 0:02:53    time: 0.0582  data: 0.0517  max mem: 10413
Epoch: [3]  [1640/4571]  eta: 0:02:52    time: 0.0589  data: 0.0516  max mem: 10413
Epoch: [3]  [1660/4571]  eta: 0:02:51    time: 0.0585  data: 0.0521  max mem: 10413
Epoch: [3]  [1680/4571]  eta: 0:02:50    time: 0.0582  data: 0.0517  max mem: 10413
Epoch: [3]  [1700/4571]  eta: 0:02:48    time: 0.0582  data: 0.0517  max mem: 10413
Epoch: [3]  [1720/4571]  eta: 0:02:47    time: 0.0582  data: 0.0517  max mem: 10413
Epoch: [3]  [1740/4571]  eta: 0:02:46    time: 0.0582  data: 0.0518  max mem: 10413
Epoch: [3]  [1760/4571]  eta: 0:02:45    time: 0.0581  data: 0.0517  max mem: 10413
Epoch: [3]  [1780/4571]  eta: 0:02:44    time: 0.0583  data: 0.0518  max mem: 10413
Epoch: [3]  [1800/4571]  eta: 0:02:43    time: 0.0639  data: 0.0574  max mem: 10413
Epoch: [3]  [1820/4571]  eta: 0:02:41    time: 0.0581  data: 0.0516  max mem: 10413
Epoch: [3]  [1840/4571]  eta: 0:02:40    time: 0.0582  data: 0.0517  max mem: 10413
Epoch: [3]  [1860/4571]  eta: 0:02:39    time: 0.0582  data: 0.0516  max mem: 10413
Epoch: [3]  [1880/4571]  eta: 0:02:38    time: 0.0581  data: 0.0516  max mem: 10413
Epoch: [3]  [1900/4571]  eta: 0:02:37    time: 0.0581  data: 0.0516  max mem: 10413
Epoch: [3]  [1920/4571]  eta: 0:02:35    time: 0.0582  data: 0.0517  max mem: 10413
Epoch: [3]  [1940/4571]  eta: 0:02:34    time: 0.0580  data: 0.0515  max mem: 10413
Epoch: [3]  [1960/4571]  eta: 0:02:33    time: 0.0581  data: 0.0516  max mem: 10413
Epoch: [3]  [1980/4571]  eta: 0:02:32    time: 0.0582  data: 0.0517  max mem: 10413
Epoch: [3]  [2000/4571]  eta: 0:02:31    time: 0.0582  data: 0.0517  max mem: 10413
Epoch: [3]  [2020/4571]  eta: 0:02:29    time: 0.0582  data: 0.0517  max mem: 10413
Epoch: [3]  [2040/4571]  eta: 0:02:28    time: 0.0594  data: 0.0517  max mem: 10413
Epoch: [3]  [2060/4571]  eta: 0:02:27    time: 0.0581  data: 0.0516  max mem: 10413
Corrupt JPEG data: premature end of data segment
Epoch: [3]  [2080/4571]  eta: 0:02:26    time: 0.0597  data: 0.0532  max mem: 10413
Epoch: [3]  [2100/4571]  eta: 0:02:25    time: 0.0582  data: 0.0517  max mem: 10413
Epoch: [3]  [2120/4571]  eta: 0:02:24    time: 0.0643  data: 0.0578  max mem: 10413
Epoch: [3]  [2140/4571]  eta: 0:02:22    time: 0.0583  data: 0.0518  max mem: 10413
Epoch: [3]  [2160/4571]  eta: 0:02:21    time: 0.0580  data: 0.0515  max mem: 10413
Epoch: [3]  [2180/4571]  eta: 0:02:20    time: 0.0581  data: 0.0516  max mem: 10413
Epoch: [3]  [2200/4571]  eta: 0:02:19    time: 0.0581  data: 0.0516  max mem: 10413
Epoch: [3]  [2220/4571]  eta: 0:02:18    time: 0.0582  data: 0.0516  max mem: 10413
Epoch: [3]  [2240/4571]  eta: 0:02:17    time: 0.0623  data: 0.0558  max mem: 10413
Epoch: [3]  [2260/4571]  eta: 0:02:15    time: 0.0582  data: 0.0517  max mem: 10413
Epoch: [3]  [2280/4571]  eta: 0:02:14    time: 0.0582  data: 0.0517  max mem: 10413
Epoch: [3]  [2300/4571]  eta: 0:02:13    time: 0.0582  data: 0.0517  max mem: 10413
Epoch: [3]  [2320/4571]  eta: 0:02:12    time: 0.0617  data: 0.0552  max mem: 10413
Epoch: [3]  [2340/4571]  eta: 0:02:11    time: 0.0580  data: 0.0515  max mem: 10413
Epoch: [3]  [2360/4571]  eta: 0:02:10    time: 0.0582  data: 0.0517  max mem: 10413
Epoch: [3]  [2380/4571]  eta: 0:02:08    time: 0.0581  data: 0.0516  max mem: 10413
Epoch: [3]  [2400/4571]  eta: 0:02:07    time: 0.0583  data: 0.0518  max mem: 10413
Epoch: [3]  [2420/4571]  eta: 0:02:06    time: 0.0582  data: 0.0517  max mem: 10413
Epoch: [3]  [2440/4571]  eta: 0:02:05    time: 0.0581  data: 0.0516  max mem: 10413
Epoch: [3]  [2460/4571]  eta: 0:02:04    time: 0.0581  data: 0.0516  max mem: 10413
Epoch: [3]  [2480/4571]  eta: 0:02:02    time: 0.0581  data: 0.0516  max mem: 10413
Epoch: [3]  [2500/4571]  eta: 0:02:01    time: 0.0630  data: 0.0564  max mem: 10413
Epoch: [3]  [2520/4571]  eta: 0:02:00    time: 0.0581  data: 0.0515  max mem: 10413
Epoch: [3]  [2540/4571]  eta: 0:01:59    time: 0.0596  data: 0.0516  max mem: 10413
Epoch: [3]  [2560/4571]  eta: 0:01:58    time: 0.0581  data: 0.0516  max mem: 10413
Epoch: [3]  [2580/4571]  eta: 0:01:57    time: 0.0582  data: 0.0516  max mem: 10413
Epoch: [3]  [2600/4571]  eta: 0:01:55    time: 0.0581  data: 0.0516  max mem: 10413
Epoch: [3]  [2620/4571]  eta: 0:01:54    time: 0.0582  data: 0.0517  max mem: 10413
Epoch: [3]  [2640/4571]  eta: 0:01:53    time: 0.0581  data: 0.0517  max mem: 10413
Epoch: [3]  [2660/4571]  eta: 0:01:52    time: 0.0581  data: 0.0516  max mem: 10413
Epoch: [3]  [2680/4571]  eta: 0:01:51    time: 0.0582  data: 0.0517  max mem: 10413
Epoch: [3]  [2700/4571]  eta: 0:01:49    time: 0.0582  data: 0.0517  max mem: 10413
Epoch: [3]  [2720/4571]  eta: 0:01:48    time: 0.0581  data: 0.0516  max mem: 10413
Epoch: [3]  [2740/4571]  eta: 0:01:47    time: 0.0582  data: 0.0517  max mem: 10413
Epoch: [3]  [2760/4571]  eta: 0:01:46    time: 0.0582  data: 0.0517  max mem: 10413
Epoch: [3]  [2780/4571]  eta: 0:01:45    time: 0.0582  data: 0.0517  max mem: 10413
Epoch: [3]  [2800/4571]  eta: 0:01:44    time: 0.0602  data: 0.0526  max mem: 10413
Epoch: [3]  [2820/4571]  eta: 0:01:42    time: 0.0581  data: 0.0516  max mem: 10413
Epoch: [3]  [2840/4571]  eta: 0:01:41    time: 0.0581  data: 0.0516  max mem: 10413
Epoch: [3]  [2860/4571]  eta: 0:01:40    time: 0.0603  data: 0.0538  max mem: 10413
Epoch: [3]  [2880/4571]  eta: 0:01:39    time: 0.0582  data: 0.0517  max mem: 10413
Epoch: [3]  [2900/4571]  eta: 0:01:38    time: 0.0582  data: 0.0516  max mem: 10413
Epoch: [3]  [2920/4571]  eta: 0:01:37    time: 0.0582  data: 0.0517  max mem: 10413
Epoch: [3]  [2940/4571]  eta: 0:01:35    time: 0.0581  data: 0.0517  max mem: 10413
Epoch: [3]  [2960/4571]  eta: 0:01:34    time: 0.0582  data: 0.0517  max mem: 10413
Epoch: [3]  [2980/4571]  eta: 0:01:33    time: 0.0580  data: 0.0515  max mem: 10413
Epoch: [3]  [3000/4571]  eta: 0:01:32    time: 0.0592  data: 0.0527  max mem: 10413
Epoch: [3]  [3020/4571]  eta: 0:01:31    time: 0.0581  data: 0.0516  max mem: 10413
Epoch: [3]  [3040/4571]  eta: 0:01:29    time: 0.0606  data: 0.0541  max mem: 10413
Epoch: [3]  [3060/4571]  eta: 0:01:28    time: 0.0581  data: 0.0516  max mem: 10413
Epoch: [3]  [3080/4571]  eta: 0:01:27    time: 0.0582  data: 0.0517  max mem: 10413
Epoch: [3]  [3100/4571]  eta: 0:01:26    time: 0.0582  data: 0.0516  max mem: 10413
Epoch: [3]  [3120/4571]  eta: 0:01:25    time: 0.0582  data: 0.0518  max mem: 10413
Epoch: [3]  [3140/4571]  eta: 0:01:24    time: 0.0581  data: 0.0516  max mem: 10413
Epoch: [3]  [3160/4571]  eta: 0:01:22    time: 0.0581  data: 0.0516  max mem: 10413
Epoch: [3]  [3180/4571]  eta: 0:01:21    time: 0.0581  data: 0.0516  max mem: 10413
Epoch: [3]  [3200/4571]  eta: 0:01:20    time: 0.0583  data: 0.0517  max mem: 10413
Epoch: [3]  [3220/4571]  eta: 0:01:19    time: 0.0612  data: 0.0547  max mem: 10413
Epoch: [3]  [3240/4571]  eta: 0:01:18    time: 0.0581  data: 0.0516  max mem: 10413
Epoch: [3]  [3260/4571]  eta: 0:01:17    time: 0.0581  data: 0.0516  max mem: 10413
Epoch: [3]  [3280/4571]  eta: 0:01:15    time: 0.0581  data: 0.0516  max mem: 10413
Epoch: [3]  [3300/4571]  eta: 0:01:14    time: 0.0581  data: 0.0516  max mem: 10413
Epoch: [3]  [3320/4571]  eta: 0:01:13    time: 0.0581  data: 0.0515  max mem: 10413
Epoch: [3]  [3340/4571]  eta: 0:01:12    time: 0.0582  data: 0.0517  max mem: 10413
Epoch: [3]  [3360/4571]  eta: 0:01:11    time: 0.0596  data: 0.0531  max mem: 10413
Epoch: [3]  [3380/4571]  eta: 0:01:09    time: 0.0584  data: 0.0520  max mem: 10413
Epoch: [3]  [3400/4571]  eta: 0:01:08    time: 0.0581  data: 0.0516  max mem: 10413
Epoch: [3]  [3420/4571]  eta: 0:01:07    time: 0.0582  data: 0.0517  max mem: 10413
Epoch: [3]  [3440/4571]  eta: 0:01:06    time: 0.0589  data: 0.0524  max mem: 10413
Epoch: [3]  [3460/4571]  eta: 0:01:05    time: 0.0582  data: 0.0517  max mem: 10413
Epoch: [3]  [3480/4571]  eta: 0:01:04    time: 0.0581  data: 0.0516  max mem: 10413
Epoch: [3]  [3500/4571]  eta: 0:01:02    time: 0.0581  data: 0.0516  max mem: 10413
Epoch: [3]  [3520/4571]  eta: 0:01:01    time: 0.0581  data: 0.0517  max mem: 10413
Epoch: [3]  [3540/4571]  eta: 0:01:00    time: 0.0610  data: 0.0546  max mem: 10413
Epoch: [3]  [3560/4571]  eta: 0:00:59    time: 0.0583  data: 0.0518  max mem: 10413
Epoch: [3]  [3580/4571]  eta: 0:00:58    time: 0.0580  data: 0.0516  max mem: 10413
Epoch: [3]  [3600/4571]  eta: 0:00:57    time: 0.0580  data: 0.0516  max mem: 10413
Epoch: [3]  [3620/4571]  eta: 0:00:55    time: 0.0582  data: 0.0517  max mem: 10413
Epoch: [3]  [3640/4571]  eta: 0:00:54    time: 0.0581  data: 0.0516  max mem: 10413
Epoch: [3]  [3660/4571]  eta: 0:00:53    time: 0.0583  data: 0.0517  max mem: 10413
Epoch: [3]  [3680/4571]  eta: 0:00:52    time: 0.0581  data: 0.0516  max mem: 10413
Epoch: [3]  [3700/4571]  eta: 0:00:51    time: 0.0581  data: 0.0516  max mem: 10413
Epoch: [3]  [3720/4571]  eta: 0:00:49    time: 0.0580  data: 0.0515  max mem: 10413
Epoch: [3]  [3740/4571]  eta: 0:00:48    time: 0.0605  data: 0.0540  max mem: 10413
Epoch: [3]  [3760/4571]  eta: 0:00:47    time: 0.0580  data: 0.0516  max mem: 10413
Epoch: [3]  [3780/4571]  eta: 0:00:46    time: 0.0582  data: 0.0517  max mem: 10413
Epoch: [3]  [3800/4571]  eta: 0:00:45    time: 0.0581  data: 0.0516  max mem: 10413
Epoch: [3]  [3820/4571]  eta: 0:00:44    time: 0.0580  data: 0.0515  max mem: 10413
Epoch: [3]  [3840/4571]  eta: 0:00:42    time: 0.0613  data: 0.0548  max mem: 10413
Epoch: [3]  [3860/4571]  eta: 0:00:41    time: 0.0592  data: 0.0526  max mem: 10413
Epoch: [3]  [3880/4571]  eta: 0:00:40    time: 0.0588  data: 0.0523  max mem: 10413
Epoch: [3]  [3900/4571]  eta: 0:00:39    time: 0.0581  data: 0.0516  max mem: 10413
Epoch: [3]  [3920/4571]  eta: 0:00:38    time: 0.0581  data: 0.0516  max mem: 10413
Epoch: [3]  [3940/4571]  eta: 0:00:37    time: 0.0580  data: 0.0516  max mem: 10413
Epoch: [3]  [3960/4571]  eta: 0:00:35    time: 0.0582  data: 0.0517  max mem: 10413
Epoch: [3]  [3980/4571]  eta: 0:00:34    time: 0.0581  data: 0.0516  max mem: 10413
Epoch: [3]  [4000/4571]  eta: 0:00:33    time: 0.0581  data: 0.0516  max mem: 10413
Epoch: [3]  [4020/4571]  eta: 0:00:32    time: 0.0583  data: 0.0518  max mem: 10413
Epoch: [3]  [4040/4571]  eta: 0:00:31    time: 0.0580  data: 0.0515  max mem: 10413
Epoch: [3]  [4060/4571]  eta: 0:00:29    time: 0.0581  data: 0.0516  max mem: 10413
Epoch: [3]  [4080/4571]  eta: 0:00:28    time: 0.0613  data: 0.0548  max mem: 10413
Epoch: [3]  [4100/4571]  eta: 0:00:27    time: 0.0582  data: 0.0517  max mem: 10413
Epoch: [3]  [4120/4571]  eta: 0:00:26    time: 0.0581  data: 0.0516  max mem: 10413
Epoch: [3]  [4140/4571]  eta: 0:00:25    time: 0.0581  data: 0.0515  max mem: 10413
Epoch: [3]  [4160/4571]  eta: 0:00:24    time: 0.0580  data: 0.0515  max mem: 10413
Epoch: [3]  [4180/4571]  eta: 0:00:22    time: 0.0586  data: 0.0522  max mem: 10413
Epoch: [3]  [4200/4571]  eta: 0:00:21    time: 0.0580  data: 0.0515  max mem: 10413
Epoch: [3]  [4220/4571]  eta: 0:00:20    time: 0.0582  data: 0.0517  max mem: 10413
Epoch: [3]  [4240/4571]  eta: 0:00:19    time: 0.0581  data: 0.0515  max mem: 10413
Epoch: [3]  [4260/4571]  eta: 0:00:18    time: 0.0586  data: 0.0521  max mem: 10413
Epoch: [3]  [4280/4571]  eta: 0:00:17    time: 0.0580  data: 0.0515  max mem: 10413
Epoch: [3]  [4300/4571]  eta: 0:00:15    time: 0.0581  data: 0.0516  max mem: 10413
Epoch: [3]  [4320/4571]  eta: 0:00:14    time: 0.0608  data: 0.0543  max mem: 10413
Epoch: [3]  [4340/4571]  eta: 0:00:13    time: 0.0581  data: 0.0516  max mem: 10413
Epoch: [3]  [4360/4571]  eta: 0:00:12    time: 0.0580  data: 0.0515  max mem: 10413
Epoch: [3]  [4380/4571]  eta: 0:00:11    time: 0.0581  data: 0.0516  max mem: 10413
Epoch: [3]  [4400/4571]  eta: 0:00:10    time: 0.0581  data: 0.0516  max mem: 10413
Epoch: [3]  [4420/4571]  eta: 0:00:08    time: 0.0581  data: 0.0516  max mem: 10413
Epoch: [3]  [4440/4571]  eta: 0:00:07    time: 0.0581  data: 0.0516  max mem: 10413
Epoch: [3]  [4460/4571]  eta: 0:00:06    time: 0.0581  data: 0.0516  max mem: 10413
Epoch: [3]  [4480/4571]  eta: 0:00:05    time: 0.0582  data: 0.0517  max mem: 10413
Epoch: [3]  [4500/4571]  eta: 0:00:04    time: 0.0581  data: 0.0516  max mem: 10413
Epoch: [3]  [4520/4571]  eta: 0:00:02    time: 0.0582  data: 0.0516  max mem: 10413
Epoch: [3]  [4540/4571]  eta: 0:00:01    time: 0.0590  data: 0.0525  max mem: 10413
Epoch: [3]  [4560/4571]  eta: 0:00:00    time: 0.0581  data: 0.0516  max mem: 10413
Epoch: [3]  [4570/4571]  eta: 0:00:00    time: 0.0581  data: 0.0516  max mem: 10413
Epoch: [3] Total time: 0:04:28 (0.0586 s / it)
:::MLLOG {"namespace": "", "time_ms": 1696361035827, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": 3, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 330, "epoch_num": 3}}
:::MLLOG {"namespace": "", "time_ms": 1696361035827, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 272.80747370628876}, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 334, "step": 4}}
:::MLLOG {"namespace": "", "time_ms": 1696361035827, "event_type": "INTERVAL_START", "key": "eval_start", "value": 4, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 344, "epoch_num": 4}}
Test:  [ 0/97]  eta: 0:00:12  model_time: 0.1298 (0.1298)  evaluator_time: 0.0017 (0.0017)  time: 0.1322  data: 0.0006  max mem: 10413
Test:  [20/97]  eta: 0:00:10  model_time: 0.1310 (0.1311)  evaluator_time: 0.0017 (0.0017)  time: 0.1336  data: 0.0006  max mem: 10413
Test:  [40/97]  eta: 0:00:07  model_time: 0.1324 (0.1318)  evaluator_time: 0.0017 (0.0018)  time: 0.1349  data: 0.0006  max mem: 10413
Test:  [60/97]  eta: 0:00:04  model_time: 0.1351 (0.1320)  evaluator_time: 0.0016 (0.0017)  time: 0.1348  data: 0.0006  max mem: 10413
Test:  [80/97]  eta: 0:00:02  model_time: 0.1316 (0.1319)  evaluator_time: 0.0018 (0.0017)  time: 0.1342  data: 0.0006  max mem: 10413
Test:  [96/97]  eta: 0:00:00  model_time: 0.1303 (0.1315)  evaluator_time: 0.0017 (0.0017)  time: 0.1323  data: 0.0006  max mem: 10413
Test: Total time: 0:00:12 (0.1340 s / it)
Averaged stats: model_time: 0.1303 (0.1323)  evaluator_time: 0.0017 (0.0018)
:::MLLOG {"namespace": "", "time_ms": 1696361049349, "event_type": "INTERVAL_START", "key": "epoch_start", "value": 4, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 158, "epoch_num": 4}}
Epoch: [4]  [   0/4572]  eta: 0:04:26    time: 0.0582  data: 0.0008  max mem: 10413
Epoch: [4]  [  20/4572]  eta: 0:04:23    time: 0.0578  data: 0.0512  max mem: 10413
Epoch: [4]  [  40/4572]  eta: 0:04:21    time: 0.0577  data: 0.0512  max mem: 10413
Epoch: [4]  [  60/4572]  eta: 0:04:20    time: 0.0579  data: 0.0513  max mem: 10413
:::MLLOG {"namespace": "", "time_ms": 1696361054030, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.352776641064232, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 437, "epoch_num": 4}}
:::MLLOG {"namespace": "", "time_ms": 1696361054030, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 4, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 438, "epoch_num": 4}}
Epoch: [4]  [  80/4572]  eta: 0:04:21    time: 0.0594  data: 0.0529  max mem: 10413
:::MLLOG {"namespace": "", "time_ms": 1696361055223, "event_type": "INTERVAL_END", "key": "run_stop", "value": null, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 315, "status": "success"}}
:::MLLOG {"namespace": "", "time_ms": 1696361055224, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": 4, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 330, "epoch_num": 4}}
:::MLLOG {"namespace": "", "time_ms": 1696361055224, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 280.594983490567}, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 334, "step": 5}}
Run time 0:19:16
:::MLLOG {"namespace": "", "time_ms": 1696361055224, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 773}}
:::MLLOG {"namespace": "", "time_ms": 1696361055224, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 773}}
:::MLLOG {"namespace": "", "time_ms": 1696361055224, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 773}}
:::MLLOG {"namespace": "", "time_ms": 1696361055225, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 773}}
:::MLLOG {"namespace": "", "time_ms": 1696361055225, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 773}}
:::MLLOG {"namespace": "", "time_ms": 1696361055224, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 773}}
:::MLLOG {"namespace": "", "time_ms": 1696361055225, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 773}}
:::MLLOG {"namespace": "", "time_ms": 1696361055225, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 773}}
:::MLLOG {"namespace": "", "time_ms": 1696361055220, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 773}}
:::MLLOG {"namespace": "", "time_ms": 1696361055220, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 773}}
:::MLLOG {"namespace": "", "time_ms": 1696361055220, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 773}}
:::MLLOG {"namespace": "", "time_ms": 1696361055220, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 773}}
:::MLLOG {"namespace": "", "time_ms": 1696361055220, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 773}}
:::MLLOG {"namespace": "", "time_ms": 1696361055220, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 773}}
:::MLLOG {"namespace": "", "time_ms": 1696361055220, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 773}}
:::MLLOG {"namespace": "", "time_ms": 1696361055220, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 773}}
Loading annotations into memory...
Done (t=0.72s)
Creating index...
Done (t=1.22s)
Loading and preparing results...
DONE (t=2.85s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=2.21s).
Accumulating evaluation results...
DONE (t=0.00s).
IoU metric: bbox
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.24099
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.36954
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.25581
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.00636
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.06025
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.26678
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.36033
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.51593
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.53847
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.02737
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.20862
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.58664
Loading and preparing results...
DONE (t=2.68s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=2.46s).
Accumulating evaluation results...
DONE (t=0.00s).
IoU metric: bbox
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.29951
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.44282
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.31990
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.00683
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.08453
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.33205
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.38307
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.55120
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.57897
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.03607
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.23227
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.63011
Loading and preparing results...
DONE (t=2.46s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=2.28s).
Accumulating evaluation results...
DONE (t=0.00s).
IoU metric: bbox
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.33320
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.47822
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.35863
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.00965
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.09356
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.36837
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.40036
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.57084
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.60044
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.03736
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.25671
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.65198
Loading and preparing results...
DONE (t=2.30s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=2.23s).
Accumulating evaluation results...
DONE (t=0.00s).
IoU metric: bbox
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.35278
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.49641
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.37836
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.01133
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.10009
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.39131
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.41301
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.58896
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.61612
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.04153
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.27166
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.66824
ENDING TIMING RUN AT 2023-10-03 07:24:19 PM
RESULT,SINGLE_STAGE_DETECTOR,,1252,dell,2023-10-03 07:03:27 PM
ENDING TIMING RUN AT 2023-10-03 07:24:20 PM
RESULT,SINGLE_STAGE_DETECTOR,,1253,dell,2023-10-03 07:03:27 PM
ENDING TIMING RUN AT 2023-10-03 07:24:20 PM
RESULT,SINGLE_STAGE_DETECTOR,,1253,dell,2023-10-03 07:03:27 PM
ENDING TIMING RUN AT 2023-10-03 07:24:20 PM
RESULT,SINGLE_STAGE_DETECTOR,,1253,dell,2023-10-03 07:03:27 PM
ENDING TIMING RUN AT 2023-10-03 07:24:20 PM
RESULT,SINGLE_STAGE_DETECTOR,,1253,dell,2023-10-03 07:03:27 PM
ENDING TIMING RUN AT 2023-10-03 07:24:20 PM
RESULT,SINGLE_STAGE_DETECTOR,,1253,dell,2023-10-03 07:03:27 PM
ENDING TIMING RUN AT 2023-10-03 07:24:20 PM
RESULT,SINGLE_STAGE_DETECTOR,,1253,dell,2023-10-03 07:03:27 PM
ENDING TIMING RUN AT 2023-10-03 07:24:20 PM
RESULT,SINGLE_STAGE_DETECTOR,,1253,dell,2023-10-03 07:03:27 PM
ENDING TIMING RUN AT 2023-10-03 07:24:21 PM
RESULT,SINGLE_STAGE_DETECTOR,,1254,dell,2023-10-03 07:03:27 PM
ENDING TIMING RUN AT 2023-10-03 07:24:21 PM
RESULT,SINGLE_STAGE_DETECTOR,,1254,dell,2023-10-03 07:03:27 PM
ENDING TIMING RUN AT 2023-10-03 07:24:21 PM
RESULT,SINGLE_STAGE_DETECTOR,,1254,dell,2023-10-03 07:03:27 PM
ENDING TIMING RUN AT 2023-10-03 07:24:21 PM
RESULT,SINGLE_STAGE_DETECTOR,,1254,dell,2023-10-03 07:03:27 PM
ENDING TIMING RUN AT 2023-10-03 07:24:21 PM
RESULT,SINGLE_STAGE_DETECTOR,,1254,dell,2023-10-03 07:03:27 PM
ENDING TIMING RUN AT 2023-10-03 07:24:21 PM
RESULT,SINGLE_STAGE_DETECTOR,,1254,dell,2023-10-03 07:03:27 PM
ENDING TIMING RUN AT 2023-10-03 07:24:21 PM
RESULT,SINGLE_STAGE_DETECTOR,,1254,dell,2023-10-03 07:03:27 PM
ENDING TIMING RUN AT 2023-10-03 07:24:22 PM
RESULT,SINGLE_STAGE_DETECTOR,,1255,dell,2023-10-03 07:03:27 PM
