+ echo 'Beginning trial 4 of 5'
Beginning trial 4 of 5
+ echo ':::DLPAL dockerd://mlperf-dell:single_stage_detector 106 2 xe9680node[30,70] '\''unknown'\'' XE9680_002x08x016'
:::DLPAL dockerd://mlperf-dell:single_stage_detector 106 2 xe9680node[30,70] 'unknown' XE9680_002x08x016
+ srun -N1 -n1 --container-name=single_stage_detector_106 python -c ''
+ '[' 1 -eq 1 ']'
+ srun --ntasks=2 bash -c 'echo -n '\''Clearing cache on '\'' && hostname && sync && sudo /sbin/sysctl vm.drop_caches=3'
Clearing cache on xe9680node70
Clearing cache on xe9680node30
vm.drop_caches = 3
vm.drop_caches = 3
+ srun --ntasks=2 --container-name=single_stage_detector_106 python -c '
from mlperf_logger import mllogger
mllogger.event(key=mllogger.constants.CACHE_CLEAR, value=True)'
:::MLLOG {"namespace": "", "time_ms": 1696363793061, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1696363793132, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
+ sleep 30
+ srun --ntasks=16 --ntasks-per-node=8 --container-name=single_stage_detector_106 --container-mounts=/xe9680_nvme1n1/training_datasets_v3.0/ssd:/datasets/open-images-v6,/root/mlperf_training/ssd/:/results,/xe9680_nvme1n1/training_datasets_v3.0/ssd/train/:/root/.cache/torch --container-workdir=/workspace/ssd slurm2pytorch ./run_and_time.sh
STARTING TIMING RUN AT 2023-10-03 08:10:23 PM
RANK 15: LOCAL_RANK 7, MASTER_ADDR xe9680node30, MASTER_PORT 49258, WORLD_SIZE 16, MLPERF_SLURM_FIRSTNODE xe9680node30, SLURM_JOB_ID 106, SLURM_NTASKS 16, SLURM_PROCID 15, SLURM_LOCALID 7, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2023-10-03 08:10:23 PM
RANK 9: LOCAL_RANK 1, MASTER_ADDR xe9680node30, MASTER_PORT 49258, WORLD_SIZE 16, MLPERF_SLURM_FIRSTNODE xe9680node30, SLURM_JOB_ID 106, SLURM_NTASKS 16, SLURM_PROCID 9, SLURM_LOCALID 1, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2023-10-03 08:10:23 PM
RANK 11: LOCAL_RANK 3, MASTER_ADDR xe9680node30, MASTER_PORT 49258, WORLD_SIZE 16, MLPERF_SLURM_FIRSTNODE xe9680node30, SLURM_JOB_ID 106, SLURM_NTASKS 16, SLURM_PROCID 11, SLURM_LOCALID 3, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2023-10-03 08:10:23 PM
STARTING TIMING RUN AT 2023-10-03 08:10:23 PM
RANK 14: LOCAL_RANK 6, MASTER_ADDR xe9680node30, MASTER_PORT 49258, WORLD_SIZE 16, MLPERF_SLURM_FIRSTNODE xe9680node30, SLURM_JOB_ID 106, SLURM_NTASKS 16, SLURM_PROCID 14, SLURM_LOCALID 6, OMP_NUM_THREADS 1
RANK 8: LOCAL_RANK 0, MASTER_ADDR xe9680node30, MASTER_PORT 49258, WORLD_SIZE 16, MLPERF_SLURM_FIRSTNODE xe9680node30, SLURM_JOB_ID 106, SLURM_NTASKS 16, SLURM_PROCID 8, SLURM_LOCALID 0, OMP_NUM_THREADS 1
running benchmark
running benchmark
STARTING TIMING RUN AT 2023-10-03 08:10:23 PM
STARTING TIMING RUN AT 2023-10-03 08:10:23 PM
STARTING TIMING RUN AT 2023-10-03 08:10:23 PM
RANK 12: LOCAL_RANK 4, MASTER_ADDR xe9680node30, MASTER_PORT 49258, WORLD_SIZE 16, MLPERF_SLURM_FIRSTNODE xe9680node30, SLURM_JOB_ID 106, SLURM_NTASKS 16, SLURM_PROCID 12, SLURM_LOCALID 4, OMP_NUM_THREADS 1
RANK 10: LOCAL_RANK 2, MASTER_ADDR xe9680node30, MASTER_PORT 49258, WORLD_SIZE 16, MLPERF_SLURM_FIRSTNODE xe9680node30, SLURM_JOB_ID 106, SLURM_NTASKS 16, SLURM_PROCID 10, SLURM_LOCALID 2, OMP_NUM_THREADS 1
running benchmark
running benchmark
RANK 13: LOCAL_RANK 5, MASTER_ADDR xe9680node30, MASTER_PORT 49258, WORLD_SIZE 16, MLPERF_SLURM_FIRSTNODE xe9680node30, SLURM_JOB_ID 106, SLURM_NTASKS 16, SLURM_PROCID 13, SLURM_LOCALID 5, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2023-10-03 08:10:23 PM
STARTING TIMING RUN AT 2023-10-03 08:10:23 PM
RANK 7: LOCAL_RANK 7, MASTER_ADDR xe9680node30, MASTER_PORT 49258, WORLD_SIZE 16, MLPERF_SLURM_FIRSTNODE xe9680node30, SLURM_JOB_ID 106, SLURM_NTASKS 16, SLURM_PROCID 7, SLURM_LOCALID 7, OMP_NUM_THREADS 1
running benchmark
RANK 6: LOCAL_RANK 6, MASTER_ADDR xe9680node30, MASTER_PORT 49258, WORLD_SIZE 16, MLPERF_SLURM_FIRSTNODE xe9680node30, SLURM_JOB_ID 106, SLURM_NTASKS 16, SLURM_PROCID 6, SLURM_LOCALID 6, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2023-10-03 08:10:23 PM
RANK 1: LOCAL_RANK 1, MASTER_ADDR xe9680node30, MASTER_PORT 49258, WORLD_SIZE 16, MLPERF_SLURM_FIRSTNODE xe9680node30, SLURM_JOB_ID 106, SLURM_NTASKS 16, SLURM_PROCID 1, SLURM_LOCALID 1, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2023-10-03 08:10:23 PM
RANK 0: LOCAL_RANK 0, MASTER_ADDR xe9680node30, MASTER_PORT 49258, WORLD_SIZE 16, MLPERF_SLURM_FIRSTNODE xe9680node30, SLURM_JOB_ID 106, SLURM_NTASKS 16, SLURM_PROCID 0, SLURM_LOCALID 0, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2023-10-03 08:10:23 PM
STARTING TIMING RUN AT 2023-10-03 08:10:23 PM
RANK 2: LOCAL_RANK 2, MASTER_ADDR xe9680node30, MASTER_PORT 49258, WORLD_SIZE 16, MLPERF_SLURM_FIRSTNODE xe9680node30, SLURM_JOB_ID 106, SLURM_NTASKS 16, SLURM_PROCID 2, SLURM_LOCALID 2, OMP_NUM_THREADS 1
running benchmark
RANK 4: LOCAL_RANK 4, MASTER_ADDR xe9680node30, MASTER_PORT 49258, WORLD_SIZE 16, MLPERF_SLURM_FIRSTNODE xe9680node30, SLURM_JOB_ID 106, SLURM_NTASKS 16, SLURM_PROCID 4, SLURM_LOCALID 4, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2023-10-03 08:10:24 PM
STARTING TIMING RUN AT 2023-10-03 08:10:24 PM
RANK 5: LOCAL_RANK 5, MASTER_ADDR xe9680node30, MASTER_PORT 49258, WORLD_SIZE 16, MLPERF_SLURM_FIRSTNODE xe9680node30, SLURM_JOB_ID 106, SLURM_NTASKS 16, SLURM_PROCID 5, SLURM_LOCALID 5, OMP_NUM_THREADS 1
running benchmark
RANK 3: LOCAL_RANK 3, MASTER_ADDR xe9680node30, MASTER_PORT 49258, WORLD_SIZE 16, MLPERF_SLURM_FIRSTNODE xe9680node30, SLURM_JOB_ID 106, SLURM_NTASKS 16, SLURM_PROCID 3, SLURM_LOCALID 3, OMP_NUM_THREADS 1
running benchmark
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=52
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=52
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=52
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=52
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=52
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=52
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=52
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=52
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=52
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=52
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=52
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=52
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=52
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=52
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=52
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=52
Matplotlib created a temporary cache directory at /tmp/matplotlib-d9rs7i8i because the default path (/root/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
Matplotlib created a temporary cache directory at /tmp/matplotlib-d4ljdpyz because the default path (/root/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
/usr/local/lib/python3.10/dist-packages/torch/jit/annotations.py:386: UserWarning: TorchScript will treat type annotations of Tensor dtype-specific subtypes as if they are normal Tensors. dtype constraints are not enforced in compilation either.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/jit/annotations.py:386: UserWarning: TorchScript will treat type annotations of Tensor dtype-specific subtypes as if they are normal Tensors. dtype constraints are not enforced in compilation either.
  warnings.warn(
Matplotlib created a temporary cache directory at /tmp/matplotlib-ccfqjz3y because the default path (/root/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
/usr/local/lib/python3.10/dist-packages/torch/jit/annotations.py:386: UserWarning: TorchScript will treat type annotations of Tensor dtype-specific subtypes as if they are normal Tensors. dtype constraints are not enforced in compilation either.
  warnings.warn(
Matplotlib created a temporary cache directory at /tmp/matplotlib-n2cwkbpg because the default path (/root/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
Matplotlib created a temporary cache directory at /tmp/matplotlib-kw8ysh9w because the default path (/root/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
/usr/local/lib/python3.10/dist-packages/torch/jit/annotations.py:386: UserWarning: TorchScript will treat type annotations of Tensor dtype-specific subtypes as if they are normal Tensors. dtype constraints are not enforced in compilation either.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/jit/annotations.py:386: UserWarning: TorchScript will treat type annotations of Tensor dtype-specific subtypes as if they are normal Tensors. dtype constraints are not enforced in compilation either.
  warnings.warn(
Matplotlib created a temporary cache directory at /tmp/matplotlib-u_vtazw_ because the default path (/root/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
/usr/local/lib/python3.10/dist-packages/torch/jit/annotations.py:386: UserWarning: TorchScript will treat type annotations of Tensor dtype-specific subtypes as if they are normal Tensors. dtype constraints are not enforced in compilation either.
  warnings.warn(
Matplotlib created a temporary cache directory at /tmp/matplotlib-zdgyvlw6 because the default path (/root/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
Matplotlib created a temporary cache directory at /tmp/matplotlib-db24ypxi because the default path (/root/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
Matplotlib created a temporary cache directory at /tmp/matplotlib-0f64dtzy because the default path (/root/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
Matplotlib created a temporary cache directory at /tmp/matplotlib-u65j5one because the default path (/root/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
Matplotlib created a temporary cache directory at /tmp/matplotlib-2gk3ewbx because the default path (/root/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
/usr/local/lib/python3.10/dist-packages/torch/jit/annotations.py:386: UserWarning: TorchScript will treat type annotations of Tensor dtype-specific subtypes as if they are normal Tensors. dtype constraints are not enforced in compilation either.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/jit/annotations.py:386: UserWarning: TorchScript will treat type annotations of Tensor dtype-specific subtypes as if they are normal Tensors. dtype constraints are not enforced in compilation either.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/jit/annotations.py:386: UserWarning: TorchScript will treat type annotations of Tensor dtype-specific subtypes as if they are normal Tensors. dtype constraints are not enforced in compilation either.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/jit/annotations.py:386: UserWarning: TorchScript will treat type annotations of Tensor dtype-specific subtypes as if they are normal Tensors. dtype constraints are not enforced in compilation either.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/jit/annotations.py:386: UserWarning: TorchScript will treat type annotations of Tensor dtype-specific subtypes as if they are normal Tensors. dtype constraints are not enforced in compilation either.
  warnings.warn(
Matplotlib created a temporary cache directory at /tmp/matplotlib-on90k6ec because the default path (/root/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
Matplotlib created a temporary cache directory at /tmp/matplotlib-ov0ccrch because the default path (/root/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
/usr/local/lib/python3.10/dist-packages/torch/jit/annotations.py:386: UserWarning: TorchScript will treat type annotations of Tensor dtype-specific subtypes as if they are normal Tensors. dtype constraints are not enforced in compilation either.
  warnings.warn(
Matplotlib created a temporary cache directory at /tmp/matplotlib-j4v97zzx because the default path (/root/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
/usr/local/lib/python3.10/dist-packages/torch/jit/annotations.py:386: UserWarning: TorchScript will treat type annotations of Tensor dtype-specific subtypes as if they are normal Tensors. dtype constraints are not enforced in compilation either.
  warnings.warn(
Matplotlib created a temporary cache directory at /tmp/matplotlib-8iuee3wh because the default path (/root/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
Matplotlib created a temporary cache directory at /tmp/matplotlib-vfjmcz9u because the default path (/root/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
/usr/local/lib/python3.10/dist-packages/torch/jit/annotations.py:386: UserWarning: TorchScript will treat type annotations of Tensor dtype-specific subtypes as if they are normal Tensors. dtype constraints are not enforced in compilation either.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/jit/annotations.py:386: UserWarning: TorchScript will treat type annotations of Tensor dtype-specific subtypes as if they are normal Tensors. dtype constraints are not enforced in compilation either.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/jit/annotations.py:386: UserWarning: TorchScript will treat type annotations of Tensor dtype-specific subtypes as if they are normal Tensors. dtype constraints are not enforced in compilation either.
  warnings.warn(
[W init.cpp:842] Warning: Use _jit_set_fusion_strategy, bailout depth is deprecated. Setting to (STATIC, 20) (function operator())
[W init.cpp:842] Warning: Use _jit_set_fusion_strategy, bailout depth is deprecated. Setting to (STATIC, 20) (function operator())
[W init.cpp:842] Warning: Use _jit_set_fusion_strategy, bailout depth is deprecated. Setting to (STATIC, 20) (function operator())
[W init.cpp:842] Warning: Use _jit_set_fusion_strategy, bailout depth is deprecated. Setting to (STATIC, 20) (function operator())
[W init.cpp:842] Warning: Use _jit_set_fusion_strategy, bailout depth is deprecated. Setting to (STATIC, 20) (function operator())
[W init.cpp:842] Warning: Use _jit_set_fusion_strategy, bailout depth is deprecated. Setting to (STATIC, 20) (function operator())
[W init.cpp:842] Warning: Use _jit_set_fusion_strategy, bailout depth is deprecated. Setting to (STATIC, 20) (function operator())
[W init.cpp:842] Warning: Use _jit_set_fusion_strategy, bailout depth is deprecated. Setting to (STATIC, 20) (function operator())
[W init.cpp:842] Warning: Use _jit_set_fusion_strategy, bailout depth is deprecated. Setting to (STATIC, 20) (function operator())
[W init.cpp:842] Warning: Use _jit_set_fusion_strategy, bailout depth is deprecated. Setting to (STATIC, 20) (function operator())
| distributed init (rank 9): env://
| distributed init (rank 8): env://
[W init.cpp:842] Warning: Use _jit_set_fusion_strategy, bailout depth is deprecated. Setting to (STATIC, 20) (function operator())
| distributed init (rank 13): env://
| distributed init (rank 14): env://
[W init.cpp:842] Warning: Use _jit_set_fusion_strategy, bailout depth is deprecated. Setting to (STATIC, 20) (function operator())
[W init.cpp:842] Warning: Use _jit_set_fusion_strategy, bailout depth is deprecated. Setting to (STATIC, 20) (function operator())
[W init.cpp:842] Warning: Use _jit_set_fusion_strategy, bailout depth is deprecated. Setting to (STATIC, 20) (function operator())
[W init.cpp:842] Warning: Use _jit_set_fusion_strategy, bailout depth is deprecated. Setting to (STATIC, 20) (function operator())
| distributed init (rank 0): env://
[W init.cpp:842] Warning: Use _jit_set_fusion_strategy, bailout depth is deprecated. Setting to (STATIC, 20) (function operator())
| distributed init (rank 10): env://
| distributed init (rank 11): env://
| distributed init (rank 15): env://
| distributed init (rank 12): env://
| distributed init (rank 5): env://
| distributed init (rank 6): env://
| distributed init (rank 2): env://
| distributed init (rank 1): env://
| distributed init (rank 7): env://
| distributed init (rank 3): env://
| distributed init (rank 4): env://
:::MLLOG {"namespace": "", "time_ms": 1696363844461, "event_type": "POINT_IN_TIME", "key": "submission_benchmark", "value": "ssd", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 352}}
:::MLLOG {"namespace": "", "time_ms": 1696363844461, "event_type": "POINT_IN_TIME", "key": "submission_org", "value": "Dell", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 352}}
:::MLLOG {"namespace": "", "time_ms": 1696363844461, "event_type": "POINT_IN_TIME", "key": "submission_division", "value": "closed", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 352}}
:::MLLOG {"namespace": "", "time_ms": 1696363844461, "event_type": "POINT_IN_TIME", "key": "submission_status", "value": "onprem", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 352}}
:::MLLOG {"namespace": "", "time_ms": 1696363844461, "event_type": "POINT_IN_TIME", "key": "submission_platform", "value": "2xXE9680x8H100-SXM-80GB", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 352}}
:::MLLOG {"namespace": "", "time_ms": 1696363844462, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 353}}
:::MLLOG {"namespace": "", "time_ms": 1696363844468, "event_type": "POINT_IN_TIME", "key": "seed", "value": 1375661976, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 368}}
:::MLLOG {"namespace": "", "time_ms": 1696363844493, "event_type": "POINT_IN_TIME", "key": "seed", "value": 1375661975, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 368}}
:::MLLOG {"namespace": "", "time_ms": 1696363844493, "event_type": "POINT_IN_TIME", "key": "seed", "value": 1375661977, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 368}}
:::MLLOG {"namespace": "", "time_ms": 1696363844493, "event_type": "POINT_IN_TIME", "key": "seed", "value": 1375661978, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 368}}
:::MLLOG {"namespace": "", "time_ms": 1696363844493, "event_type": "POINT_IN_TIME", "key": "seed", "value": 1375661979, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 368}}
:::MLLOG {"namespace": "", "time_ms": 1696363844493, "event_type": "POINT_IN_TIME", "key": "seed", "value": 1375661980, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 368}}
:::MLLOG {"namespace": "", "time_ms": 1696363844493, "event_type": "POINT_IN_TIME", "key": "seed", "value": 1375661981, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 368}}
:::MLLOG {"namespace": "", "time_ms": 1696363844493, "event_type": "POINT_IN_TIME", "key": "seed", "value": 1375661982, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 368}}
:::MLLOG {"namespace": "", "time_ms": 1696363844493, "event_type": "POINT_IN_TIME", "key": "local_batch_size", "value": 16, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 371}}
:::MLLOG {"namespace": "", "time_ms": 1696363844493, "event_type": "POINT_IN_TIME", "key": "global_batch_size", "value": 256, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 372}}
:::MLLOG {"namespace": "", "time_ms": 1696363844494, "event_type": "POINT_IN_TIME", "key": "epoch_count", "value": 6, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 373}}
:::MLLOG {"namespace": "", "time_ms": 1696363844494, "event_type": "POINT_IN_TIME", "key": "first_epoch_num", "value": 0, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 374}}
Namespace(backbone='resnext50_32x4d', trainable_backbone_layers=3, sync_bn=False, data_layout='channels_last', amp=True, async_coco=True, async_coco_check_freq=20, num_eval_ranks=16, dataset='openimages-mlperf', dataset_path='/datasets/open-images-v6', num_classes=None, train_data_path=None, train_annotations_file=None, val_data_path=None, val_annotations_file=None, image_size=[800, 800], data_augmentation='hflip', epochs=6, max_iters_per_epoch=None, max_eval_iters_per_epoch=None, start_epoch=0, output_dir=None, target_map=0.34, resume='', pretrained=False, batch_size=16, eval_batch_size=16, lr=8.5e-05, warmup_epochs=0, warmup_factor=0.001, workers=4, print_freq=20, eval_print_freq=20, test_only=False, seed=1375661975, device='cuda', cocoeval='nvidia', coco_threads=8, world_size=16, dist_url='env://', frozen_bn_opt=True, frozen_bn_fp16=True, jit=True, cuda_graphs=True, cuda_graphs_eval=False, cls_head_pad=True, reg_head_pad=True, cuda_graphs_syn=True, model_warmup_epochs=16, master_weights=True, dali=True, dali_matched_idxs=True, dali_eval=True, dali_eval_cache=False, dali_prefetch_queue_depth=2, dali_cpu_decode=True, dali_cmn=0, dali_cmn_hint=0, dali_decoder_hint_height=7360, dali_decoder_hint_width=7360, dali_decoder_hw_load=0.65, dali_input_batch_multiplier=1, dali_eval_cmn_hint=0, dali_eval_decoder_hint_height=0, dali_eval_decoder_hint_width=0, dali_eval_decoder_hw_load=0.65, dali_eval_input_batch_multiplier=1, dali_sync=False, apex_adam=True, apex_focal_loss=True, apex_backbone_fusion=True, apex_head_fusion=True, broadcast_buffers=False, fp16_allreduce=False, ddp_bucket_sz=25, ddp_first_bucket_sz=None, no_gradient_as_bucket_view=False, max_boxes=1000, cudnn_bench=False, deterministic=False, not_graphed_prologues=False, metric_loss=False, syn_dataset=False, sync_after_graph_replay=False, allreduce_barrier=False, skip_eval=False, cuda_profiler=False, cuda_profiler_eval=False, cuda_profiler_start=-1, cuda_profiler_stop=-1, power_benchmark=False, power_sustain_time=600, rank=0, gpu=0, distributed=True, dist_back:::MLLOG {"namespace": "", "time_ms": 1696363844498, "event_type": "POINT_IN_TIME", "key": "seed", "value": 1375661983, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 368}}
:::MLLOG {"namespace": "", "time_ms": 1696363844498, "event_type": "POINT_IN_TIME", "key": "seed", "value": 1375661984, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 368}}
:::MLLOG {"namespace": "", "time_ms": 1696363844498, "event_type": "POINT_IN_TIME", "key": "seed", "value": 1375661985, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 368}}
:::MLLOG {"namespace": "", "time_ms": 1696363844498, "event_type": "POINT_IN_TIME", "key": "seed", "value": 1375661986, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 368}}
:::MLLOG {"namespace": "", "time_ms": 1696363844498, "event_type": "POINT_IN_TIME", "key": "seed", "value": 1375661987, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 368}}
:::MLLOG {"namespace": "", "time_ms": 1696363844498, "event_type": "POINT_IN_TIME", "key": "seed", "value": 1375661988, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 368}}
:::MLLOG {"namespace": "", "time_ms": 1696363844498, "event_type": "POINT_IN_TIME", "key": "seed", "value": 1375661989, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 368}}
:::MLLOG {"namespace": "", "time_ms": 1696363844498, "event_type": "POINT_IN_TIME", "key": "seed", "value": 1375661990, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 368}}
end='nccl', ranks=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], num_train_ranks=16, train_ranks=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], eval_ranks=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], train_rank=0, eval_rank=0)
Getting dataset information
Creating model
:::MLLOG {"namespace": "", "time_ms": 1696363844501, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 209, "tensor": "module.backbone.fpn.extra_blocks.p6.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696363844529, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 211, "tensor": "module.backbone.fpn.extra_blocks.p6.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1696363844529, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 209, "tensor": "module.backbone.fpn.extra_blocks.p7.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696363844532, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 211, "tensor": "module.backbone.fpn.extra_blocks.p7.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1696363844663, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696363844663, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer1.0.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696363844663, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer1.0.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696363844663, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer1.0.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696363844664, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer1.0.downsample.0.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696363844664, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer1.1.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696363844664, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer1.1.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696363844664, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer1.1.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696363844664, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer1.2.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696363844664, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer1.2.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696363844664, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer1.2.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696363844665, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.0.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696363844665, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.0.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696363844665, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.0.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696363844666, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.0.downsample.0.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696363844666, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.1.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696363844667, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.1.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696363844667, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.1.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696363844668, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.2.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696363844669, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.2.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696363844669, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.2.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696363844669, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.3.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696363844670, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.3.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696363844670, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.3.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696363844671, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.0.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696363844672, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.0.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696363844672, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.0.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696363844675, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.0.downsample.0.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696363844677, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.1.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696363844679, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.1.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696363844680, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.1.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696363844682, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.2.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696363844684, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.2.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696363844685, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.2.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696363844687, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.3.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696363844689, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.3.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696363844690, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.3.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696363844692, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.4.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696363844694, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.4.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696363844695, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.4.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696363844697, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.5.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696363844699, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.5.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696363844700, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.5.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696363844702, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer4.0.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696363844707, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer4.0.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696363844708, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer4.0.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696363844717, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer4.0.downsample.0.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696363844725, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer4.1.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696363844734, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer4.1.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696363844736, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer4.1.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696363844744, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer4.2.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696363844753, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer4.2.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696363844754, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer4.2.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696363844857, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 108, "tensor": "module.backbone.fpn.inner_blocks.0.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696363844858, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 110, "tensor": "module.backbone.fpn.inner_blocks.0.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1696363844858, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 108, "tensor": "module.backbone.fpn.inner_blocks.1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696363844859, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 110, "tensor": "module.backbone.fpn.inner_blocks.1.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1696363844859, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 108, "tensor": "module.backbone.fpn.inner_blocks.2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696363844861, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 110, "tensor": "module.backbone.fpn.inner_blocks.2.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1696363844861, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 108, "tensor": "module.backbone.fpn.layer_blocks.0.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696363844864, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 110, "tensor": "module.backbone.fpn.layer_blocks.0.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1696363844864, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 108, "tensor": "module.backbone.fpn.layer_blocks.1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696363844866, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 110, "tensor": "module.backbone.fpn.layer_blocks.1.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1696363844866, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 108, "tensor": "module.backbone.fpn.layer_blocks.2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696363844869, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 110, "tensor": "module.backbone.fpn.layer_blocks.2.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1696363844882, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 142, "tensor": "module.head.classification_head.conv.0.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696363844885, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 144, "tensor": "module.head.classification_head.conv.0.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1696363844885, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 142, "tensor": "module.head.classification_head.conv.2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696363844888, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 144, "tensor": "module.head.classification_head.conv.2.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1696363844888, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 142, "tensor": "module.head.classification_head.conv.4.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696363844890, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 144, "tensor": "module.head.classification_head.conv.4.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1696363844890, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 142, "tensor": "module.head.classification_head.conv.6.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696363844893, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 144, "tensor": "module.head.classification_head.conv.6.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1696363844914, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 148, "tensor": "module.head.classification_head.cls_logits.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696363844937, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 150, "tensor": "module.head.classification_head.cls_logits.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1696363844948, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 317, "tensor": "module.head.regression_head.bbox_reg.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696363844948, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 319, "tensor": "module.head.regression_head.bbox_reg.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1696363844948, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 324, "tensor": "module.head.regression_head.conv.0.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696363844951, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 326, "tensor": "module.head.regression_head.conv.0.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1696363844951, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 324, "tensor": "module.head.regression_head.conv.2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696363844953, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 326, "tensor": "module.head.regression_head.conv.2.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1696363844954, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 324, "tensor": "module.head.regression_head.conv.4.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696363844956, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 326, "tensor": "module.head.regression_head.conv.4.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1696363844956, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 324, "tensor": "module.head.regression_head.conv.6.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1696363844959, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 326, "tensor": "module.head.regression_head.conv.6.bias"}}
Casting convolutional layers to half
/usr/local/lib/python3.10/dist-packages/apex/optimizers/fused_adam.py:112: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  self._dummy_overflow_buf = torch.cuda.IntTensor([0])
/usr/local/lib/python3.10/dist-packages/apex/optimizers/fused_adam.py:112: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  self._dummy_overflow_buf = torch.cuda.IntTensor([0])
/usr/local/lib/python3.10/dist-packages/apex/optimizers/fused_adam.py:112: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  self._dummy_overflow_buf = torch.cuda.IntTensor([0])
/usr/local/lib/python3.10/dist-packages/apex/optimizers/fused_adam.py:112: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  self._dummy_overflow_buf = torch.cuda.IntTensor([0])
/usr/local/lib/python3.10/dist-packages/apex/optimizers/fused_adam.py:112: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  self._dummy_overflow_buf = torch.cuda.IntTensor([0])
/usr/local/lib/python3.10/dist-packages/apex/optimizers/fused_adam.py:112: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  self._dummy_overflow_buf = torch.cuda.IntTensor([0])
/usr/local/lib/python3.10/dist-packages/apex/optimizers/fused_adam.py:112: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  self._dummy_overflow_buf = torch.cuda.IntTensor([0])
:::MLLOG {"namespace": "", "time_ms": 1696363845034, "event_type": "POINT_IN_TIME", "key": "opt_name", "value": "adam", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 450}}
/usr/local/lib/python3.10/dist-packages/apex/optimizers/fused_adam.py:112: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  self._dummy_overflow_buf = torch.cuda.IntTensor([0])
:::MLLOG {"namespace": "", "time_ms": 1696363845035, "event_type": "POINT_IN_TIME", "key": "opt_base_learning_rate", "value": 8.5e-05, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 451}}
:::MLLOG {"namespace": "", "time_ms": 1696363845035, "event_type": "POINT_IN_TIME", "key": "opt_weight_decay", "value": 0, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 452}}
:::MLLOG {"namespace": "", "time_ms": 1696363845035, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_warmup_epochs", "value": 0, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 453}}
:::MLLOG {"namespace": "", "time_ms": 1696363845035, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_warmup_factor", "value": 0.001, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 454}}
:::MLLOG {"namespace": "", "time_ms": 1696363845035, "event_type": "POINT_IN_TIME", "key": "gradient_accumulation_steps", "value": 1, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 455}}
/usr/local/lib/python3.10/dist-packages/apex/optimizers/fused_adam.py:112: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  self._dummy_overflow_buf = torch.cuda.IntTensor([0])
/usr/local/lib/python3.10/dist-packages/apex/optimizers/fused_adam.py:112: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  self._dummy_overflow_buf = torch.cuda.IntTensor([0])
/usr/local/lib/python3.10/dist-packages/apex/optimizers/fused_adam.py:112: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  self._dummy_overflow_buf = torch.cuda.IntTensor([0])
/usr/local/lib/python3.10/dist-packages/apex/optimizers/fused_adam.py:112: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  self._dummy_overflow_buf = torch.cuda.IntTensor([0])
/usr/local/lib/python3.10/dist-packages/apex/optimizers/fused_adam.py:112: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  self._dummy_overflow_buf = torch.cuda.IntTensor([0])
/usr/local/lib/python3.10/dist-packages/apex/optimizers/fused_adam.py:112: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  self._dummy_overflow_buf = torch.cuda.IntTensor([0])
/usr/local/lib/python3.10/dist-packages/apex/optimizers/fused_adam.py:112: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  self._dummy_overflow_buf = torch.cuda.IntTensor([0])
/usr/local/lib/python3.10/dist-packages/apex/optimizers/fused_adam.py:112: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:83.)
  self._dummy_overflow_buf = torch.cuda.IntTensor([0])
/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3516.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3516.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3516.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3516.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3516.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3516.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3516.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3516.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
Model eval warmup
/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3516.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3516.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3516.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3516.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3516.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3516.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3516.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3516.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/workspace/ssd/model/jit_fn.py:40: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  bn_relu_out, relu_mask = fwd_bn_relu_jit(input, scale, bias)
/workspace/ssd/model/jit_fn.py:40: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  bn_relu_out, relu_mask = fwd_bn_relu_jit(input, scale, bias)
/workspace/ssd/model/jit_fn.py:40: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  bn_relu_out, relu_mask = fwd_bn_relu_jit(input, scale, bias)
/workspace/ssd/model/jit_fn.py:40: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  bn_relu_out, relu_mask = fwd_bn_relu_jit(input, scale, bias)
/workspace/ssd/model/jit_fn.py:40: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  bn_relu_out, relu_mask = fwd_bn_relu_jit(input, scale, bias)
/workspace/ssd/model/jit_fn.py:40: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  bn_relu_out, relu_mask = fwd_bn_relu_jit(input, scale, bias)
/workspace/ssd/model/jit_fn.py:40: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  bn_relu_out, relu_mask = fwd_bn_relu_jit(input, scale, bias)
/workspace/ssd/model/jit_fn.py:40: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  bn_relu_out, relu_mask = fwd_bn_relu_jit(input, scale, bias)
/workspace/ssd/model/jit_fn.py:40: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  bn_relu_out, relu_mask = fwd_bn_relu_jit(input, scale, bias)
/workspace/ssd/model/jit_fn.py:40: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  bn_relu_out, relu_mask = fwd_bn_relu_jit(input, scale, bias)
/workspace/ssd/model/jit_fn.py:40: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  bn_relu_out, relu_mask = fwd_bn_relu_jit(input, scale, bias)
/workspace/ssd/model/jit_fn.py:40: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  bn_relu_out, relu_mask = fwd_bn_relu_jit(input, scale, bias)
/workspace/ssd/model/jit_fn.py:40: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  bn_relu_out, relu_mask = fwd_bn_relu_jit(input, scale, bias)
/workspace/ssd/model/jit_fn.py:40: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  bn_relu_out, relu_mask = fwd_bn_relu_jit(input, scale, bias)
/workspace/ssd/model/jit_fn.py:40: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  bn_relu_out, relu_mask = fwd_bn_relu_jit(input, scale, bias)
/workspace/ssd/model/jit_fn.py:40: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  bn_relu_out, relu_mask = fwd_bn_relu_jit(input, scale, bias)
Time: 45.17829942703247 sec
Creating Dali training dataloader
Creating Dali eval dataloader
CUDA graph capture
/usr/local/lib/python3.10/dist-packages/torch/cuda/amp/grad_scaler.py:378: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/cuda/amp/grad_scaler.py:378: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/cuda/amp/grad_scaler.py:378: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/cuda/amp/grad_scaler.py:378: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/cuda/amp/grad_scaler.py:378: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/cuda/amp/grad_scaler.py:378: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/cuda/amp/grad_scaler.py:378: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/cuda/amp/grad_scaler.py:378: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/cuda/amp/grad_scaler.py:378: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/cuda/amp/grad_scaler.py:378: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/cuda/amp/grad_scaler.py:378: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/cuda/amp/grad_scaler.py:378: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/cuda/amp/grad_scaler.py:378: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/cuda/amp/grad_scaler.py:378: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/cuda/amp/grad_scaler.py:378: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/cuda/amp/grad_scaler.py:378: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/cuda/graphs.py:75: UserWarning: Attempting to start graph capture but NCCL ProcessGroup(s) have remaining enqueued work. Waiting for enqueued work to finish... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/cuda/CUDAGraph.cpp:73.)
  super().capture_begin()
/usr/local/lib/python3.10/dist-packages/torch/cuda/graphs.py:75: UserWarning: Attempting to start graph capture but NCCL ProcessGroup(s) have remaining enqueued work. Waiting for enqueued work to finish... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/cuda/CUDAGraph.cpp:73.)
  super().capture_begin()
/usr/local/lib/python3.10/dist-packages/torch/cuda/graphs.py:75: UserWarning: Attempting to start graph capture but NCCL ProcessGroup(s) have remaining enqueued work. Waiting for enqueued work to finish... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/cuda/CUDAGraph.cpp:73.)
  super().capture_begin()
/usr/local/lib/python3.10/dist-packages/torch/cuda/graphs.py:75: UserWarning: Attempting to start graph capture but NCCL ProcessGroup(s) have remaining enqueued work. Waiting for enqueued work to finish... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/cuda/CUDAGraph.cpp:73.)
  super().capture_begin()
/usr/local/lib/python3.10/dist-packages/torch/cuda/graphs.py:75: UserWarning: Attempting to start graph capture but NCCL ProcessGroup(s) have remaining enqueued work. Waiting for enqueued work to finish... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/cuda/CUDAGraph.cpp:73.)
  super().capture_begin()
/usr/local/lib/python3.10/dist-packages/torch/cuda/graphs.py:75: UserWarning: Attempting to start graph capture but NCCL ProcessGroup(s) have remaining enqueued work. Waiting for enqueued work to finish... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/cuda/CUDAGraph.cpp:73.)
  super().capture_begin()
/usr/local/lib/python3.10/dist-packages/torch/cuda/graphs.py:75: UserWarning: Attempting to start graph capture but NCCL ProcessGroup(s) have remaining enqueued work. Waiting for enqueued work to finish... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/cuda/CUDAGraph.cpp:73.)
  super().capture_begin()
/usr/local/lib/python3.10/dist-packages/torch/cuda/graphs.py:75: UserWarning: Attempting to start graph capture but NCCL ProcessGroup(s) have remaining enqueued work. Waiting for enqueued work to finish... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/cuda/CUDAGraph.cpp:73.)
  super().capture_begin()
/usr/local/lib/python3.10/dist-packages/torch/cuda/graphs.py:75: UserWarning: Attempting to start graph capture but NCCL ProcessGroup(s) have remaining enqueued work. Waiting for enqueued work to finish... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/cuda/CUDAGraph.cpp:73.)
  super().capture_begin()
/usr/local/lib/python3.10/dist-packages/torch/cuda/graphs.py:75: UserWarning: Attempting to start graph capture but NCCL ProcessGroup(s) have remaining enqueued work. Waiting for enqueued work to finish... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/cuda/CUDAGraph.cpp:73.)
  super().capture_begin()
/usr/local/lib/python3.10/dist-packages/torch/cuda/graphs.py:75: UserWarning: Attempting to start graph capture but NCCL ProcessGroup(s) have remaining enqueued work. Waiting for enqueued work to finish... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/cuda/CUDAGraph.cpp:73.)
  super().capture_begin()
/usr/local/lib/python3.10/dist-packages/torch/cuda/graphs.py:75: UserWarning: Attempting to start graph capture but NCCL ProcessGroup(s) have remaining enqueued work. Waiting for enqueued work to finish... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/cuda/CUDAGraph.cpp:73.)
  super().capture_begin()
/usr/local/lib/python3.10/dist-packages/torch/cuda/graphs.py:75: UserWarning: Attempting to start graph capture but NCCL ProcessGroup(s) have remaining enqueued work. Waiting for enqueued work to finish... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/cuda/CUDAGraph.cpp:73.)
  super().capture_begin()
/usr/local/lib/python3.10/dist-packages/torch/cuda/graphs.py:75: UserWarning: Attempting to start graph capture but NCCL ProcessGroup(s) have remaining enqueued work. Waiting for enqueued work to finish... (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/cuda/CUDAGraph.cpp:73.)
  super().capture_begin()
:::MLLOG {"namespace": "", "time_ms": 1696363914941, "event_type": "INTERVAL_END", "key": "init_stop", "value": null, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 571}}
:::MLLOG {"namespace": "", "time_ms": 1696363914943, "event_type": "INTERVAL_START", "key": "run_start", "value": null, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 575}}
:::MLLOG {"namespace": "", "time_ms": 1696363914943, "event_type": "POINT_IN_TIME", "key": "train_samples", "value": 4572, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 623}}
:::MLLOG {"namespace": "", "time_ms": 1696363914943, "event_type": "POINT_IN_TIME", "key": "eval_samples", "value": 97, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 626}}
Running ...
:::MLLOG {"namespace": "", "time_ms": 1696363914944, "event_type": "INTERVAL_START", "key": "epoch_start", "value": 0, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 158, "epoch_num": 0}}
Epoch: [0]  [   0/4572]  eta: 0:04:24    time: 0.0579  data: 0.0003  max mem: 10412
Epoch: [0]  [  20/4572]  eta: 0:04:28    time: 0.0590  data: 0.0523  max mem: 10412
Epoch: [0]  [  40/4572]  eta: 0:04:26    time: 0.0588  data: 0.0523  max mem: 10412
Epoch: [0]  [  60/4572]  eta: 0:04:25    time: 0.0588  data: 0.0522  max mem: 10412
Epoch: [0]  [  80/4572]  eta: 0:04:24    time: 0.0587  data: 0.0523  max mem: 10412
Epoch: [0]  [ 100/4572]  eta: 0:04:29    time: 0.0667  data: 0.0602  max mem: 10412
Epoch: [0]  [ 120/4572]  eta: 0:04:29    time: 0.0613  data: 0.0548  max mem: 10412
Epoch: [0]  [ 140/4572]  eta: 0:04:32    time: 0.0668  data: 0.0599  max mem: 10412
Epoch: [0]  [ 160/4572]  eta: 0:04:30    time: 0.0615  data: 0.0550  max mem: 10412
Epoch: [0]  [ 180/4572]  eta: 0:04:28    time: 0.0599  data: 0.0534  max mem: 10412
Epoch: [0]  [ 200/4572]  eta: 0:04:26    time: 0.0588  data: 0.0524  max mem: 10412
Epoch: [0]  [ 220/4572]  eta: 0:04:24    time: 0.0587  data: 0.0522  max mem: 10412
Epoch: [0]  [ 240/4572]  eta: 0:04:22    time: 0.0588  data: 0.0522  max mem: 10412
Epoch: [0]  [ 260/4572]  eta: 0:04:20    time: 0.0587  data: 0.0522  max mem: 10412
Epoch: [0]  [ 280/4572]  eta: 0:04:19    time: 0.0592  data: 0.0526  max mem: 10412
Epoch: [0]  [ 300/4572]  eta: 0:04:17    time: 0.0590  data: 0.0525  max mem: 10412
Epoch: [0]  [ 320/4572]  eta: 0:04:16    time: 0.0589  data: 0.0524  max mem: 10412
Epoch: [0]  [ 340/4572]  eta: 0:04:14    time: 0.0589  data: 0.0523  max mem: 10412
Epoch: [0]  [ 360/4572]  eta: 0:04:13    time: 0.0590  data: 0.0524  max mem: 10412
Epoch: [0]  [ 380/4572]  eta: 0:04:11    time: 0.0590  data: 0.0524  max mem: 10412
Epoch: [0]  [ 400/4572]  eta: 0:04:10    time: 0.0590  data: 0.0524  max mem: 10412
Epoch: [0]  [ 420/4572]  eta: 0:04:09    time: 0.0645  data: 0.0580  max mem: 10412
Epoch: [0]  [ 440/4572]  eta: 0:04:08    time: 0.0590  data: 0.0525  max mem: 10412
Epoch: [0]  [ 460/4572]  eta: 0:04:07    time: 0.0593  data: 0.0527  max mem: 10412
Epoch: [0]  [ 480/4572]  eta: 0:04:05    time: 0.0591  data: 0.0525  max mem: 10412
Epoch: [0]  [ 500/4572]  eta: 0:04:04    time: 0.0617  data: 0.0552  max mem: 10412
Epoch: [0]  [ 520/4572]  eta: 0:04:03    time: 0.0587  data: 0.0522  max mem: 10412
Epoch: [0]  [ 540/4572]  eta: 0:04:01    time: 0.0589  data: 0.0524  max mem: 10412
Epoch: [0]  [ 560/4572]  eta: 0:04:00    time: 0.0592  data: 0.0527  max mem: 10412
Epoch: [0]  [ 580/4572]  eta: 0:03:59    time: 0.0592  data: 0.0527  max mem: 10412
Epoch: [0]  [ 600/4572]  eta: 0:04:00    time: 0.0748  data: 0.0584  max mem: 10412
Epoch: [0]  [ 620/4572]  eta: 0:03:58    time: 0.0588  data: 0.0523  max mem: 10412
Epoch: [0]  [ 640/4572]  eta: 0:03:57    time: 0.0590  data: 0.0524  max mem: 10412
Epoch: [0]  [ 660/4572]  eta: 0:03:55    time: 0.0593  data: 0.0528  max mem: 10412
Epoch: [0]  [ 680/4572]  eta: 0:03:55    time: 0.0637  data: 0.0573  max mem: 10412
Epoch: [0]  [ 700/4572]  eta: 0:03:53    time: 0.0587  data: 0.0522  max mem: 10412
Epoch: [0]  [ 720/4572]  eta: 0:03:53    time: 0.0665  data: 0.0600  max mem: 10412
Epoch: [0]  [ 740/4572]  eta: 0:03:51    time: 0.0592  data: 0.0526  max mem: 10412
Epoch: [0]  [ 760/4572]  eta: 0:03:50    time: 0.0592  data: 0.0526  max mem: 10412
Epoch: [0]  [ 780/4572]  eta: 0:03:49    time: 0.0651  data: 0.0584  max mem: 10412
Epoch: [0]  [ 800/4572]  eta: 0:03:49    time: 0.0666  data: 0.0601  max mem: 10412
Epoch: [0]  [ 820/4572]  eta: 0:03:47    time: 0.0592  data: 0.0526  max mem: 10412
Epoch: [0]  [ 840/4572]  eta: 0:03:46    time: 0.0591  data: 0.0525  max mem: 10412
Epoch: [0]  [ 860/4572]  eta: 0:03:46    time: 0.0705  data: 0.0638  max mem: 10412
Epoch: [0]  [ 880/4572]  eta: 0:03:45    time: 0.0647  data: 0.0582  max mem: 10412
Epoch: [0]  [ 900/4572]  eta: 0:03:44    time: 0.0632  data: 0.0567  max mem: 10412
Epoch: [0]  [ 920/4572]  eta: 0:03:42    time: 0.0593  data: 0.0528  max mem: 10412
Epoch: [0]  [ 940/4572]  eta: 0:03:42    time: 0.0696  data: 0.0631  max mem: 10412
Epoch: [0]  [ 960/4572]  eta: 0:03:40    time: 0.0595  data: 0.0528  max mem: 10412
Epoch: [0]  [ 980/4572]  eta: 0:03:39    time: 0.0601  data: 0.0534  max mem: 10412
Epoch: [0]  [1000/4572]  eta: 0:03:38    time: 0.0681  data: 0.0615  max mem: 10412
Epoch: [0]  [1020/4572]  eta: 0:03:37    time: 0.0598  data: 0.0532  max mem: 10412
Epoch: [0]  [1040/4572]  eta: 0:03:36    time: 0.0592  data: 0.0526  max mem: 10412
Epoch: [0]  [1060/4572]  eta: 0:03:34    time: 0.0593  data: 0.0528  max mem: 10412
Epoch: [0]  [1080/4572]  eta: 0:03:33    time: 0.0591  data: 0.0526  max mem: 10412
Epoch: [0]  [1100/4572]  eta: 0:03:32    time: 0.0592  data: 0.0526  max mem: 10412
Epoch: [0]  [1120/4572]  eta: 0:03:30    time: 0.0591  data: 0.0525  max mem: 10412
Epoch: [0]  [1140/4572]  eta: 0:03:29    time: 0.0619  data: 0.0553  max mem: 10412
Epoch: [0]  [1160/4572]  eta: 0:03:28    time: 0.0590  data: 0.0525  max mem: 10412
Epoch: [0]  [1180/4572]  eta: 0:03:27    time: 0.0697  data: 0.0632  max mem: 10412
Epoch: [0]  [1200/4572]  eta: 0:03:26    time: 0.0593  data: 0.0527  max mem: 10412
Epoch: [0]  [1220/4572]  eta: 0:03:24    time: 0.0590  data: 0.0525  max mem: 10412
Epoch: [0]  [1240/4572]  eta: 0:03:23    time: 0.0592  data: 0.0529  max mem: 10412
Epoch: [0]  [1260/4572]  eta: 0:03:22    time: 0.0593  data: 0.0528  max mem: 10412
Epoch: [0]  [1280/4572]  eta: 0:03:20    time: 0.0592  data: 0.0526  max mem: 10412
Epoch: [0]  [1300/4572]  eta: 0:03:19    time: 0.0592  data: 0.0526  max mem: 10412
Epoch: [0]  [1320/4572]  eta: 0:03:18    time: 0.0592  data: 0.0527  max mem: 10412
Epoch: [0]  [1340/4572]  eta: 0:03:17    time: 0.0622  data: 0.0555  max mem: 10412
Epoch: [0]  [1360/4572]  eta: 0:03:15    time: 0.0594  data: 0.0528  max mem: 10412
Epoch: [0]  [1380/4572]  eta: 0:03:14    time: 0.0591  data: 0.0526  max mem: 10412
Epoch: [0]  [1400/4572]  eta: 0:03:13    time: 0.0596  data: 0.0530  max mem: 10412
Epoch: [0]  [1420/4572]  eta: 0:03:11    time: 0.0591  data: 0.0526  max mem: 10412
Epoch: [0]  [1440/4572]  eta: 0:03:10    time: 0.0591  data: 0.0526  max mem: 10412
Corrupt JPEG data: premature end of data segment
Epoch: [0]  [1460/4572]  eta: 0:03:09    time: 0.0606  data: 0.0541  max mem: 10412
Epoch: [0]  [1480/4572]  eta: 0:03:08    time: 0.0592  data: 0.0526  max mem: 10412
Epoch: [0]  [1500/4572]  eta: 0:03:07    time: 0.0754  data: 0.0689  max mem: 10412
Epoch: [0]  [1520/4572]  eta: 0:03:06    time: 0.0592  data: 0.0527  max mem: 10412
Epoch: [0]  [1540/4572]  eta: 0:03:04    time: 0.0605  data: 0.0537  max mem: 10412
Epoch: [0]  [1560/4572]  eta: 0:03:03    time: 0.0591  data: 0.0526  max mem: 10412
Epoch: [0]  [1580/4572]  eta: 0:03:02    time: 0.0591  data: 0.0526  max mem: 10412
Epoch: [0]  [1600/4572]  eta: 0:03:01    time: 0.0593  data: 0.0527  max mem: 10412
Epoch: [0]  [1620/4572]  eta: 0:02:59    time: 0.0591  data: 0.0526  max mem: 10412
Epoch: [0]  [1640/4572]  eta: 0:02:58    time: 0.0592  data: 0.0526  max mem: 10412
Epoch: [0]  [1660/4572]  eta: 0:02:57    time: 0.0598  data: 0.0533  max mem: 10412
Epoch: [0]  [1680/4572]  eta: 0:02:56    time: 0.0767  data: 0.0701  max mem: 10412
Epoch: [0]  [1700/4572]  eta: 0:02:55    time: 0.0590  data: 0.0526  max mem: 10412
Epoch: [0]  [1720/4572]  eta: 0:02:54    time: 0.0593  data: 0.0527  max mem: 10412
Epoch: [0]  [1740/4572]  eta: 0:02:53    time: 0.0733  data: 0.0668  max mem: 10412
Epoch: [0]  [1760/4572]  eta: 0:02:51    time: 0.0592  data: 0.0527  max mem: 10412
Epoch: [0]  [1780/4572]  eta: 0:02:50    time: 0.0593  data: 0.0528  max mem: 10412
Epoch: [0]  [1800/4572]  eta: 0:02:49    time: 0.0592  data: 0.0526  max mem: 10412
Epoch: [0]  [1820/4572]  eta: 0:02:48    time: 0.0620  data: 0.0554  max mem: 10412
Epoch: [0]  [1840/4572]  eta: 0:02:46    time: 0.0593  data: 0.0527  max mem: 10412
Epoch: [0]  [1860/4572]  eta: 0:02:45    time: 0.0593  data: 0.0528  max mem: 10412
Epoch: [0]  [1880/4572]  eta: 0:02:44    time: 0.0591  data: 0.0526  max mem: 10412
Epoch: [0]  [1900/4572]  eta: 0:02:43    time: 0.0772  data: 0.0705  max mem: 10412
Epoch: [0]  [1920/4572]  eta: 0:02:42    time: 0.0591  data: 0.0525  max mem: 10412
Epoch: [0]  [1940/4572]  eta: 0:02:41    time: 0.0649  data: 0.0582  max mem: 10412
Epoch: [0]  [1960/4572]  eta: 0:02:39    time: 0.0591  data: 0.0526  max mem: 10412
Epoch: [0]  [1980/4572]  eta: 0:02:38    time: 0.0590  data: 0.0525  max mem: 10412
Epoch: [0]  [2000/4572]  eta: 0:02:37    time: 0.0591  data: 0.0526  max mem: 10412
Epoch: [0]  [2020/4572]  eta: 0:02:36    time: 0.0591  data: 0.0526  max mem: 10412
Epoch: [0]  [2040/4572]  eta: 0:02:34    time: 0.0600  data: 0.0534  max mem: 10412
Epoch: [0]  [2060/4572]  eta: 0:02:33    time: 0.0592  data: 0.0526  max mem: 10412
Epoch: [0]  [2080/4572]  eta: 0:02:32    time: 0.0591  data: 0.0525  max mem: 10412
Epoch: [0]  [2100/4572]  eta: 0:02:30    time: 0.0591  data: 0.0525  max mem: 10412
Epoch: [0]  [2120/4572]  eta: 0:02:29    time: 0.0602  data: 0.0535  max mem: 10412
Epoch: [0]  [2140/4572]  eta: 0:02:28    time: 0.0591  data: 0.0525  max mem: 10412
Epoch: [0]  [2160/4572]  eta: 0:02:27    time: 0.0591  data: 0.0526  max mem: 10412
Epoch: [0]  [2180/4572]  eta: 0:02:25    time: 0.0592  data: 0.0527  max mem: 10412
Epoch: [0]  [2200/4572]  eta: 0:02:24    time: 0.0593  data: 0.0528  max mem: 10412
Epoch: [0]  [2220/4572]  eta: 0:02:23    time: 0.0590  data: 0.0525  max mem: 10412
Epoch: [0]  [2240/4572]  eta: 0:02:22    time: 0.0592  data: 0.0526  max mem: 10412
Epoch: [0]  [2260/4572]  eta: 0:02:20    time: 0.0591  data: 0.0527  max mem: 10412
Epoch: [0]  [2280/4572]  eta: 0:02:19    time: 0.0593  data: 0.0527  max mem: 10412
Epoch: [0]  [2300/4572]  eta: 0:02:18    time: 0.0592  data: 0.0526  max mem: 10412
Epoch: [0]  [2320/4572]  eta: 0:02:17    time: 0.0592  data: 0.0526  max mem: 10412
Epoch: [0]  [2340/4572]  eta: 0:02:15    time: 0.0591  data: 0.0526  max mem: 10412
Epoch: [0]  [2360/4572]  eta: 0:02:14    time: 0.0595  data: 0.0530  max mem: 10412
Epoch: [0]  [2380/4572]  eta: 0:02:13    time: 0.0591  data: 0.0525  max mem: 10412
Epoch: [0]  [2400/4572]  eta: 0:02:12    time: 0.0609  data: 0.0544  max mem: 10412
Epoch: [0]  [2420/4572]  eta: 0:02:10    time: 0.0593  data: 0.0527  max mem: 10412
Epoch: [0]  [2440/4572]  eta: 0:02:09    time: 0.0591  data: 0.0526  max mem: 10412
Epoch: [0]  [2460/4572]  eta: 0:02:08    time: 0.0762  data: 0.0696  max mem: 10412
Epoch: [0]  [2480/4572]  eta: 0:02:07    time: 0.0595  data: 0.0529  max mem: 10412
Epoch: [0]  [2500/4572]  eta: 0:02:06    time: 0.0700  data: 0.0635  max mem: 10412
Epoch: [0]  [2520/4572]  eta: 0:02:05    time: 0.0588  data: 0.0524  max mem: 10412
Epoch: [0]  [2540/4572]  eta: 0:02:03    time: 0.0609  data: 0.0542  max mem: 10412
Epoch: [0]  [2560/4572]  eta: 0:02:02    time: 0.0587  data: 0.0522  max mem: 10412
Epoch: [0]  [2580/4572]  eta: 0:02:01    time: 0.0589  data: 0.0524  max mem: 10412
Epoch: [0]  [2600/4572]  eta: 0:02:00    time: 0.0591  data: 0.0527  max mem: 10412
Epoch: [0]  [2620/4572]  eta: 0:01:58    time: 0.0590  data: 0.0525  max mem: 10412
Epoch: [0]  [2640/4572]  eta: 0:01:57    time: 0.0590  data: 0.0525  max mem: 10412
Epoch: [0]  [2660/4572]  eta: 0:01:56    time: 0.0769  data: 0.0704  max mem: 10412
Epoch: [0]  [2680/4572]  eta: 0:01:55    time: 0.0587  data: 0.0522  max mem: 10412
Epoch: [0]  [2700/4572]  eta: 0:01:54    time: 0.0590  data: 0.0525  max mem: 10412
Epoch: [0]  [2720/4572]  eta: 0:01:52    time: 0.0590  data: 0.0525  max mem: 10412
Epoch: [0]  [2740/4572]  eta: 0:01:51    time: 0.0590  data: 0.0525  max mem: 10412
Epoch: [0]  [2760/4572]  eta: 0:01:50    time: 0.0617  data: 0.0552  max mem: 10412
Epoch: [0]  [2780/4572]  eta: 0:01:49    time: 0.0590  data: 0.0524  max mem: 10412
Epoch: [0]  [2800/4572]  eta: 0:01:48    time: 0.0590  data: 0.0524  max mem: 10412
Epoch: [0]  [2820/4572]  eta: 0:01:46    time: 0.0590  data: 0.0524  max mem: 10412
Epoch: [0]  [2840/4572]  eta: 0:01:45    time: 0.0793  data: 0.0729  max mem: 10412
Epoch: [0]  [2860/4572]  eta: 0:01:44    time: 0.0748  data: 0.0684  max mem: 10412
Epoch: [0]  [2880/4572]  eta: 0:01:43    time: 0.0587  data: 0.0522  max mem: 10412
Epoch: [0]  [2900/4572]  eta: 0:01:42    time: 0.0587  data: 0.0523  max mem: 10412
Epoch: [0]  [2920/4572]  eta: 0:01:40    time: 0.0586  data: 0.0521  max mem: 10412
Epoch: [0]  [2940/4572]  eta: 0:01:39    time: 0.0587  data: 0.0522  max mem: 10412
Epoch: [0]  [2960/4572]  eta: 0:01:38    time: 0.0736  data: 0.0672  max mem: 10412
Epoch: [0]  [2980/4572]  eta: 0:01:37    time: 0.0765  data: 0.0701  max mem: 10412
Epoch: [0]  [3000/4572]  eta: 0:01:36    time: 0.0589  data: 0.0523  max mem: 10412
Epoch: [0]  [3020/4572]  eta: 0:01:35    time: 0.0727  data: 0.0522  max mem: 10412
Epoch: [0]  [3040/4572]  eta: 0:01:33    time: 0.0586  data: 0.0521  max mem: 10412
Epoch: [0]  [3060/4572]  eta: 0:01:32    time: 0.0587  data: 0.0522  max mem: 10412
Epoch: [0]  [3080/4572]  eta: 0:01:31    time: 0.0587  data: 0.0522  max mem: 10412
Epoch: [0]  [3100/4572]  eta: 0:01:30    time: 0.0733  data: 0.0669  max mem: 10412
Epoch: [0]  [3120/4572]  eta: 0:01:29    time: 0.0606  data: 0.0541  max mem: 10412
Epoch: [0]  [3140/4572]  eta: 0:01:27    time: 0.0586  data: 0.0538  max mem: 10412
Epoch: [0]  [3160/4572]  eta: 0:01:26    time: 0.0758  data: 0.0694  max mem: 10412
Epoch: [0]  [3180/4572]  eta: 0:01:25    time: 0.0587  data: 0.0522  max mem: 10412
Epoch: [0]  [3200/4572]  eta: 0:01:24    time: 0.0597  data: 0.0532  max mem: 10412
Epoch: [0]  [3220/4572]  eta: 0:01:23    time: 0.0585  data: 0.0521  max mem: 10412
Epoch: [0]  [3240/4572]  eta: 0:01:21    time: 0.0587  data: 0.0522  max mem: 10412
Epoch: [0]  [3260/4572]  eta: 0:01:20    time: 0.0587  data: 0.0521  max mem: 10412
Epoch: [0]  [3280/4572]  eta: 0:01:19    time: 0.0587  data: 0.0522  max mem: 10412
Epoch: [0]  [3300/4572]  eta: 0:01:18    time: 0.0586  data: 0.0521  max mem: 10412
Epoch: [0]  [3320/4572]  eta: 0:01:16    time: 0.0587  data: 0.0522  max mem: 10412
Epoch: [0]  [3340/4572]  eta: 0:01:15    time: 0.0587  data: 0.0522  max mem: 10412
Epoch: [0]  [3360/4572]  eta: 0:01:14    time: 0.0724  data: 0.0659  max mem: 10412
Epoch: [0]  [3380/4572]  eta: 0:01:13    time: 0.0586  data: 0.0521  max mem: 10412
Epoch: [0]  [3400/4572]  eta: 0:01:11    time: 0.0586  data: 0.0522  max mem: 10412
Epoch: [0]  [3420/4572]  eta: 0:01:10    time: 0.0587  data: 0.0522  max mem: 10412
Epoch: [0]  [3440/4572]  eta: 0:01:09    time: 0.0588  data: 0.0522  max mem: 10412
Epoch: [0]  [3460/4572]  eta: 0:01:08    time: 0.0609  data: 0.0544  max mem: 10412
Epoch: [0]  [3480/4572]  eta: 0:01:06    time: 0.0602  data: 0.0537  max mem: 10412
Epoch: [0]  [3500/4572]  eta: 0:01:05    time: 0.0589  data: 0.0523  max mem: 10412
Epoch: [0]  [3520/4572]  eta: 0:01:04    time: 0.0587  data: 0.0523  max mem: 10412
Epoch: [0]  [3540/4572]  eta: 0:01:03    time: 0.0592  data: 0.0526  max mem: 10412
Epoch: [0]  [3560/4572]  eta: 0:01:01    time: 0.0599  data: 0.0535  max mem: 10412
Epoch: [0]  [3580/4572]  eta: 0:01:00    time: 0.0587  data: 0.0522  max mem: 10412
Epoch: [0]  [3600/4572]  eta: 0:00:59    time: 0.0586  data: 0.0521  max mem: 10412
Epoch: [0]  [3620/4572]  eta: 0:00:58    time: 0.0587  data: 0.0522  max mem: 10412
Epoch: [0]  [3640/4572]  eta: 0:00:57    time: 0.0592  data: 0.0526  max mem: 10412
Epoch: [0]  [3660/4572]  eta: 0:00:55    time: 0.0589  data: 0.0523  max mem: 10412
Epoch: [0]  [3680/4572]  eta: 0:00:54    time: 0.0587  data: 0.0522  max mem: 10412
Epoch: [0]  [3700/4572]  eta: 0:00:53    time: 0.0586  data: 0.0521  max mem: 10412
Epoch: [0]  [3720/4572]  eta: 0:00:52    time: 0.0586  data: 0.0521  max mem: 10412
Epoch: [0]  [3740/4572]  eta: 0:00:50    time: 0.0586  data: 0.0537  max mem: 10412
Epoch: [0]  [3760/4572]  eta: 0:00:49    time: 0.0586  data: 0.0521  max mem: 10412
Epoch: [0]  [3780/4572]  eta: 0:00:48    time: 0.0587  data: 0.0522  max mem: 10412
Epoch: [0]  [3800/4572]  eta: 0:00:47    time: 0.0585  data: 0.0520  max mem: 10412
Epoch: [0]  [3820/4572]  eta: 0:00:45    time: 0.0590  data: 0.0526  max mem: 10412
Epoch: [0]  [3840/4572]  eta: 0:00:44    time: 0.0586  data: 0.0521  max mem: 10412
Epoch: [0]  [3860/4572]  eta: 0:00:43    time: 0.0587  data: 0.0522  max mem: 10412
Epoch: [0]  [3880/4572]  eta: 0:00:42    time: 0.0585  data: 0.0520  max mem: 10412
Epoch: [0]  [3900/4572]  eta: 0:00:41    time: 0.0594  data: 0.0522  max mem: 10412
Epoch: [0]  [3920/4572]  eta: 0:00:39    time: 0.0729  data: 0.0664  max mem: 10412
Epoch: [0]  [3940/4572]  eta: 0:00:38    time: 0.0585  data: 0.0520  max mem: 10412
Epoch: [0]  [3960/4572]  eta: 0:00:37    time: 0.0609  data: 0.0545  max mem: 10412
Epoch: [0]  [3980/4572]  eta: 0:00:36    time: 0.0617  data: 0.0552  max mem: 10412
Epoch: [0]  [4000/4572]  eta: 0:00:34    time: 0.0585  data: 0.0519  max mem: 10412
Epoch: [0]  [4020/4572]  eta: 0:00:33    time: 0.0595  data: 0.0530  max mem: 10412
Epoch: [0]  [4040/4572]  eta: 0:00:32    time: 0.0585  data: 0.0521  max mem: 10412
Epoch: [0]  [4060/4572]  eta: 0:00:31    time: 0.0586  data: 0.0521  max mem: 10412
Epoch: [0]  [4080/4572]  eta: 0:00:30    time: 0.0585  data: 0.0520  max mem: 10412
Epoch: [0]  [4100/4572]  eta: 0:00:28    time: 0.0592  data: 0.0528  max mem: 10412
Epoch: [0]  [4120/4572]  eta: 0:00:27    time: 0.0632  data: 0.0567  max mem: 10412
Epoch: [0]  [4140/4572]  eta: 0:00:26    time: 0.0585  data: 0.0521  max mem: 10412
Epoch: [0]  [4160/4572]  eta: 0:00:25    time: 0.0586  data: 0.0520  max mem: 10412
Epoch: [0]  [4180/4572]  eta: 0:00:23    time: 0.0587  data: 0.0521  max mem: 10412
Epoch: [0]  [4200/4572]  eta: 0:00:22    time: 0.0585  data: 0.0520  max mem: 10412
Epoch: [0]  [4220/4572]  eta: 0:00:21    time: 0.0585  data: 0.0520  max mem: 10412
Epoch: [0]  [4240/4572]  eta: 0:00:20    time: 0.0584  data: 0.0519  max mem: 10412
Epoch: [0]  [4260/4572]  eta: 0:00:19    time: 0.0631  data: 0.0567  max mem: 10412
Epoch: [0]  [4280/4572]  eta: 0:00:17    time: 0.0586  data: 0.0521  max mem: 10412
Epoch: [0]  [4300/4572]  eta: 0:00:16    time: 0.0585  data: 0.0521  max mem: 10412
Epoch: [0]  [4320/4572]  eta: 0:00:15    time: 0.0585  data: 0.0520  max mem: 10412
Epoch: [0]  [4340/4572]  eta: 0:00:14    time: 0.0586  data: 0.0521  max mem: 10412
Epoch: [0]  [4360/4572]  eta: 0:00:12    time: 0.0629  data: 0.0565  max mem: 10412
Epoch: [0]  [4380/4572]  eta: 0:00:11    time: 0.0584  data: 0.0518  max mem: 10412
Epoch: [0]  [4400/4572]  eta: 0:00:10    time: 0.0585  data: 0.0521  max mem: 10412
Epoch: [0]  [4420/4572]  eta: 0:00:09    time: 0.0584  data: 0.0520  max mem: 10412
Epoch: [0]  [4440/4572]  eta: 0:00:08    time: 0.0586  data: 0.0522  max mem: 10412
Epoch: [0]  [4460/4572]  eta: 0:00:06    time: 0.0584  data: 0.0520  max mem: 10412
Epoch: [0]  [4480/4572]  eta: 0:00:05    time: 0.0731  data: 0.0665  max mem: 10412
Epoch: [0]  [4500/4572]  eta: 0:00:04    time: 0.0586  data: 0.0521  max mem: 10412
Epoch: [0]  [4520/4572]  eta: 0:00:03    time: 0.0585  data: 0.0520  max mem: 10412
Epoch: [0]  [4540/4572]  eta: 0:00:01    time: 0.0586  data: 0.0520  max mem: 10412
Epoch: [0]  [4560/4572]  eta: 0:00:00    time: 0.0612  data: 0.0547  max mem: 10412
Epoch: [0]  [4571/4572]  eta: 0:00:00    time: 0.0585  data: 0.0520  max mem: 10412
Epoch: [0] Total time: 0:04:38 (0.0609 s / it)
:::MLLOG {"namespace": "", "time_ms": 1696364193455, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": 0, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 330, "epoch_num": 0}}
:::MLLOG {"namespace": "", "time_ms": 1696364193456, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 262.76112603496614}, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 334, "step": 1}}
:::MLLOG {"namespace": "", "time_ms": 1696364193456, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 344, "epoch_num": 1}}
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
Test:  [ 0/97]  eta: 0:00:19  model_time: 0.1957 (0.1957)  evaluator_time: 0.0017 (0.0017)  time: 0.1978  data: 0.0003  max mem: 10412
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
Test:  [20/97]  eta: 0:00:11  model_time: 0.1419 (0.1456)  evaluator_time: 0.0019 (0.0019)  time: 0.1458  data: 0.0006  max mem: 10412
Test:  [40/97]  eta: 0:00:08  model_time: 0.1455 (0.1447)  evaluator_time: 0.0020 (0.0020)  time: 0.1465  data: 0.0006  max mem: 10412
Test:  [60/97]  eta: 0:00:05  model_time: 0.1501 (0.1459)  evaluator_time: 0.0021 (0.0020)  time: 0.1513  data: 0.0006  max mem: 10412
Test:  [80/97]  eta: 0:00:02  model_time: 0.1448 (0.1452)  evaluator_time: 0.0021 (0.0020)  time: 0.1456  data: 0.0006  max mem: 10412
Test:  [96/97]  eta: 0:00:00  model_time: 0.1494 (0.1452)  evaluator_time: 0.0019 (0.0020)  time: 0.1481  data: 0.0006  max mem: 10412
Test: Total time: 0:00:14 (0.1479 s / it)
Averaged stats: model_time: 0.1494 (0.1467)  evaluator_time: 0.0019 (0.0021)
:::MLLOG {"namespace": "", "time_ms": 1696364208631, "event_type": "INTERVAL_START", "key": "epoch_start", "value": 1, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 158, "epoch_num": 1}}
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
Epoch: [1]  [   0/4571]  eta: 0:04:27    time: 0.0585  data: 0.0009  max mem: 10412
Epoch: [1]  [  20/4571]  eta: 0:04:26    time: 0.0585  data: 0.0519  max mem: 10412
Epoch: [1]  [  40/4571]  eta: 0:04:27    time: 0.0597  data: 0.0533  max mem: 10412
/usr/local/lib/python3.10/dist-packages/torch/jit/annotations.py:386: UserWarning: TorchScript will treat type annotations of Tensor dtype-specific subtypes as if they are normal Tensors. dtype constraints are not enforced in compilation either.
  warnings.warn(
Epoch: [1]  [  60/4571]  eta: 0:04:25    time: 0.0583  data: 0.0517  max mem: 10412
Epoch: [1]  [  80/4571]  eta: 0:04:23    time: 0.0581  data: 0.0516  max mem: 10412
Epoch: [1]  [ 100/4571]  eta: 0:04:21    time: 0.0582  data: 0.0517  max mem: 10412
Epoch: [1]  [ 120/4571]  eta: 0:04:20    time: 0.0582  data: 0.0518  max mem: 10412
Epoch: [1]  [ 140/4571]  eta: 0:04:19    time: 0.0583  data: 0.0517  max mem: 10412
Epoch: [1]  [ 160/4571]  eta: 0:04:18    time: 0.0592  data: 0.0526  max mem: 10412
:::MLLOG {"namespace": "", "time_ms": 1696364218533, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.2368209260274295, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 437, "epoch_num": 1}}
:::MLLOG {"namespace": "", "time_ms": 1696364218534, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 438, "epoch_num": 1}}
Epoch: [1]  [ 180/4571]  eta: 0:04:17    time: 0.0583  data: 0.0518  max mem: 10412
Epoch: [1]  [ 200/4571]  eta: 0:04:15    time: 0.0585  data: 0.0519  max mem: 10412
Epoch: [1]  [ 220/4571]  eta: 0:04:14    time: 0.0586  data: 0.0522  max mem: 10412
Epoch: [1]  [ 240/4571]  eta: 0:04:13    time: 0.0583  data: 0.0518  max mem: 10412
Epoch: [1]  [ 260/4571]  eta: 0:04:12    time: 0.0592  data: 0.0528  max mem: 10412
Epoch: [1]  [ 280/4571]  eta: 0:04:11    time: 0.0583  data: 0.0519  max mem: 10412
Epoch: [1]  [ 300/4571]  eta: 0:04:10    time: 0.0584  data: 0.0519  max mem: 10412
Epoch: [1]  [ 320/4571]  eta: 0:04:09    time: 0.0591  data: 0.0526  max mem: 10412
Epoch: [1]  [ 340/4571]  eta: 0:04:07    time: 0.0589  data: 0.0524  max mem: 10412
Epoch: [1]  [ 360/4571]  eta: 0:04:06    time: 0.0584  data: 0.0519  max mem: 10412
Epoch: [1]  [ 380/4571]  eta: 0:04:05    time: 0.0585  data: 0.0519  max mem: 10412
Epoch: [1]  [ 400/4571]  eta: 0:04:04    time: 0.0583  data: 0.0518  max mem: 10412
Epoch: [1]  [ 420/4571]  eta: 0:04:03    time: 0.0583  data: 0.0519  max mem: 10412
Epoch: [1]  [ 440/4571]  eta: 0:04:02    time: 0.0593  data: 0.0528  max mem: 10412
Epoch: [1]  [ 460/4571]  eta: 0:04:00    time: 0.0584  data: 0.0519  max mem: 10412
Epoch: [1]  [ 480/4571]  eta: 0:03:59    time: 0.0584  data: 0.0519  max mem: 10412
Epoch: [1]  [ 500/4571]  eta: 0:03:58    time: 0.0584  data: 0.0519  max mem: 10412
Epoch: [1]  [ 520/4571]  eta: 0:03:57    time: 0.0584  data: 0.0520  max mem: 10412
Epoch: [1]  [ 540/4571]  eta: 0:03:56    time: 0.0583  data: 0.0518  max mem: 10412
Epoch: [1]  [ 560/4571]  eta: 0:03:54    time: 0.0584  data: 0.0519  max mem: 10412
Epoch: [1]  [ 580/4571]  eta: 0:03:53    time: 0.0585  data: 0.0520  max mem: 10412
Epoch: [1]  [ 600/4571]  eta: 0:03:52    time: 0.0583  data: 0.0518  max mem: 10412
Epoch: [1]  [ 620/4571]  eta: 0:03:51    time: 0.0585  data: 0.0520  max mem: 10412
Epoch: [1]  [ 640/4571]  eta: 0:03:50    time: 0.0584  data: 0.0519  max mem: 10412
Epoch: [1]  [ 660/4571]  eta: 0:03:48    time: 0.0585  data: 0.0520  max mem: 10412
Epoch: [1]  [ 680/4571]  eta: 0:03:47    time: 0.0584  data: 0.0519  max mem: 10412
Epoch: [1]  [ 700/4571]  eta: 0:03:46    time: 0.0583  data: 0.0519  max mem: 10412
Epoch: [1]  [ 720/4571]  eta: 0:03:45    time: 0.0585  data: 0.0519  max mem: 10412
Epoch: [1]  [ 740/4571]  eta: 0:03:44    time: 0.0584  data: 0.0519  max mem: 10412
Epoch: [1]  [ 760/4571]  eta: 0:03:46    time: 0.0964  data: 0.0900  max mem: 10412
Epoch: [1]  [ 780/4571]  eta: 0:03:45    time: 0.0582  data: 0.0517  max mem: 10412
Epoch: [1]  [ 800/4571]  eta: 0:03:44    time: 0.0582  data: 0.0518  max mem: 10412
Epoch: [1]  [ 820/4571]  eta: 0:03:42    time: 0.0584  data: 0.0519  max mem: 10412
Epoch: [1]  [ 840/4571]  eta: 0:03:41    time: 0.0595  data: 0.0530  max mem: 10412
Epoch: [1]  [ 860/4571]  eta: 0:03:40    time: 0.0584  data: 0.0520  max mem: 10412
Epoch: [1]  [ 880/4571]  eta: 0:03:39    time: 0.0584  data: 0.0519  max mem: 10412
Epoch: [1]  [ 900/4571]  eta: 0:03:38    time: 0.0624  data: 0.0560  max mem: 10412
Epoch: [1]  [ 920/4571]  eta: 0:03:36    time: 0.0585  data: 0.0520  max mem: 10412
Epoch: [1]  [ 940/4571]  eta: 0:03:35    time: 0.0583  data: 0.0518  max mem: 10412
Epoch: [1]  [ 960/4571]  eta: 0:03:34    time: 0.0584  data: 0.0519  max mem: 10412
Epoch: [1]  [ 980/4571]  eta: 0:03:33    time: 0.0583  data: 0.0518  max mem: 10412
Epoch: [1]  [1000/4571]  eta: 0:03:31    time: 0.0585  data: 0.0520  max mem: 10412
Epoch: [1]  [1020/4571]  eta: 0:03:30    time: 0.0584  data: 0.0519  max mem: 10412
Epoch: [1]  [1040/4571]  eta: 0:03:29    time: 0.0583  data: 0.0518  max mem: 10412
Epoch: [1]  [1060/4571]  eta: 0:03:28    time: 0.0603  data: 0.0538  max mem: 10412
Epoch: [1]  [1080/4571]  eta: 0:03:27    time: 0.0594  data: 0.0529  max mem: 10412
Epoch: [1]  [1100/4571]  eta: 0:03:25    time: 0.0584  data: 0.0520  max mem: 10412
Epoch: [1]  [1120/4571]  eta: 0:03:24    time: 0.0585  data: 0.0519  max mem: 10412
Corrupt JPEG data: premature end of data segment
Epoch: [1]  [1140/4571]  eta: 0:03:23    time: 0.0583  data: 0.0519  max mem: 10412
Epoch: [1]  [1160/4571]  eta: 0:03:22    time: 0.0585  data: 0.0520  max mem: 10412
Epoch: [1]  [1180/4571]  eta: 0:03:20    time: 0.0583  data: 0.0518  max mem: 10412
Epoch: [1]  [1200/4571]  eta: 0:03:19    time: 0.0585  data: 0.0520  max mem: 10412
Epoch: [1]  [1220/4571]  eta: 0:03:18    time: 0.0584  data: 0.0519  max mem: 10412
Epoch: [1]  [1240/4571]  eta: 0:03:17    time: 0.0585  data: 0.0520  max mem: 10412
Epoch: [1]  [1260/4571]  eta: 0:03:15    time: 0.0583  data: 0.0518  max mem: 10412
Epoch: [1]  [1280/4571]  eta: 0:03:14    time: 0.0601  data: 0.0536  max mem: 10412
Epoch: [1]  [1300/4571]  eta: 0:03:13    time: 0.0584  data: 0.0520  max mem: 10412
Epoch: [1]  [1320/4571]  eta: 0:03:12    time: 0.0584  data: 0.0519  max mem: 10412
Epoch: [1]  [1340/4571]  eta: 0:03:11    time: 0.0586  data: 0.0521  max mem: 10412
Epoch: [1]  [1360/4571]  eta: 0:03:10    time: 0.0607  data: 0.0542  max mem: 10412
Epoch: [1]  [1380/4571]  eta: 0:03:08    time: 0.0586  data: 0.0521  max mem: 10412
Epoch: [1]  [1400/4571]  eta: 0:03:07    time: 0.0584  data: 0.0520  max mem: 10412
Epoch: [1]  [1420/4571]  eta: 0:03:06    time: 0.0585  data: 0.0520  max mem: 10412
Epoch: [1]  [1440/4571]  eta: 0:03:05    time: 0.0584  data: 0.0519  max mem: 10412
Epoch: [1]  [1460/4571]  eta: 0:03:04    time: 0.0585  data: 0.0520  max mem: 10412
Epoch: [1]  [1480/4571]  eta: 0:03:02    time: 0.0583  data: 0.0518  max mem: 10412
Epoch: [1]  [1500/4571]  eta: 0:03:01    time: 0.0585  data: 0.0520  max mem: 10412
Epoch: [1]  [1520/4571]  eta: 0:03:00    time: 0.0583  data: 0.0518  max mem: 10412
Epoch: [1]  [1540/4571]  eta: 0:02:59    time: 0.0584  data: 0.0520  max mem: 10412
Epoch: [1]  [1560/4571]  eta: 0:02:57    time: 0.0585  data: 0.0520  max mem: 10412
Epoch: [1]  [1580/4571]  eta: 0:02:56    time: 0.0587  data: 0.0522  max mem: 10412
Epoch: [1]  [1600/4571]  eta: 0:02:55    time: 0.0583  data: 0.0518  max mem: 10412
Epoch: [1]  [1620/4571]  eta: 0:02:54    time: 0.0588  data: 0.0523  max mem: 10412
Epoch: [1]  [1640/4571]  eta: 0:02:53    time: 0.0584  data: 0.0519  max mem: 10412
Epoch: [1]  [1660/4571]  eta: 0:02:51    time: 0.0585  data: 0.0519  max mem: 10412
Epoch: [1]  [1680/4571]  eta: 0:02:51    time: 0.0933  data: 0.0868  max mem: 10412
Epoch: [1]  [1700/4571]  eta: 0:02:50    time: 0.0627  data: 0.0562  max mem: 10412
Epoch: [1]  [1720/4571]  eta: 0:02:49    time: 0.0583  data: 0.0519  max mem: 10412
Epoch: [1]  [1740/4571]  eta: 0:02:48    time: 0.0584  data: 0.0520  max mem: 10412
Epoch: [1]  [1760/4571]  eta: 0:02:47    time: 0.0583  data: 0.0518  max mem: 10412
Epoch: [1]  [1780/4571]  eta: 0:02:45    time: 0.0584  data: 0.0519  max mem: 10412
Epoch: [1]  [1800/4571]  eta: 0:02:44    time: 0.0608  data: 0.0519  max mem: 10412
Epoch: [1]  [1820/4571]  eta: 0:02:43    time: 0.0584  data: 0.0519  max mem: 10412
Epoch: [1]  [1840/4571]  eta: 0:02:42    time: 0.0583  data: 0.0518  max mem: 10412
Epoch: [1]  [1860/4571]  eta: 0:02:41    time: 0.0594  data: 0.0530  max mem: 10412
Epoch: [1]  [1880/4571]  eta: 0:02:39    time: 0.0584  data: 0.0518  max mem: 10412
Epoch: [1]  [1900/4571]  eta: 0:02:38    time: 0.0584  data: 0.0519  max mem: 10412
Epoch: [1]  [1920/4571]  eta: 0:02:37    time: 0.0585  data: 0.0520  max mem: 10412
Epoch: [1]  [1940/4571]  eta: 0:02:36    time: 0.0582  data: 0.0517  max mem: 10412
Epoch: [1]  [1960/4571]  eta: 0:02:35    time: 0.0587  data: 0.0522  max mem: 10412
Epoch: [1]  [1980/4571]  eta: 0:02:33    time: 0.0602  data: 0.0537  max mem: 10412
Epoch: [1]  [2000/4571]  eta: 0:02:32    time: 0.0584  data: 0.0519  max mem: 10412
Epoch: [1]  [2020/4571]  eta: 0:02:31    time: 0.0584  data: 0.0519  max mem: 10412
Epoch: [1]  [2040/4571]  eta: 0:02:30    time: 0.0582  data: 0.0518  max mem: 10412
Epoch: [1]  [2060/4571]  eta: 0:02:29    time: 0.0583  data: 0.0519  max mem: 10412
Epoch: [1]  [2080/4571]  eta: 0:02:27    time: 0.0585  data: 0.0535  max mem: 10412
Epoch: [1]  [2100/4571]  eta: 0:02:26    time: 0.0582  data: 0.0517  max mem: 10412
Epoch: [1]  [2120/4571]  eta: 0:02:25    time: 0.0585  data: 0.0520  max mem: 10412
Epoch: [1]  [2140/4571]  eta: 0:02:24    time: 0.0584  data: 0.0519  max mem: 10412
Epoch: [1]  [2160/4571]  eta: 0:02:23    time: 0.0583  data: 0.0519  max mem: 10412
Epoch: [1]  [2180/4571]  eta: 0:02:21    time: 0.0637  data: 0.0573  max mem: 10412
Epoch: [1]  [2200/4571]  eta: 0:02:20    time: 0.0585  data: 0.0520  max mem: 10412
Epoch: [1]  [2220/4571]  eta: 0:02:19    time: 0.0583  data: 0.0517  max mem: 10412
Epoch: [1]  [2240/4571]  eta: 0:02:18    time: 0.0582  data: 0.0518  max mem: 10412
Epoch: [1]  [2260/4571]  eta: 0:02:17    time: 0.0583  data: 0.0519  max mem: 10412
Epoch: [1]  [2280/4571]  eta: 0:02:15    time: 0.0583  data: 0.0518  max mem: 10412
Epoch: [1]  [2300/4571]  eta: 0:02:14    time: 0.0582  data: 0.0516  max mem: 10412
Epoch: [1]  [2320/4571]  eta: 0:02:13    time: 0.0584  data: 0.0519  max mem: 10412
Epoch: [1]  [2340/4571]  eta: 0:02:12    time: 0.0584  data: 0.0518  max mem: 10412
Epoch: [1]  [2360/4571]  eta: 0:02:11    time: 0.0583  data: 0.0519  max mem: 10412
Epoch: [1]  [2380/4571]  eta: 0:02:09    time: 0.0584  data: 0.0519  max mem: 10412
Epoch: [1]  [2400/4571]  eta: 0:02:08    time: 0.0583  data: 0.0518  max mem: 10412
Epoch: [1]  [2420/4571]  eta: 0:02:07    time: 0.0585  data: 0.0519  max mem: 10412
Epoch: [1]  [2440/4571]  eta: 0:02:06    time: 0.0583  data: 0.0518  max mem: 10412
Epoch: [1]  [2460/4571]  eta: 0:02:05    time: 0.0583  data: 0.0519  max mem: 10412
Epoch: [1]  [2480/4571]  eta: 0:02:03    time: 0.0584  data: 0.0519  max mem: 10412
Epoch: [1]  [2500/4571]  eta: 0:02:02    time: 0.0582  data: 0.0517  max mem: 10412
Epoch: [1]  [2520/4571]  eta: 0:02:01    time: 0.0584  data: 0.0520  max mem: 10412
Epoch: [1]  [2540/4571]  eta: 0:02:00    time: 0.0584  data: 0.0518  max mem: 10412
Epoch: [1]  [2560/4571]  eta: 0:01:59    time: 0.0583  data: 0.0518  max mem: 10412
Epoch: [1]  [2580/4571]  eta: 0:01:57    time: 0.0584  data: 0.0520  max mem: 10412
Epoch: [1]  [2600/4571]  eta: 0:01:56    time: 0.0583  data: 0.0518  max mem: 10412
Epoch: [1]  [2620/4571]  eta: 0:01:55    time: 0.0607  data: 0.0543  max mem: 10412
Epoch: [1]  [2640/4571]  eta: 0:01:54    time: 0.0584  data: 0.0519  max mem: 10412
Epoch: [1]  [2660/4571]  eta: 0:01:53    time: 0.0604  data: 0.0539  max mem: 10412
Epoch: [1]  [2680/4571]  eta: 0:01:51    time: 0.0583  data: 0.0519  max mem: 10412
Epoch: [1]  [2700/4571]  eta: 0:01:50    time: 0.0584  data: 0.0519  max mem: 10412
Epoch: [1]  [2720/4571]  eta: 0:01:49    time: 0.0585  data: 0.0520  max mem: 10412
Epoch: [1]  [2740/4571]  eta: 0:01:48    time: 0.0582  data: 0.0518  max mem: 10412
Epoch: [1]  [2760/4571]  eta: 0:01:47    time: 0.0584  data: 0.0519  max mem: 10412
Epoch: [1]  [2780/4571]  eta: 0:01:45    time: 0.0583  data: 0.0518  max mem: 10412
Epoch: [1]  [2800/4571]  eta: 0:01:44    time: 0.0583  data: 0.0518  max mem: 10412
Epoch: [1]  [2820/4571]  eta: 0:01:43    time: 0.0583  data: 0.0519  max mem: 10412
Epoch: [1]  [2840/4571]  eta: 0:01:42    time: 0.0583  data: 0.0518  max mem: 10412
Epoch: [1]  [2860/4571]  eta: 0:01:41    time: 0.0583  data: 0.0518  max mem: 10412
Epoch: [1]  [2880/4571]  eta: 0:01:40    time: 0.0584  data: 0.0519  max mem: 10412
Epoch: [1]  [2900/4571]  eta: 0:01:38    time: 0.0582  data: 0.0517  max mem: 10412
Epoch: [1]  [2920/4571]  eta: 0:01:37    time: 0.0585  data: 0.0521  max mem: 10412
Epoch: [1]  [2940/4571]  eta: 0:01:36    time: 0.0594  data: 0.0529  max mem: 10412
Epoch: [1]  [2960/4571]  eta: 0:01:35    time: 0.0583  data: 0.0518  max mem: 10412
Epoch: [1]  [2980/4571]  eta: 0:01:34    time: 0.0584  data: 0.0519  max mem: 10412
Epoch: [1]  [3000/4571]  eta: 0:01:33    time: 0.0950  data: 0.0886  max mem: 10412
Epoch: [1]  [3020/4571]  eta: 0:01:32    time: 0.0583  data: 0.0518  max mem: 10412
Epoch: [1]  [3040/4571]  eta: 0:01:30    time: 0.0583  data: 0.0518  max mem: 10412
Epoch: [1]  [3060/4571]  eta: 0:01:29    time: 0.0584  data: 0.0519  max mem: 10412
Epoch: [1]  [3080/4571]  eta: 0:01:28    time: 0.0583  data: 0.0518  max mem: 10412
Epoch: [1]  [3100/4571]  eta: 0:01:27    time: 0.0582  data: 0.0517  max mem: 10412
Epoch: [1]  [3120/4571]  eta: 0:01:26    time: 0.0583  data: 0.0519  max mem: 10412
Epoch: [1]  [3140/4571]  eta: 0:01:24    time: 0.0583  data: 0.0518  max mem: 10412
Epoch: [1]  [3160/4571]  eta: 0:01:23    time: 0.0583  data: 0.0519  max mem: 10412
Epoch: [1]  [3180/4571]  eta: 0:01:22    time: 0.0594  data: 0.0529  max mem: 10412
Epoch: [1]  [3200/4571]  eta: 0:01:21    time: 0.0583  data: 0.0518  max mem: 10412
Epoch: [1]  [3220/4571]  eta: 0:01:20    time: 0.0584  data: 0.0519  max mem: 10412
Epoch: [1]  [3240/4571]  eta: 0:01:18    time: 0.0583  data: 0.0518  max mem: 10412
Epoch: [1]  [3260/4571]  eta: 0:01:17    time: 0.0582  data: 0.0518  max mem: 10412
Epoch: [1]  [3280/4571]  eta: 0:01:16    time: 0.0582  data: 0.0518  max mem: 10412
Epoch: [1]  [3300/4571]  eta: 0:01:15    time: 0.0584  data: 0.0519  max mem: 10412
Epoch: [1]  [3320/4571]  eta: 0:01:14    time: 0.0595  data: 0.0517  max mem: 10412
Epoch: [1]  [3340/4571]  eta: 0:01:12    time: 0.0583  data: 0.0517  max mem: 10412
Epoch: [1]  [3360/4571]  eta: 0:01:11    time: 0.0582  data: 0.0517  max mem: 10412
Epoch: [1]  [3380/4571]  eta: 0:01:10    time: 0.0582  data: 0.0518  max mem: 10412
Epoch: [1]  [3400/4571]  eta: 0:01:09    time: 0.0582  data: 0.0518  max mem: 10412
Epoch: [1]  [3420/4571]  eta: 0:01:08    time: 0.0584  data: 0.0519  max mem: 10412
Epoch: [1]  [3440/4571]  eta: 0:01:07    time: 0.0624  data: 0.0559  max mem: 10412
Epoch: [1]  [3460/4571]  eta: 0:01:05    time: 0.0584  data: 0.0519  max mem: 10412
Epoch: [1]  [3480/4571]  eta: 0:01:04    time: 0.0975  data: 0.0909  max mem: 10412
Epoch: [1]  [3500/4571]  eta: 0:01:03    time: 0.0582  data: 0.0518  max mem: 10412
Epoch: [1]  [3520/4571]  eta: 0:01:02    time: 0.0603  data: 0.0539  max mem: 10412
Epoch: [1]  [3540/4571]  eta: 0:01:01    time: 0.0584  data: 0.0520  max mem: 10412
Epoch: [1]  [3560/4571]  eta: 0:01:00    time: 0.0583  data: 0.0518  max mem: 10412
Epoch: [1]  [3580/4571]  eta: 0:00:58    time: 0.0595  data: 0.0530  max mem: 10412
Epoch: [1]  [3600/4571]  eta: 0:00:57    time: 0.0595  data: 0.0531  max mem: 10412
Epoch: [1]  [3620/4571]  eta: 0:00:56    time: 0.0583  data: 0.0518  max mem: 10412
Epoch: [1]  [3640/4571]  eta: 0:00:55    time: 0.0583  data: 0.0518  max mem: 10412
Epoch: [1]  [3660/4571]  eta: 0:00:54    time: 0.0583  data: 0.0518  max mem: 10412
Epoch: [1]  [3680/4571]  eta: 0:00:52    time: 0.0584  data: 0.0519  max mem: 10412
Epoch: [1]  [3700/4571]  eta: 0:00:51    time: 0.0583  data: 0.0517  max mem: 10412
Epoch: [1]  [3720/4571]  eta: 0:00:50    time: 0.0591  data: 0.0519  max mem: 10412
Epoch: [1]  [3740/4571]  eta: 0:00:49    time: 0.0581  data: 0.0517  max mem: 10412
Epoch: [1]  [3760/4571]  eta: 0:00:48    time: 0.0583  data: 0.0519  max mem: 10412
Epoch: [1]  [3780/4571]  eta: 0:00:46    time: 0.0582  data: 0.0517  max mem: 10412
Epoch: [1]  [3800/4571]  eta: 0:00:45    time: 0.0583  data: 0.0519  max mem: 10412
Epoch: [1]  [3820/4571]  eta: 0:00:44    time: 0.0582  data: 0.0518  max mem: 10412
Epoch: [1]  [3840/4571]  eta: 0:00:43    time: 0.0583  data: 0.0518  max mem: 10412
Epoch: [1]  [3860/4571]  eta: 0:00:42    time: 0.0582  data: 0.0517  max mem: 10412
Epoch: [1]  [3880/4571]  eta: 0:00:41    time: 0.0585  data: 0.0520  max mem: 10412
Epoch: [1]  [3900/4571]  eta: 0:00:39    time: 0.0582  data: 0.0517  max mem: 10412
Epoch: [1]  [3920/4571]  eta: 0:00:38    time: 0.0912  data: 0.0847  max mem: 10412
Epoch: [1]  [3940/4571]  eta: 0:00:37    time: 0.0582  data: 0.0518  max mem: 10412
Epoch: [1]  [3960/4571]  eta: 0:00:36    time: 0.0585  data: 0.0519  max mem: 10412
Epoch: [1]  [3980/4571]  eta: 0:00:35    time: 0.0582  data: 0.0517  max mem: 10412
Epoch: [1]  [4000/4571]  eta: 0:00:33    time: 0.0583  data: 0.0518  max mem: 10412
Epoch: [1]  [4020/4571]  eta: 0:00:32    time: 0.0583  data: 0.0518  max mem: 10412
Epoch: [1]  [4040/4571]  eta: 0:00:31    time: 0.0582  data: 0.0518  max mem: 10412
Epoch: [1]  [4060/4571]  eta: 0:00:30    time: 0.0582  data: 0.0517  max mem: 10412
Epoch: [1]  [4080/4571]  eta: 0:00:29    time: 0.0583  data: 0.0518  max mem: 10412
Epoch: [1]  [4100/4571]  eta: 0:00:28    time: 0.0582  data: 0.0517  max mem: 10412
Epoch: [1]  [4120/4571]  eta: 0:00:26    time: 0.0609  data: 0.0543  max mem: 10412
Epoch: [1]  [4140/4571]  eta: 0:00:25    time: 0.0583  data: 0.0518  max mem: 10412
Epoch: [1]  [4160/4571]  eta: 0:00:24    time: 0.0583  data: 0.0519  max mem: 10412
Epoch: [1]  [4180/4571]  eta: 0:00:23    time: 0.0583  data: 0.0518  max mem: 10412
Epoch: [1]  [4200/4571]  eta: 0:00:22    time: 0.0582  data: 0.0518  max mem: 10412
Epoch: [1]  [4220/4571]  eta: 0:00:20    time: 0.0936  data: 0.0871  max mem: 10412
Epoch: [1]  [4240/4571]  eta: 0:00:19    time: 0.0591  data: 0.0527  max mem: 10412
Epoch: [1]  [4260/4571]  eta: 0:00:18    time: 0.0582  data: 0.0517  max mem: 10412
Epoch: [1]  [4280/4571]  eta: 0:00:17    time: 0.0928  data: 0.0863  max mem: 10412
Epoch: [1]  [4300/4571]  eta: 0:00:16    time: 0.0582  data: 0.0517  max mem: 10412
Epoch: [1]  [4320/4571]  eta: 0:00:15    time: 0.0583  data: 0.0519  max mem: 10412
Epoch: [1]  [4340/4571]  eta: 0:00:13    time: 0.0594  data: 0.0529  max mem: 10412
Epoch: [1]  [4360/4571]  eta: 0:00:12    time: 0.0583  data: 0.0518  max mem: 10412
Epoch: [1]  [4380/4571]  eta: 0:00:11    time: 0.0583  data: 0.0518  max mem: 10412
Epoch: [1]  [4400/4571]  eta: 0:00:10    time: 0.0582  data: 0.0517  max mem: 10412
Epoch: [1]  [4420/4571]  eta: 0:00:09    time: 0.0584  data: 0.0518  max mem: 10412
Epoch: [1]  [4440/4571]  eta: 0:00:07    time: 0.0582  data: 0.0518  max mem: 10412
Epoch: [1]  [4460/4571]  eta: 0:00:06    time: 0.0584  data: 0.0519  max mem: 10412
Epoch: [1]  [4480/4571]  eta: 0:00:05    time: 0.0582  data: 0.0517  max mem: 10412
Epoch: [1]  [4500/4571]  eta: 0:00:04    time: 0.0592  data: 0.0527  max mem: 10412
Epoch: [1]  [4520/4571]  eta: 0:00:03    time: 0.0584  data: 0.0519  max mem: 10412
Epoch: [1]  [4540/4571]  eta: 0:00:01    time: 0.0583  data: 0.0518  max mem: 10412
Epoch: [1]  [4560/4571]  eta: 0:00:00    time: 0.0583  data: 0.0518  max mem: 10412
Epoch: [1]  [4570/4571]  eta: 0:00:00    time: 0.0584  data: 0.0518  max mem: 10412
Epoch: [1] Total time: 0:04:32 (0.0597 s / it)
:::MLLOG {"namespace": "", "time_ms": 1696364481600, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": 1, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 330, "epoch_num": 1}}
:::MLLOG {"namespace": "", "time_ms": 1696364481600, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 268.0486829200005}, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 334, "step": 2}}
:::MLLOG {"namespace": "", "time_ms": 1696364481600, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 344, "epoch_num": 2}}
Test:  [ 0/97]  eta: 0:00:14  model_time: 0.1430 (0.1430)  evaluator_time: 0.0020 (0.0020)  time: 0.1457  data: 0.0006  max mem: 10412
Test:  [20/97]  eta: 0:00:10  model_time: 0.1396 (0.1389)  evaluator_time: 0.0020 (0.0020)  time: 0.1414  data: 0.0006  max mem: 10412
Test:  [40/97]  eta: 0:00:08  model_time: 0.1388 (0.1378)  evaluator_time: 0.0021 (0.0034)  time: 0.1423  data: 0.0006  max mem: 10412
Test:  [60/97]  eta: 0:00:05  model_time: 0.1358 (0.1378)  evaluator_time: 0.0020 (0.0029)  time: 0.1405  data: 0.0006  max mem: 10412
Test:  [80/97]  eta: 0:00:02  model_time: 0.1386 (0.1378)  evaluator_time: 0.0020 (0.0027)  time: 0.1406  data: 0.0006  max mem: 10412
Test:  [96/97]  eta: 0:00:00  model_time: 0.1423 (0.1383)  evaluator_time: 0.0019 (0.0026)  time: 0.1431  data: 0.0006  max mem: 10412
Test: Total time: 0:00:13 (0.1417 s / it)
Averaged stats: model_time: 0.1423 (0.1398)  evaluator_time: 0.0019 (0.0026)
:::MLLOG {"namespace": "", "time_ms": 1696364496578, "event_type": "INTERVAL_START", "key": "epoch_start", "value": 2, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 158, "epoch_num": 2}}
Epoch: [2]  [   0/4572]  eta: 0:04:27    time: 0.0584  data: 0.0008  max mem: 10412
Epoch: [2]  [  20/4572]  eta: 0:04:23    time: 0.0580  data: 0.0515  max mem: 10412
Epoch: [2]  [  40/4572]  eta: 0:04:22    time: 0.0580  data: 0.0515  max mem: 10412
Epoch: [2]  [  60/4572]  eta: 0:04:21    time: 0.0579  data: 0.0514  max mem: 10412
Epoch: [2]  [  80/4572]  eta: 0:04:20    time: 0.0580  data: 0.0515  max mem: 10412
:::MLLOG {"namespace": "", "time_ms": 1696364502033, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.2947737603379433, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 437, "epoch_num": 2}}
:::MLLOG {"namespace": "", "time_ms": 1696364502033, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 438, "epoch_num": 2}}
Epoch: [2]  [ 100/4572]  eta: 0:04:19    time: 0.0580  data: 0.0514  max mem: 10412
Epoch: [2]  [ 120/4572]  eta: 0:04:18    time: 0.0580  data: 0.0515  max mem: 10412
Epoch: [2]  [ 140/4572]  eta: 0:04:19    time: 0.0627  data: 0.0562  max mem: 10412
Epoch: [2]  [ 160/4572]  eta: 0:04:18    time: 0.0586  data: 0.0521  max mem: 10412
Epoch: [2]  [ 180/4572]  eta: 0:04:32    time: 0.0889  data: 0.0852  max mem: 10412
Epoch: [2]  [ 200/4572]  eta: 0:04:29    time: 0.0592  data: 0.0527  max mem: 10412
Epoch: [2]  [ 220/4572]  eta: 0:04:27    time: 0.0582  data: 0.0518  max mem: 10412
Epoch: [2]  [ 240/4572]  eta: 0:04:25    time: 0.0603  data: 0.0538  max mem: 10412
Epoch: [2]  [ 260/4572]  eta: 0:04:23    time: 0.0582  data: 0.0517  max mem: 10412
Epoch: [2]  [ 280/4572]  eta: 0:04:21    time: 0.0581  data: 0.0516  max mem: 10412
Epoch: [2]  [ 300/4572]  eta: 0:04:19    time: 0.0581  data: 0.0516  max mem: 10412
Epoch: [2]  [ 320/4572]  eta: 0:04:17    time: 0.0582  data: 0.0518  max mem: 10412
Epoch: [2]  [ 340/4572]  eta: 0:04:15    time: 0.0594  data: 0.0530  max mem: 10412
Epoch: [2]  [ 360/4572]  eta: 0:04:14    time: 0.0582  data: 0.0517  max mem: 10412
Epoch: [2]  [ 380/4572]  eta: 0:04:12    time: 0.0581  data: 0.0517  max mem: 10412
Epoch: [2]  [ 400/4572]  eta: 0:04:10    time: 0.0581  data: 0.0517  max mem: 10412
Epoch: [2]  [ 420/4572]  eta: 0:04:09    time: 0.0584  data: 0.0519  max mem: 10412
Epoch: [2]  [ 440/4572]  eta: 0:04:07    time: 0.0598  data: 0.0533  max mem: 10412
Epoch: [2]  [ 460/4572]  eta: 0:04:06    time: 0.0582  data: 0.0516  max mem: 10412
Epoch: [2]  [ 480/4572]  eta: 0:04:04    time: 0.0581  data: 0.0516  max mem: 10412
Epoch: [2]  [ 500/4572]  eta: 0:04:09    time: 0.0941  data: 0.0876  max mem: 10412
Epoch: [2]  [ 520/4572]  eta: 0:04:07    time: 0.0595  data: 0.0531  max mem: 10412
Epoch: [2]  [ 540/4572]  eta: 0:04:06    time: 0.0582  data: 0.0516  max mem: 10412
Epoch: [2]  [ 560/4572]  eta: 0:04:04    time: 0.0581  data: 0.0516  max mem: 10412
Epoch: [2]  [ 580/4572]  eta: 0:04:02    time: 0.0583  data: 0.0518  max mem: 10412
Epoch: [2]  [ 600/4572]  eta: 0:04:05    time: 0.0932  data: 0.0867  max mem: 10412
Epoch: [2]  [ 620/4572]  eta: 0:04:04    time: 0.0583  data: 0.0519  max mem: 10412
Epoch: [2]  [ 640/4572]  eta: 0:04:02    time: 0.0582  data: 0.0517  max mem: 10412
Epoch: [2]  [ 660/4572]  eta: 0:04:00    time: 0.0583  data: 0.0518  max mem: 10412
Epoch: [2]  [ 680/4572]  eta: 0:03:59    time: 0.0582  data: 0.0518  max mem: 10412
Epoch: [2]  [ 700/4572]  eta: 0:03:57    time: 0.0582  data: 0.0517  max mem: 10412
Epoch: [2]  [ 720/4572]  eta: 0:03:56    time: 0.0582  data: 0.0517  max mem: 10412
Epoch: [2]  [ 740/4572]  eta: 0:03:54    time: 0.0583  data: 0.0519  max mem: 10412
Epoch: [2]  [ 760/4572]  eta: 0:03:53    time: 0.0583  data: 0.0518  max mem: 10412
Epoch: [2]  [ 780/4572]  eta: 0:03:54    time: 0.0881  data: 0.0817  max mem: 10412
Epoch: [2]  [ 800/4572]  eta: 0:03:52    time: 0.0582  data: 0.0517  max mem: 10412
Epoch: [2]  [ 820/4572]  eta: 0:03:51    time: 0.0600  data: 0.0535  max mem: 10412
Epoch: [2]  [ 840/4572]  eta: 0:03:50    time: 0.0583  data: 0.0519  max mem: 10412
Epoch: [2]  [ 860/4572]  eta: 0:03:48    time: 0.0582  data: 0.0517  max mem: 10412
Epoch: [2]  [ 880/4572]  eta: 0:03:46    time: 0.0582  data: 0.0517  max mem: 10412
Epoch: [2]  [ 900/4572]  eta: 0:03:45    time: 0.0581  data: 0.0516  max mem: 10412
Epoch: [2]  [ 920/4572]  eta: 0:03:43    time: 0.0582  data: 0.0518  max mem: 10412
Epoch: [2]  [ 940/4572]  eta: 0:03:42    time: 0.0583  data: 0.0518  max mem: 10412
Epoch: [2]  [ 960/4572]  eta: 0:03:41    time: 0.0582  data: 0.0518  max mem: 10412
Epoch: [2]  [ 980/4572]  eta: 0:03:39    time: 0.0581  data: 0.0516  max mem: 10412
Epoch: [2]  [1000/4572]  eta: 0:03:38    time: 0.0582  data: 0.0517  max mem: 10412
Epoch: [2]  [1020/4572]  eta: 0:03:36    time: 0.0582  data: 0.0518  max mem: 10412
Epoch: [2]  [1040/4572]  eta: 0:03:35    time: 0.0583  data: 0.0517  max mem: 10412
Epoch: [2]  [1060/4572]  eta: 0:03:33    time: 0.0587  data: 0.0523  max mem: 10412
Epoch: [2]  [1080/4572]  eta: 0:03:32    time: 0.0584  data: 0.0518  max mem: 10412
Epoch: [2]  [1100/4572]  eta: 0:03:31    time: 0.0582  data: 0.0517  max mem: 10412
Epoch: [2]  [1120/4572]  eta: 0:03:30    time: 0.0645  data: 0.0579  max mem: 10412
Epoch: [2]  [1140/4572]  eta: 0:03:28    time: 0.0582  data: 0.0518  max mem: 10412
Epoch: [2]  [1160/4572]  eta: 0:03:27    time: 0.0582  data: 0.0517  max mem: 10412
Epoch: [2]  [1180/4572]  eta: 0:03:26    time: 0.0581  data: 0.0516  max mem: 10412
Epoch: [2]  [1200/4572]  eta: 0:03:24    time: 0.0582  data: 0.0518  max mem: 10412
Epoch: [2]  [1220/4572]  eta: 0:03:23    time: 0.0582  data: 0.0517  max mem: 10412
Epoch: [2]  [1240/4572]  eta: 0:03:23    time: 0.0903  data: 0.0517  max mem: 10412
Epoch: [2]  [1260/4572]  eta: 0:03:22    time: 0.0582  data: 0.0516  max mem: 10412
Epoch: [2]  [1280/4572]  eta: 0:03:21    time: 0.0582  data: 0.0518  max mem: 10412
Epoch: [2]  [1300/4572]  eta: 0:03:19    time: 0.0583  data: 0.0518  max mem: 10412
Epoch: [2]  [1320/4572]  eta: 0:03:18    time: 0.0582  data: 0.0517  max mem: 10412
Epoch: [2]  [1340/4572]  eta: 0:03:16    time: 0.0582  data: 0.0517  max mem: 10412
Epoch: [2]  [1360/4572]  eta: 0:03:15    time: 0.0582  data: 0.0518  max mem: 10412
Epoch: [2]  [1380/4572]  eta: 0:03:14    time: 0.0583  data: 0.0518  max mem: 10412
Epoch: [2]  [1400/4572]  eta: 0:03:12    time: 0.0581  data: 0.0517  max mem: 10412
Epoch: [2]  [1420/4572]  eta: 0:03:11    time: 0.0597  data: 0.0533  max mem: 10412
Epoch: [2]  [1440/4572]  eta: 0:03:10    time: 0.0583  data: 0.0518  max mem: 10412
Epoch: [2]  [1460/4572]  eta: 0:03:09    time: 0.0604  data: 0.0539  max mem: 10412
Epoch: [2]  [1480/4572]  eta: 0:03:07    time: 0.0582  data: 0.0517  max mem: 10412
Epoch: [2]  [1500/4572]  eta: 0:03:06    time: 0.0583  data: 0.0518  max mem: 10412
Epoch: [2]  [1520/4572]  eta: 0:03:05    time: 0.0583  data: 0.0519  max mem: 10412
Epoch: [2]  [1540/4572]  eta: 0:03:03    time: 0.0583  data: 0.0519  max mem: 10412
Epoch: [2]  [1560/4572]  eta: 0:03:02    time: 0.0584  data: 0.0518  max mem: 10412
Epoch: [2]  [1580/4572]  eta: 0:03:01    time: 0.0582  data: 0.0517  max mem: 10412
Epoch: [2]  [1600/4572]  eta: 0:02:59    time: 0.0584  data: 0.0519  max mem: 10412
Epoch: [2]  [1620/4572]  eta: 0:02:58    time: 0.0583  data: 0.0518  max mem: 10412
Epoch: [2]  [1640/4572]  eta: 0:02:57    time: 0.0582  data: 0.0517  max mem: 10412
Epoch: [2]  [1660/4572]  eta: 0:02:56    time: 0.0582  data: 0.0517  max mem: 10412
Epoch: [2]  [1680/4572]  eta: 0:02:54    time: 0.0583  data: 0.0518  max mem: 10412
Epoch: [2]  [1700/4572]  eta: 0:02:53    time: 0.0582  data: 0.0517  max mem: 10412
Epoch: [2]  [1720/4572]  eta: 0:02:52    time: 0.0606  data: 0.0541  max mem: 10412
Epoch: [2]  [1740/4572]  eta: 0:02:51    time: 0.0594  data: 0.0529  max mem: 10412
Epoch: [2]  [1760/4572]  eta: 0:02:49    time: 0.0583  data: 0.0518  max mem: 10412
Epoch: [2]  [1780/4572]  eta: 0:02:48    time: 0.0583  data: 0.0518  max mem: 10412
Epoch: [2]  [1800/4572]  eta: 0:02:47    time: 0.0606  data: 0.0542  max mem: 10412
Epoch: [2]  [1820/4572]  eta: 0:02:46    time: 0.0583  data: 0.0518  max mem: 10412
Epoch: [2]  [1840/4572]  eta: 0:02:44    time: 0.0583  data: 0.0518  max mem: 10412
Epoch: [2]  [1860/4572]  eta: 0:02:43    time: 0.0583  data: 0.0518  max mem: 10412
Epoch: [2]  [1880/4572]  eta: 0:02:42    time: 0.0584  data: 0.0518  max mem: 10412
Epoch: [2]  [1900/4572]  eta: 0:02:40    time: 0.0583  data: 0.0518  max mem: 10412
Epoch: [2]  [1920/4572]  eta: 0:02:39    time: 0.0582  data: 0.0517  max mem: 10412
Epoch: [2]  [1940/4572]  eta: 0:02:38    time: 0.0583  data: 0.0518  max mem: 10412
Epoch: [2]  [1960/4572]  eta: 0:02:37    time: 0.0583  data: 0.0518  max mem: 10412
Epoch: [2]  [1980/4572]  eta: 0:02:36    time: 0.0620  data: 0.0531  max mem: 10412
Epoch: [2]  [2000/4572]  eta: 0:02:34    time: 0.0604  data: 0.0540  max mem: 10412
Epoch: [2]  [2020/4572]  eta: 0:02:33    time: 0.0585  data: 0.0520  max mem: 10412
Epoch: [2]  [2040/4572]  eta: 0:02:32    time: 0.0582  data: 0.0517  max mem: 10412
Epoch: [2]  [2060/4572]  eta: 0:02:31    time: 0.0584  data: 0.0519  max mem: 10412
Epoch: [2]  [2080/4572]  eta: 0:02:29    time: 0.0583  data: 0.0518  max mem: 10412
Epoch: [2]  [2100/4572]  eta: 0:02:28    time: 0.0582  data: 0.0517  max mem: 10412
Epoch: [2]  [2120/4572]  eta: 0:02:27    time: 0.0583  data: 0.0518  max mem: 10412
Epoch: [2]  [2140/4572]  eta: 0:02:26    time: 0.0584  data: 0.0518  max mem: 10412
Epoch: [2]  [2160/4572]  eta: 0:02:24    time: 0.0582  data: 0.0517  max mem: 10412
Epoch: [2]  [2180/4572]  eta: 0:02:23    time: 0.0583  data: 0.0519  max mem: 10412
Corrupt JPEG data: premature end of data segment
Epoch: [2]  [2200/4572]  eta: 0:02:22    time: 0.0588  data: 0.0522  max mem: 10412
Epoch: [2]  [2220/4572]  eta: 0:02:21    time: 0.0582  data: 0.0517  max mem: 10412
Epoch: [2]  [2240/4572]  eta: 0:02:19    time: 0.0584  data: 0.0519  max mem: 10412
Epoch: [2]  [2260/4572]  eta: 0:02:19    time: 0.0945  data: 0.0880  max mem: 10412
Epoch: [2]  [2280/4572]  eta: 0:02:18    time: 0.0581  data: 0.0517  max mem: 10412
Epoch: [2]  [2300/4572]  eta: 0:02:16    time: 0.0582  data: 0.0517  max mem: 10412
Epoch: [2]  [2320/4572]  eta: 0:02:15    time: 0.0582  data: 0.0517  max mem: 10412
Epoch: [2]  [2340/4572]  eta: 0:02:14    time: 0.0581  data: 0.0517  max mem: 10412
Epoch: [2]  [2360/4572]  eta: 0:02:13    time: 0.0582  data: 0.0518  max mem: 10412
Epoch: [2]  [2380/4572]  eta: 0:02:11    time: 0.0582  data: 0.0517  max mem: 10412
Epoch: [2]  [2400/4572]  eta: 0:02:10    time: 0.0607  data: 0.0517  max mem: 10412
Epoch: [2]  [2420/4572]  eta: 0:02:09    time: 0.0582  data: 0.0517  max mem: 10412
Epoch: [2]  [2440/4572]  eta: 0:02:08    time: 0.0582  data: 0.0517  max mem: 10412
Epoch: [2]  [2460/4572]  eta: 0:02:07    time: 0.0582  data: 0.0517  max mem: 10412
Epoch: [2]  [2480/4572]  eta: 0:02:05    time: 0.0583  data: 0.0518  max mem: 10412
Epoch: [2]  [2500/4572]  eta: 0:02:04    time: 0.0582  data: 0.0517  max mem: 10412
Epoch: [2]  [2520/4572]  eta: 0:02:03    time: 0.0582  data: 0.0517  max mem: 10412
Epoch: [2]  [2540/4572]  eta: 0:02:02    time: 0.0582  data: 0.0517  max mem: 10412
Epoch: [2]  [2560/4572]  eta: 0:02:00    time: 0.0621  data: 0.0556  max mem: 10412
Epoch: [2]  [2580/4572]  eta: 0:01:59    time: 0.0583  data: 0.0519  max mem: 10412
Epoch: [2]  [2600/4572]  eta: 0:01:58    time: 0.0582  data: 0.0517  max mem: 10412
Epoch: [2]  [2620/4572]  eta: 0:01:57    time: 0.0602  data: 0.0537  max mem: 10412
Epoch: [2]  [2640/4572]  eta: 0:01:56    time: 0.0581  data: 0.0516  max mem: 10412
Epoch: [2]  [2660/4572]  eta: 0:01:54    time: 0.0582  data: 0.0518  max mem: 10412
Epoch: [2]  [2680/4572]  eta: 0:01:53    time: 0.0647  data: 0.0583  max mem: 10412
Epoch: [2]  [2700/4572]  eta: 0:01:52    time: 0.0581  data: 0.0517  max mem: 10412
Epoch: [2]  [2720/4572]  eta: 0:01:51    time: 0.0583  data: 0.0518  max mem: 10412
Epoch: [2]  [2740/4572]  eta: 0:01:50    time: 0.0582  data: 0.0516  max mem: 10412
Epoch: [2]  [2760/4572]  eta: 0:01:48    time: 0.0582  data: 0.0517  max mem: 10412
Epoch: [2]  [2780/4572]  eta: 0:01:47    time: 0.0587  data: 0.0518  max mem: 10412
Epoch: [2]  [2800/4572]  eta: 0:01:46    time: 0.0582  data: 0.0517  max mem: 10412
Epoch: [2]  [2820/4572]  eta: 0:01:45    time: 0.0581  data: 0.0517  max mem: 10412
Epoch: [2]  [2840/4572]  eta: 0:01:43    time: 0.0583  data: 0.0518  max mem: 10412
Epoch: [2]  [2860/4572]  eta: 0:01:42    time: 0.0583  data: 0.0517  max mem: 10412
Epoch: [2]  [2880/4572]  eta: 0:01:41    time: 0.0582  data: 0.0517  max mem: 10412
Epoch: [2]  [2900/4572]  eta: 0:01:40    time: 0.0593  data: 0.0529  max mem: 10412
Epoch: [2]  [2920/4572]  eta: 0:01:39    time: 0.0584  data: 0.0519  max mem: 10412
Epoch: [2]  [2940/4572]  eta: 0:01:37    time: 0.0582  data: 0.0517  max mem: 10412
Epoch: [2]  [2960/4572]  eta: 0:01:36    time: 0.0582  data: 0.0517  max mem: 10412
Epoch: [2]  [2980/4572]  eta: 0:01:35    time: 0.0582  data: 0.0518  max mem: 10412
Epoch: [2]  [3000/4572]  eta: 0:01:34    time: 0.0595  data: 0.0530  max mem: 10412
Epoch: [2]  [3020/4572]  eta: 0:01:32    time: 0.0587  data: 0.0523  max mem: 10412
Epoch: [2]  [3040/4572]  eta: 0:01:31    time: 0.0589  data: 0.0517  max mem: 10412
Epoch: [2]  [3060/4572]  eta: 0:01:30    time: 0.0581  data: 0.0517  max mem: 10412
Epoch: [2]  [3080/4572]  eta: 0:01:29    time: 0.0581  data: 0.0517  max mem: 10412
Epoch: [2]  [3100/4572]  eta: 0:01:28    time: 0.0633  data: 0.0568  max mem: 10412
Epoch: [2]  [3120/4572]  eta: 0:01:26    time: 0.0591  data: 0.0527  max mem: 10412
Epoch: [2]  [3140/4572]  eta: 0:01:25    time: 0.0584  data: 0.0519  max mem: 10412
Epoch: [2]  [3160/4572]  eta: 0:01:24    time: 0.0583  data: 0.0518  max mem: 10412
Epoch: [2]  [3180/4572]  eta: 0:01:23    time: 0.0588  data: 0.0523  max mem: 10412
Epoch: [2]  [3200/4572]  eta: 0:01:22    time: 0.0582  data: 0.0517  max mem: 10412
Epoch: [2]  [3220/4572]  eta: 0:01:20    time: 0.0581  data: 0.0517  max mem: 10412
Epoch: [2]  [3240/4572]  eta: 0:01:19    time: 0.0583  data: 0.0519  max mem: 10412
Epoch: [2]  [3260/4572]  eta: 0:01:18    time: 0.0582  data: 0.0517  max mem: 10412
Epoch: [2]  [3280/4572]  eta: 0:01:17    time: 0.0582  data: 0.0516  max mem: 10412
Epoch: [2]  [3300/4572]  eta: 0:01:16    time: 0.0581  data: 0.0516  max mem: 10412
Epoch: [2]  [3320/4572]  eta: 0:01:14    time: 0.0583  data: 0.0518  max mem: 10412
Epoch: [2]  [3340/4572]  eta: 0:01:13    time: 0.0584  data: 0.0519  max mem: 10412
Epoch: [2]  [3360/4572]  eta: 0:01:12    time: 0.0581  data: 0.0516  max mem: 10412
Epoch: [2]  [3380/4572]  eta: 0:01:11    time: 0.0582  data: 0.0518  max mem: 10412
Epoch: [2]  [3400/4572]  eta: 0:01:10    time: 0.0582  data: 0.0518  max mem: 10412
Epoch: [2]  [3420/4572]  eta: 0:01:08    time: 0.0582  data: 0.0517  max mem: 10412
Epoch: [2]  [3440/4572]  eta: 0:01:07    time: 0.0583  data: 0.0517  max mem: 10412
Epoch: [2]  [3460/4572]  eta: 0:01:06    time: 0.0581  data: 0.0517  max mem: 10412
Epoch: [2]  [3480/4572]  eta: 0:01:05    time: 0.0583  data: 0.0518  max mem: 10412
Epoch: [2]  [3500/4572]  eta: 0:01:04    time: 0.0586  data: 0.0521  max mem: 10412
Epoch: [2]  [3520/4572]  eta: 0:01:02    time: 0.0581  data: 0.0517  max mem: 10412
Epoch: [2]  [3540/4572]  eta: 0:01:01    time: 0.0582  data: 0.0518  max mem: 10412
Epoch: [2]  [3560/4572]  eta: 0:01:00    time: 0.0582  data: 0.0517  max mem: 10412
Epoch: [2]  [3580/4572]  eta: 0:00:59    time: 0.0582  data: 0.0517  max mem: 10412
Epoch: [2]  [3600/4572]  eta: 0:00:58    time: 0.0582  data: 0.0517  max mem: 10412
Epoch: [2]  [3620/4572]  eta: 0:00:56    time: 0.0582  data: 0.0517  max mem: 10412
Epoch: [2]  [3640/4572]  eta: 0:00:55    time: 0.0581  data: 0.0516  max mem: 10412
Epoch: [2]  [3660/4572]  eta: 0:00:54    time: 0.0594  data: 0.0529  max mem: 10412
Epoch: [2]  [3680/4572]  eta: 0:00:53    time: 0.0582  data: 0.0518  max mem: 10412
Epoch: [2]  [3700/4572]  eta: 0:00:52    time: 0.0582  data: 0.0517  max mem: 10412
Epoch: [2]  [3720/4572]  eta: 0:00:50    time: 0.0583  data: 0.0518  max mem: 10412
Epoch: [2]  [3740/4572]  eta: 0:00:49    time: 0.0582  data: 0.0517  max mem: 10412
Epoch: [2]  [3760/4572]  eta: 0:00:48    time: 0.0582  data: 0.0517  max mem: 10412
Epoch: [2]  [3780/4572]  eta: 0:00:47    time: 0.0582  data: 0.0517  max mem: 10412
Epoch: [2]  [3800/4572]  eta: 0:00:46    time: 0.0582  data: 0.0517  max mem: 10412
Epoch: [2]  [3820/4572]  eta: 0:00:44    time: 0.0582  data: 0.0517  max mem: 10412
Epoch: [2]  [3840/4572]  eta: 0:00:43    time: 0.0582  data: 0.0517  max mem: 10412
Epoch: [2]  [3860/4572]  eta: 0:00:42    time: 0.0581  data: 0.0517  max mem: 10412
Epoch: [2]  [3880/4572]  eta: 0:00:41    time: 0.0581  data: 0.0517  max mem: 10412
Epoch: [2]  [3900/4572]  eta: 0:00:40    time: 0.0583  data: 0.0519  max mem: 10412
Epoch: [2]  [3920/4572]  eta: 0:00:38    time: 0.0581  data: 0.0516  max mem: 10412
Epoch: [2]  [3940/4572]  eta: 0:00:37    time: 0.0581  data: 0.0517  max mem: 10412
Epoch: [2]  [3960/4572]  eta: 0:00:36    time: 0.0583  data: 0.0518  max mem: 10412
Epoch: [2]  [3980/4572]  eta: 0:00:35    time: 0.0583  data: 0.0518  max mem: 10412
Epoch: [2]  [4000/4572]  eta: 0:00:34    time: 0.0582  data: 0.0517  max mem: 10412
Epoch: [2]  [4020/4572]  eta: 0:00:32    time: 0.0587  data: 0.0515  max mem: 10412
Epoch: [2]  [4040/4572]  eta: 0:00:31    time: 0.0596  data: 0.0531  max mem: 10412
Epoch: [2]  [4060/4572]  eta: 0:00:30    time: 0.0583  data: 0.0518  max mem: 10412
Epoch: [2]  [4080/4572]  eta: 0:00:29    time: 0.0586  data: 0.0521  max mem: 10412
Epoch: [2]  [4100/4572]  eta: 0:00:28    time: 0.0582  data: 0.0517  max mem: 10412
Epoch: [2]  [4120/4572]  eta: 0:00:26    time: 0.0888  data: 0.0824  max mem: 10412
Epoch: [2]  [4140/4572]  eta: 0:00:25    time: 0.0581  data: 0.0515  max mem: 10412
Epoch: [2]  [4160/4572]  eta: 0:00:24    time: 0.0581  data: 0.0516  max mem: 10412
Epoch: [2]  [4180/4572]  eta: 0:00:23    time: 0.0581  data: 0.0516  max mem: 10412
Epoch: [2]  [4200/4572]  eta: 0:00:22    time: 0.0582  data: 0.0517  max mem: 10412
Epoch: [2]  [4220/4572]  eta: 0:00:20    time: 0.0581  data: 0.0517  max mem: 10412
Epoch: [2]  [4240/4572]  eta: 0:00:19    time: 0.0582  data: 0.0517  max mem: 10412
Epoch: [2]  [4260/4572]  eta: 0:00:18    time: 0.0582  data: 0.0517  max mem: 10412
Epoch: [2]  [4280/4572]  eta: 0:00:17    time: 0.0582  data: 0.0517  max mem: 10412
Epoch: [2]  [4300/4572]  eta: 0:00:16    time: 0.0581  data: 0.0516  max mem: 10412
Epoch: [2]  [4320/4572]  eta: 0:00:15    time: 0.0581  data: 0.0517  max mem: 10412
Epoch: [2]  [4340/4572]  eta: 0:00:13    time: 0.0581  data: 0.0516  max mem: 10412
Epoch: [2]  [4360/4572]  eta: 0:00:12    time: 0.0582  data: 0.0517  max mem: 10412
Epoch: [2]  [4380/4572]  eta: 0:00:11    time: 0.0581  data: 0.0516  max mem: 10412
Epoch: [2]  [4400/4572]  eta: 0:00:10    time: 0.0582  data: 0.0517  max mem: 10412
Epoch: [2]  [4420/4572]  eta: 0:00:09    time: 0.0582  data: 0.0518  max mem: 10412
Epoch: [2]  [4440/4572]  eta: 0:00:07    time: 0.0582  data: 0.0518  max mem: 10412
Epoch: [2]  [4460/4572]  eta: 0:00:06    time: 0.0582  data: 0.0517  max mem: 10412
Epoch: [2]  [4480/4572]  eta: 0:00:05    time: 0.0581  data: 0.0516  max mem: 10412
Epoch: [2]  [4500/4572]  eta: 0:00:04    time: 0.0582  data: 0.0517  max mem: 10412
Epoch: [2]  [4520/4572]  eta: 0:00:03    time: 0.0584  data: 0.0519  max mem: 10412
Epoch: [2]  [4540/4572]  eta: 0:00:01    time: 0.0581  data: 0.0516  max mem: 10412
Epoch: [2]  [4560/4572]  eta: 0:00:00    time: 0.0630  data: 0.0565  max mem: 10412
Epoch: [2]  [4571/4572]  eta: 0:00:00    time: 0.0581  data: 0.0516  max mem: 10412
Epoch: [2] Total time: 0:04:32 (0.0595 s / it)
:::MLLOG {"namespace": "", "time_ms": 1696364768860, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": 2, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 330, "epoch_num": 2}}
:::MLLOG {"namespace": "", "time_ms": 1696364768860, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 268.7753185102976}, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 334, "step": 3}}
:::MLLOG {"namespace": "", "time_ms": 1696364768860, "event_type": "INTERVAL_START", "key": "eval_start", "value": 3, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 344, "epoch_num": 3}}
Test:  [ 0/97]  eta: 0:00:12  model_time: 0.1286 (0.1286)  evaluator_time: 0.0019 (0.0019)  time: 0.1313  data: 0.0006  max mem: 10412
Test:  [20/97]  eta: 0:00:10  model_time: 0.1294 (0.1303)  evaluator_time: 0.0018 (0.0019)  time: 0.1329  data: 0.0006  max mem: 10412
Test:  [40/97]  eta: 0:00:07  model_time: 0.1322 (0.1303)  evaluator_time: 0.0018 (0.0019)  time: 0.1330  data: 0.0006  max mem: 10412
Test:  [60/97]  eta: 0:00:04  model_time: 0.1324 (0.1301)  evaluator_time: 0.0018 (0.0018)  time: 0.1323  data: 0.0006  max mem: 10412
Test:  [80/97]  eta: 0:00:02  model_time: 0.1323 (0.1301)  evaluator_time: 0.0019 (0.0026)  time: 0.1356  data: 0.0006  max mem: 10412
Test:  [96/97]  eta: 0:00:00  model_time: 0.1286 (0.1298)  evaluator_time: 0.0017 (0.0024)  time: 0.1308  data: 0.0006  max mem: 10412
Test: Total time: 0:00:12 (0.1330 s / it)
Averaged stats: model_time: 0.1286 (0.1319)  evaluator_time: 0.0017 (0.0025)
:::MLLOG {"namespace": "", "time_ms": 1696364782630, "event_type": "INTERVAL_START", "key": "epoch_start", "value": 3, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 158, "epoch_num": 3}}
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
Epoch: [3]  [   0/4571]  eta: 0:04:26    time: 0.0583  data: 0.0009  max mem: 10412
Epoch: [3]  [  20/4571]  eta: 0:04:22    time: 0.0578  data: 0.0513  max mem: 10412
Epoch: [3]  [  40/4571]  eta: 0:04:23    time: 0.0586  data: 0.0521  max mem: 10412
Epoch: [3]  [  60/4571]  eta: 0:04:22    time: 0.0581  data: 0.0515  max mem: 10412
Epoch: [3]  [  80/4571]  eta: 0:04:20    time: 0.0579  data: 0.0514  max mem: 10412
:::MLLOG {"namespace": "", "time_ms": 1696364787557, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.33191040820106893, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 437, "epoch_num": 3}}
:::MLLOG {"namespace": "", "time_ms": 1696364787557, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 3, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 438, "epoch_num": 3}}
Epoch: [3]  [ 100/4571]  eta: 0:04:21    time: 0.0600  data: 0.0535  max mem: 10412
Epoch: [3]  [ 120/4571]  eta: 0:04:19    time: 0.0581  data: 0.0515  max mem: 10412
Epoch: [3]  [ 140/4571]  eta: 0:04:18    time: 0.0580  data: 0.0514  max mem: 10412
Epoch: [3]  [ 160/4571]  eta: 0:04:17    time: 0.0580  data: 0.0515  max mem: 10412
Epoch: [3]  [ 180/4571]  eta: 0:04:17    time: 0.0612  data: 0.0548  max mem: 10412
Epoch: [3]  [ 200/4571]  eta: 0:04:15    time: 0.0581  data: 0.0516  max mem: 10412
Epoch: [3]  [ 220/4571]  eta: 0:04:14    time: 0.0581  data: 0.0516  max mem: 10412
Epoch: [3]  [ 240/4571]  eta: 0:04:13    time: 0.0580  data: 0.0516  max mem: 10412
Epoch: [3]  [ 260/4571]  eta: 0:04:11    time: 0.0580  data: 0.0515  max mem: 10412
Epoch: [3]  [ 280/4571]  eta: 0:04:10    time: 0.0581  data: 0.0516  max mem: 10412
Epoch: [3]  [ 300/4571]  eta: 0:04:09    time: 0.0580  data: 0.0515  max mem: 10412
Epoch: [3]  [ 320/4571]  eta: 0:04:08    time: 0.0581  data: 0.0516  max mem: 10412
Epoch: [3]  [ 340/4571]  eta: 0:04:06    time: 0.0580  data: 0.0515  max mem: 10412
Epoch: [3]  [ 360/4571]  eta: 0:04:05    time: 0.0581  data: 0.0516  max mem: 10412
Epoch: [3]  [ 380/4571]  eta: 0:04:04    time: 0.0580  data: 0.0515  max mem: 10412
Epoch: [3]  [ 400/4571]  eta: 0:04:03    time: 0.0580  data: 0.0515  max mem: 10412
Epoch: [3]  [ 420/4571]  eta: 0:04:01    time: 0.0581  data: 0.0516  max mem: 10412
Epoch: [3]  [ 440/4571]  eta: 0:04:00    time: 0.0581  data: 0.0516  max mem: 10412
Epoch: [3]  [ 460/4571]  eta: 0:03:59    time: 0.0581  data: 0.0517  max mem: 10412
Epoch: [3]  [ 480/4571]  eta: 0:03:59    time: 0.0626  data: 0.0561  max mem: 10412
Epoch: [3]  [ 500/4571]  eta: 0:03:58    time: 0.0620  data: 0.0554  max mem: 10412
Epoch: [3]  [ 520/4571]  eta: 0:03:57    time: 0.0580  data: 0.0516  max mem: 10412
Epoch: [3]  [ 540/4571]  eta: 0:03:56    time: 0.0580  data: 0.0515  max mem: 10412
Epoch: [3]  [ 560/4571]  eta: 0:03:54    time: 0.0581  data: 0.0515  max mem: 10412
Epoch: [3]  [ 580/4571]  eta: 0:03:53    time: 0.0590  data: 0.0524  max mem: 10412
Epoch: [3]  [ 600/4571]  eta: 0:03:52    time: 0.0581  data: 0.0516  max mem: 10412
Epoch: [3]  [ 620/4571]  eta: 0:03:51    time: 0.0581  data: 0.0517  max mem: 10412
Epoch: [3]  [ 640/4571]  eta: 0:03:49    time: 0.0580  data: 0.0515  max mem: 10412
Epoch: [3]  [ 660/4571]  eta: 0:03:48    time: 0.0581  data: 0.0516  max mem: 10412
Epoch: [3]  [ 680/4571]  eta: 0:03:47    time: 0.0581  data: 0.0516  max mem: 10412
Epoch: [3]  [ 700/4571]  eta: 0:03:46    time: 0.0581  data: 0.0516  max mem: 10412
Epoch: [3]  [ 720/4571]  eta: 0:03:45    time: 0.0601  data: 0.0536  max mem: 10412
Epoch: [3]  [ 740/4571]  eta: 0:03:44    time: 0.0586  data: 0.0522  max mem: 10412
Epoch: [3]  [ 760/4571]  eta: 0:03:42    time: 0.0580  data: 0.0515  max mem: 10412
Epoch: [3]  [ 780/4571]  eta: 0:03:41    time: 0.0580  data: 0.0515  max mem: 10412
Epoch: [3]  [ 800/4571]  eta: 0:03:40    time: 0.0584  data: 0.0519  max mem: 10412
Epoch: [3]  [ 820/4571]  eta: 0:03:39    time: 0.0581  data: 0.0516  max mem: 10412
Epoch: [3]  [ 840/4571]  eta: 0:03:38    time: 0.0581  data: 0.0516  max mem: 10412
Epoch: [3]  [ 860/4571]  eta: 0:03:36    time: 0.0583  data: 0.0518  max mem: 10412
Epoch: [3]  [ 880/4571]  eta: 0:03:35    time: 0.0581  data: 0.0516  max mem: 10412
Epoch: [3]  [ 900/4571]  eta: 0:03:34    time: 0.0581  data: 0.0516  max mem: 10412
Epoch: [3]  [ 920/4571]  eta: 0:03:33    time: 0.0581  data: 0.0517  max mem: 10412
Epoch: [3]  [ 940/4571]  eta: 0:03:32    time: 0.0581  data: 0.0516  max mem: 10412
Epoch: [3]  [ 960/4571]  eta: 0:03:30    time: 0.0581  data: 0.0515  max mem: 10412
Epoch: [3]  [ 980/4571]  eta: 0:03:29    time: 0.0581  data: 0.0516  max mem: 10412
Epoch: [3]  [1000/4571]  eta: 0:03:28    time: 0.0581  data: 0.0517  max mem: 10412
Epoch: [3]  [1020/4571]  eta: 0:03:27    time: 0.0580  data: 0.0516  max mem: 10412
Epoch: [3]  [1040/4571]  eta: 0:03:26    time: 0.0583  data: 0.0518  max mem: 10412
Epoch: [3]  [1060/4571]  eta: 0:03:25    time: 0.0582  data: 0.0517  max mem: 10412
Epoch: [3]  [1080/4571]  eta: 0:03:24    time: 0.0627  data: 0.0563  max mem: 10412
Epoch: [3]  [1100/4571]  eta: 0:03:22    time: 0.0581  data: 0.0516  max mem: 10412
Epoch: [3]  [1120/4571]  eta: 0:03:21    time: 0.0582  data: 0.0516  max mem: 10412
Epoch: [3]  [1140/4571]  eta: 0:03:20    time: 0.0581  data: 0.0517  max mem: 10412
Epoch: [3]  [1160/4571]  eta: 0:03:19    time: 0.0581  data: 0.0517  max mem: 10412
Epoch: [3]  [1180/4571]  eta: 0:03:18    time: 0.0582  data: 0.0516  max mem: 10412
Epoch: [3]  [1200/4571]  eta: 0:03:17    time: 0.0581  data: 0.0516  max mem: 10412
Epoch: [3]  [1220/4571]  eta: 0:03:15    time: 0.0582  data: 0.0517  max mem: 10412
Epoch: [3]  [1240/4571]  eta: 0:03:14    time: 0.0589  data: 0.0524  max mem: 10412
Epoch: [3]  [1260/4571]  eta: 0:03:13    time: 0.0582  data: 0.0517  max mem: 10412
Epoch: [3]  [1280/4571]  eta: 0:03:12    time: 0.0588  data: 0.0523  max mem: 10412
Epoch: [3]  [1300/4571]  eta: 0:03:11    time: 0.0582  data: 0.0517  max mem: 10412
Epoch: [3]  [1320/4571]  eta: 0:03:10    time: 0.0582  data: 0.0517  max mem: 10412
Epoch: [3]  [1340/4571]  eta: 0:03:08    time: 0.0581  data: 0.0516  max mem: 10412
Epoch: [3]  [1360/4571]  eta: 0:03:07    time: 0.0582  data: 0.0517  max mem: 10412
Epoch: [3]  [1380/4571]  eta: 0:03:06    time: 0.0582  data: 0.0517  max mem: 10412
Epoch: [3]  [1400/4571]  eta: 0:03:05    time: 0.0581  data: 0.0516  max mem: 10412
Epoch: [3]  [1420/4571]  eta: 0:03:04    time: 0.0581  data: 0.0517  max mem: 10412
Epoch: [3]  [1440/4571]  eta: 0:03:02    time: 0.0583  data: 0.0518  max mem: 10412
Epoch: [3]  [1460/4571]  eta: 0:03:01    time: 0.0582  data: 0.0532  max mem: 10412
Epoch: [3]  [1480/4571]  eta: 0:03:00    time: 0.0583  data: 0.0517  max mem: 10412
Epoch: [3]  [1500/4571]  eta: 0:02:59    time: 0.0582  data: 0.0517  max mem: 10412
Epoch: [3]  [1520/4571]  eta: 0:02:58    time: 0.0580  data: 0.0516  max mem: 10412
Epoch: [3]  [1540/4571]  eta: 0:02:57    time: 0.0581  data: 0.0517  max mem: 10412
Epoch: [3]  [1560/4571]  eta: 0:02:55    time: 0.0587  data: 0.0523  max mem: 10412
Epoch: [3]  [1580/4571]  eta: 0:02:54    time: 0.0580  data: 0.0515  max mem: 10412
Epoch: [3]  [1600/4571]  eta: 0:02:53    time: 0.0581  data: 0.0517  max mem: 10412
Epoch: [3]  [1620/4571]  eta: 0:02:52    time: 0.0582  data: 0.0518  max mem: 10412
Epoch: [3]  [1640/4571]  eta: 0:02:51    time: 0.0587  data: 0.0516  max mem: 10412
Epoch: [3]  [1660/4571]  eta: 0:02:50    time: 0.0586  data: 0.0521  max mem: 10412
Epoch: [3]  [1680/4571]  eta: 0:02:48    time: 0.0581  data: 0.0516  max mem: 10412
Epoch: [3]  [1700/4571]  eta: 0:02:47    time: 0.0580  data: 0.0515  max mem: 10412
Epoch: [3]  [1720/4571]  eta: 0:02:46    time: 0.0582  data: 0.0518  max mem: 10412
Epoch: [3]  [1740/4571]  eta: 0:02:45    time: 0.0583  data: 0.0518  max mem: 10412
Epoch: [3]  [1760/4571]  eta: 0:02:44    time: 0.0581  data: 0.0516  max mem: 10412
Epoch: [3]  [1780/4571]  eta: 0:02:42    time: 0.0582  data: 0.0517  max mem: 10412
Epoch: [3]  [1800/4571]  eta: 0:02:41    time: 0.0639  data: 0.0574  max mem: 10412
Epoch: [3]  [1820/4571]  eta: 0:02:40    time: 0.0582  data: 0.0517  max mem: 10412
Epoch: [3]  [1840/4571]  eta: 0:02:39    time: 0.0583  data: 0.0518  max mem: 10412
Epoch: [3]  [1860/4571]  eta: 0:02:38    time: 0.0581  data: 0.0516  max mem: 10412
Epoch: [3]  [1880/4571]  eta: 0:02:37    time: 0.0582  data: 0.0517  max mem: 10412
Epoch: [3]  [1900/4571]  eta: 0:02:36    time: 0.0581  data: 0.0516  max mem: 10412
Epoch: [3]  [1920/4571]  eta: 0:02:34    time: 0.0581  data: 0.0516  max mem: 10412
Epoch: [3]  [1940/4571]  eta: 0:02:33    time: 0.0581  data: 0.0516  max mem: 10412
Epoch: [3]  [1960/4571]  eta: 0:02:32    time: 0.0583  data: 0.0518  max mem: 10412
Epoch: [3]  [1980/4571]  eta: 0:02:31    time: 0.0583  data: 0.0517  max mem: 10412
Epoch: [3]  [2000/4571]  eta: 0:02:30    time: 0.0582  data: 0.0517  max mem: 10412
Epoch: [3]  [2020/4571]  eta: 0:02:29    time: 0.0582  data: 0.0517  max mem: 10412
Epoch: [3]  [2040/4571]  eta: 0:02:27    time: 0.0593  data: 0.0516  max mem: 10412
Epoch: [3]  [2060/4571]  eta: 0:02:26    time: 0.0582  data: 0.0517  max mem: 10412
Corrupt JPEG data: premature end of data segment
Epoch: [3]  [2080/4571]  eta: 0:02:25    time: 0.0595  data: 0.0531  max mem: 10412
Epoch: [3]  [2100/4571]  eta: 0:02:24    time: 0.0581  data: 0.0516  max mem: 10412
Epoch: [3]  [2120/4571]  eta: 0:02:23    time: 0.0644  data: 0.0579  max mem: 10412
Epoch: [3]  [2140/4571]  eta: 0:02:22    time: 0.0581  data: 0.0516  max mem: 10412
Epoch: [3]  [2160/4571]  eta: 0:02:21    time: 0.0581  data: 0.0516  max mem: 10412
Epoch: [3]  [2180/4571]  eta: 0:02:19    time: 0.0582  data: 0.0517  max mem: 10412
Epoch: [3]  [2200/4571]  eta: 0:02:18    time: 0.0583  data: 0.0519  max mem: 10412
Epoch: [3]  [2220/4571]  eta: 0:02:17    time: 0.0582  data: 0.0517  max mem: 10412
Epoch: [3]  [2240/4571]  eta: 0:02:16    time: 0.0623  data: 0.0558  max mem: 10412
Epoch: [3]  [2260/4571]  eta: 0:02:15    time: 0.0581  data: 0.0516  max mem: 10412
Epoch: [3]  [2280/4571]  eta: 0:02:14    time: 0.0581  data: 0.0517  max mem: 10412
Epoch: [3]  [2300/4571]  eta: 0:02:12    time: 0.0582  data: 0.0517  max mem: 10412
Epoch: [3]  [2320/4571]  eta: 0:02:12    time: 0.0942  data: 0.0877  max mem: 10412
Epoch: [3]  [2340/4571]  eta: 0:02:11    time: 0.0579  data: 0.0514  max mem: 10412
Epoch: [3]  [2360/4571]  eta: 0:02:09    time: 0.0581  data: 0.0516  max mem: 10412
Epoch: [3]  [2380/4571]  eta: 0:02:08    time: 0.0580  data: 0.0515  max mem: 10412
Epoch: [3]  [2400/4571]  eta: 0:02:07    time: 0.0580  data: 0.0515  max mem: 10412
Epoch: [3]  [2420/4571]  eta: 0:02:06    time: 0.0581  data: 0.0516  max mem: 10412
Epoch: [3]  [2440/4571]  eta: 0:02:05    time: 0.0580  data: 0.0516  max mem: 10412
Epoch: [3]  [2460/4571]  eta: 0:02:04    time: 0.0580  data: 0.0516  max mem: 10412
Epoch: [3]  [2480/4571]  eta: 0:02:02    time: 0.0580  data: 0.0516  max mem: 10412
Epoch: [3]  [2500/4571]  eta: 0:02:01    time: 0.0629  data: 0.0564  max mem: 10412
Epoch: [3]  [2520/4571]  eta: 0:02:00    time: 0.0581  data: 0.0517  max mem: 10412
Epoch: [3]  [2540/4571]  eta: 0:01:59    time: 0.0595  data: 0.0516  max mem: 10412
Epoch: [3]  [2560/4571]  eta: 0:01:58    time: 0.0581  data: 0.0516  max mem: 10412
Epoch: [3]  [2580/4571]  eta: 0:01:57    time: 0.0579  data: 0.0514  max mem: 10412
Epoch: [3]  [2600/4571]  eta: 0:01:55    time: 0.0581  data: 0.0516  max mem: 10412
Epoch: [3]  [2620/4571]  eta: 0:01:54    time: 0.0580  data: 0.0516  max mem: 10412
Epoch: [3]  [2640/4571]  eta: 0:01:53    time: 0.0580  data: 0.0515  max mem: 10412
Epoch: [3]  [2660/4571]  eta: 0:01:52    time: 0.0580  data: 0.0515  max mem: 10412
Epoch: [3]  [2680/4571]  eta: 0:01:51    time: 0.0581  data: 0.0517  max mem: 10412
Epoch: [3]  [2700/4571]  eta: 0:01:49    time: 0.0582  data: 0.0517  max mem: 10412
Epoch: [3]  [2720/4571]  eta: 0:01:48    time: 0.0580  data: 0.0516  max mem: 10412
Epoch: [3]  [2740/4571]  eta: 0:01:47    time: 0.0580  data: 0.0516  max mem: 10412
Epoch: [3]  [2760/4571]  eta: 0:01:46    time: 0.0580  data: 0.0515  max mem: 10412
Epoch: [3]  [2780/4571]  eta: 0:01:45    time: 0.0581  data: 0.0516  max mem: 10412
Epoch: [3]  [2800/4571]  eta: 0:01:44    time: 0.0600  data: 0.0525  max mem: 10412
Epoch: [3]  [2820/4571]  eta: 0:01:42    time: 0.0580  data: 0.0515  max mem: 10412
Epoch: [3]  [2840/4571]  eta: 0:01:41    time: 0.0580  data: 0.0515  max mem: 10412
Epoch: [3]  [2860/4571]  eta: 0:01:40    time: 0.0601  data: 0.0536  max mem: 10412
Epoch: [3]  [2880/4571]  eta: 0:01:39    time: 0.0580  data: 0.0515  max mem: 10412
Epoch: [3]  [2900/4571]  eta: 0:01:38    time: 0.0580  data: 0.0515  max mem: 10412
Epoch: [3]  [2920/4571]  eta: 0:01:36    time: 0.0581  data: 0.0516  max mem: 10412
Epoch: [3]  [2940/4571]  eta: 0:01:35    time: 0.0581  data: 0.0517  max mem: 10412
Epoch: [3]  [2960/4571]  eta: 0:01:34    time: 0.0581  data: 0.0516  max mem: 10412
Epoch: [3]  [2980/4571]  eta: 0:01:33    time: 0.0581  data: 0.0516  max mem: 10412
Epoch: [3]  [3000/4571]  eta: 0:01:32    time: 0.0600  data: 0.0535  max mem: 10412
Epoch: [3]  [3020/4571]  eta: 0:01:31    time: 0.0581  data: 0.0516  max mem: 10412
Epoch: [3]  [3040/4571]  eta: 0:01:29    time: 0.0605  data: 0.0540  max mem: 10412
Epoch: [3]  [3060/4571]  eta: 0:01:28    time: 0.0580  data: 0.0516  max mem: 10412
Epoch: [3]  [3080/4571]  eta: 0:01:27    time: 0.0581  data: 0.0516  max mem: 10412
Epoch: [3]  [3100/4571]  eta: 0:01:26    time: 0.0582  data: 0.0516  max mem: 10412
Epoch: [3]  [3120/4571]  eta: 0:01:25    time: 0.0582  data: 0.0517  max mem: 10412
Epoch: [3]  [3140/4571]  eta: 0:01:24    time: 0.0580  data: 0.0515  max mem: 10412
Epoch: [3]  [3160/4571]  eta: 0:01:22    time: 0.0580  data: 0.0515  max mem: 10412
Epoch: [3]  [3180/4571]  eta: 0:01:21    time: 0.0582  data: 0.0517  max mem: 10412
Epoch: [3]  [3200/4571]  eta: 0:01:20    time: 0.0581  data: 0.0517  max mem: 10412
Epoch: [3]  [3220/4571]  eta: 0:01:19    time: 0.0610  data: 0.0545  max mem: 10412
Epoch: [3]  [3240/4571]  eta: 0:01:18    time: 0.0582  data: 0.0516  max mem: 10412
Epoch: [3]  [3260/4571]  eta: 0:01:16    time: 0.0580  data: 0.0515  max mem: 10412
Epoch: [3]  [3280/4571]  eta: 0:01:15    time: 0.0581  data: 0.0516  max mem: 10412
Epoch: [3]  [3300/4571]  eta: 0:01:14    time: 0.0581  data: 0.0515  max mem: 10412
Epoch: [3]  [3320/4571]  eta: 0:01:13    time: 0.0580  data: 0.0515  max mem: 10412
Epoch: [3]  [3340/4571]  eta: 0:01:12    time: 0.0581  data: 0.0516  max mem: 10412
Epoch: [3]  [3360/4571]  eta: 0:01:11    time: 0.0595  data: 0.0530  max mem: 10412
Epoch: [3]  [3380/4571]  eta: 0:01:09    time: 0.0584  data: 0.0519  max mem: 10412
Epoch: [3]  [3400/4571]  eta: 0:01:08    time: 0.0580  data: 0.0516  max mem: 10412
Epoch: [3]  [3420/4571]  eta: 0:01:07    time: 0.0582  data: 0.0517  max mem: 10412
Epoch: [3]  [3440/4571]  eta: 0:01:06    time: 0.0588  data: 0.0523  max mem: 10412
Epoch: [3]  [3460/4571]  eta: 0:01:05    time: 0.0580  data: 0.0515  max mem: 10412
Epoch: [3]  [3480/4571]  eta: 0:01:04    time: 0.0580  data: 0.0515  max mem: 10412
Epoch: [3]  [3500/4571]  eta: 0:01:02    time: 0.0581  data: 0.0516  max mem: 10412
Epoch: [3]  [3520/4571]  eta: 0:01:01    time: 0.0581  data: 0.0517  max mem: 10412
Epoch: [3]  [3540/4571]  eta: 0:01:00    time: 0.0618  data: 0.0554  max mem: 10412
Epoch: [3]  [3560/4571]  eta: 0:00:59    time: 0.0581  data: 0.0517  max mem: 10412
Epoch: [3]  [3580/4571]  eta: 0:00:58    time: 0.0581  data: 0.0516  max mem: 10412
Epoch: [3]  [3600/4571]  eta: 0:00:56    time: 0.0581  data: 0.0516  max mem: 10412
Epoch: [3]  [3620/4571]  eta: 0:00:55    time: 0.0581  data: 0.0516  max mem: 10412
Epoch: [3]  [3640/4571]  eta: 0:00:54    time: 0.0581  data: 0.0516  max mem: 10412
Epoch: [3]  [3660/4571]  eta: 0:00:53    time: 0.0580  data: 0.0515  max mem: 10412
Epoch: [3]  [3680/4571]  eta: 0:00:52    time: 0.0580  data: 0.0515  max mem: 10412
Epoch: [3]  [3700/4571]  eta: 0:00:51    time: 0.0581  data: 0.0516  max mem: 10412
Epoch: [3]  [3720/4571]  eta: 0:00:49    time: 0.0580  data: 0.0514  max mem: 10412
Epoch: [3]  [3740/4571]  eta: 0:00:48    time: 0.0605  data: 0.0540  max mem: 10412
Epoch: [3]  [3760/4571]  eta: 0:00:47    time: 0.0581  data: 0.0516  max mem: 10412
Epoch: [3]  [3780/4571]  eta: 0:00:46    time: 0.0580  data: 0.0515  max mem: 10412
Epoch: [3]  [3800/4571]  eta: 0:00:45    time: 0.0580  data: 0.0515  max mem: 10412
Epoch: [3]  [3820/4571]  eta: 0:00:44    time: 0.0581  data: 0.0516  max mem: 10412
Epoch: [3]  [3840/4571]  eta: 0:00:42    time: 0.0611  data: 0.0546  max mem: 10412
Epoch: [3]  [3860/4571]  eta: 0:00:41    time: 0.0589  data: 0.0525  max mem: 10412
Epoch: [3]  [3880/4571]  eta: 0:00:40    time: 0.0586  data: 0.0521  max mem: 10412
Epoch: [3]  [3900/4571]  eta: 0:00:39    time: 0.0581  data: 0.0516  max mem: 10412
Epoch: [3]  [3920/4571]  eta: 0:00:38    time: 0.0581  data: 0.0515  max mem: 10412
Epoch: [3]  [3940/4571]  eta: 0:00:37    time: 0.0580  data: 0.0515  max mem: 10412
Epoch: [3]  [3960/4571]  eta: 0:00:35    time: 0.0580  data: 0.0515  max mem: 10412
Epoch: [3]  [3980/4571]  eta: 0:00:34    time: 0.0580  data: 0.0515  max mem: 10412
Epoch: [3]  [4000/4571]  eta: 0:00:33    time: 0.0581  data: 0.0516  max mem: 10412
Epoch: [3]  [4020/4571]  eta: 0:00:32    time: 0.0580  data: 0.0516  max mem: 10412
Epoch: [3]  [4040/4571]  eta: 0:00:31    time: 0.0580  data: 0.0515  max mem: 10412
Epoch: [3]  [4060/4571]  eta: 0:00:29    time: 0.0580  data: 0.0515  max mem: 10412
Epoch: [3]  [4080/4571]  eta: 0:00:28    time: 0.0613  data: 0.0548  max mem: 10412
Epoch: [3]  [4100/4571]  eta: 0:00:27    time: 0.0582  data: 0.0517  max mem: 10412
Epoch: [3]  [4120/4571]  eta: 0:00:26    time: 0.0582  data: 0.0516  max mem: 10412
Epoch: [3]  [4140/4571]  eta: 0:00:25    time: 0.0581  data: 0.0516  max mem: 10412
Epoch: [3]  [4160/4571]  eta: 0:00:24    time: 0.0580  data: 0.0515  max mem: 10412
Epoch: [3]  [4180/4571]  eta: 0:00:22    time: 0.0585  data: 0.0521  max mem: 10412
Epoch: [3]  [4200/4571]  eta: 0:00:21    time: 0.0580  data: 0.0515  max mem: 10412
Epoch: [3]  [4220/4571]  eta: 0:00:20    time: 0.0582  data: 0.0516  max mem: 10412
Epoch: [3]  [4240/4571]  eta: 0:00:19    time: 0.0580  data: 0.0515  max mem: 10412
Epoch: [3]  [4260/4571]  eta: 0:00:18    time: 0.0584  data: 0.0519  max mem: 10412
Epoch: [3]  [4280/4571]  eta: 0:00:17    time: 0.0580  data: 0.0516  max mem: 10412
Epoch: [3]  [4300/4571]  eta: 0:00:15    time: 0.0581  data: 0.0517  max mem: 10412
Epoch: [3]  [4320/4571]  eta: 0:00:14    time: 0.0608  data: 0.0543  max mem: 10412
Epoch: [3]  [4340/4571]  eta: 0:00:13    time: 0.0580  data: 0.0515  max mem: 10412
Epoch: [3]  [4360/4571]  eta: 0:00:12    time: 0.0580  data: 0.0515  max mem: 10412
Epoch: [3]  [4380/4571]  eta: 0:00:11    time: 0.0581  data: 0.0516  max mem: 10412
Epoch: [3]  [4400/4571]  eta: 0:00:10    time: 0.0581  data: 0.0517  max mem: 10412
Epoch: [3]  [4420/4571]  eta: 0:00:08    time: 0.0580  data: 0.0516  max mem: 10412
Epoch: [3]  [4440/4571]  eta: 0:00:07    time: 0.0583  data: 0.0518  max mem: 10412
Epoch: [3]  [4460/4571]  eta: 0:00:06    time: 0.0581  data: 0.0516  max mem: 10412
Epoch: [3]  [4480/4571]  eta: 0:00:05    time: 0.0582  data: 0.0517  max mem: 10412
Epoch: [3]  [4500/4571]  eta: 0:00:04    time: 0.0581  data: 0.0516  max mem: 10412
Epoch: [3]  [4520/4571]  eta: 0:00:02    time: 0.0581  data: 0.0517  max mem: 10412
Epoch: [3]  [4540/4571]  eta: 0:00:01    time: 0.0589  data: 0.0525  max mem: 10412
Epoch: [3]  [4560/4571]  eta: 0:00:00    time: 0.0581  data: 0.0516  max mem: 10412
Epoch: [3]  [4570/4571]  eta: 0:00:00    time: 0.0580  data: 0.0516  max mem: 10412
Epoch: [3] Total time: 0:04:27 (0.0586 s / it)
:::MLLOG {"namespace": "", "time_ms": 1696365050655, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": 3, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 330, "epoch_num": 3}}
:::MLLOG {"namespace": "", "time_ms": 1696365050655, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 272.9855193938448}, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 334, "step": 4}}
:::MLLOG {"namespace": "", "time_ms": 1696365050656, "event_type": "INTERVAL_START", "key": "eval_start", "value": 4, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 344, "epoch_num": 4}}
Test:  [ 0/97]  eta: 0:00:13  model_time: 0.1340 (0.1340)  evaluator_time: 0.0018 (0.0018)  time: 0.1366  data: 0.0006  max mem: 10412
Test:  [20/97]  eta: 0:00:10  model_time: 0.1351 (0.1330)  evaluator_time: 0.0017 (0.0018)  time: 0.1355  data: 0.0006  max mem: 10412
Test:  [40/97]  eta: 0:00:07  model_time: 0.1331 (0.1330)  evaluator_time: 0.0018 (0.0018)  time: 0.1355  data: 0.0006  max mem: 10412
Test:  [60/97]  eta: 0:00:05  model_time: 0.1303 (0.1327)  evaluator_time: 0.0016 (0.0018)  time: 0.1346  data: 0.0006  max mem: 10412
Test:  [80/97]  eta: 0:00:02  model_time: 0.1338 (0.1331)  evaluator_time: 0.0017 (0.0018)  time: 0.1369  data: 0.0006  max mem: 10412
Test:  [96/97]  eta: 0:00:00  model_time: 0.1328 (0.1328)  evaluator_time: 0.0016 (0.0017)  time: 0.1340  data: 0.0006  max mem: 10412
Test: Total time: 0:00:13 (0.1353 s / it)
Averaged stats: model_time: 0.1328 (0.1349)  evaluator_time: 0.0016 (0.0018)
:::MLLOG {"namespace": "", "time_ms": 1696365064615, "event_type": "INTERVAL_START", "key": "epoch_start", "value": 4, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 158, "epoch_num": 4}}
Epoch: [4]  [   0/4572]  eta: 0:04:26    time: 0.0583  data: 0.0008  max mem: 10412
Epoch: [4]  [  20/4572]  eta: 0:04:22    time: 0.0577  data: 0.0513  max mem: 10412
Epoch: [4]  [  40/4572]  eta: 0:04:22    time: 0.0579  data: 0.0514  max mem: 10412
Epoch: [4]  [  60/4572]  eta: 0:04:20    time: 0.0578  data: 0.0513  max mem: 10412
:::MLLOG {"namespace": "", "time_ms": 1696365069234, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.35085743162430183, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 437, "epoch_num": 4}}
:::MLLOG {"namespace": "", "time_ms": 1696365069235, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 4, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 438, "epoch_num": 4}}
Epoch: [4]  [  80/4572]  eta: 0:04:21    time: 0.0593  data: 0.0528  max mem: 10412
:::MLLOG {"namespace": "", "time_ms": 1696365070488, "event_type": "INTERVAL_END", "key": "run_stop", "value": null, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 315, "status": "success"}}
:::MLLOG {"namespace": "", "time_ms": 1696365070489, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": 4, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 330, "epoch_num": 4}}
:::MLLOG {"namespace": "", "time_ms": 1696365070490, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 280.6319917689925}, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 334, "step": 5}}
Run time 0:19:15
:::MLLOG {"namespace": "", "time_ms": 1696365070490, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 773}}
:::MLLOG {"namespace": "", "time_ms": 1696365070490, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 773}}
:::MLLOG {"namespace": "", "time_ms": 1696365070490, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 773}}
:::MLLOG {"namespace": "", "time_ms": 1696365070490, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 773}}
:::MLLOG {"namespace": "", "time_ms": 1696365070490, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 773}}
:::MLLOG {"namespace": "", "time_ms": 1696365070489, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 773}}
:::MLLOG {"namespace": "", "time_ms": 1696365070490, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 773}}
:::MLLOG {"namespace": "", "time_ms": 1696365070490, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 773}}
:::MLLOG {"namespace": "", "time_ms": 1696365070490, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 773}}
:::MLLOG {"namespace": "", "time_ms": 1696365070489, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 773}}
:::MLLOG {"namespace": "", "time_ms": 1696365070489, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 773}}
:::MLLOG {"namespace": "", "time_ms": 1696365070489, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 773}}
:::MLLOG {"namespace": "", "time_ms": 1696365070489, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 773}}
:::MLLOG {"namespace": "", "time_ms": 1696365070489, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 773}}
:::MLLOG {"namespace": "", "time_ms": 1696365070489, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 773}}
:::MLLOG {"namespace": "", "time_ms": 1696365070489, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 773}}
Loading annotations into memory...
Done (t=0.72s)
Creating index...
Done (t=1.22s)
Loading and preparing results...
DONE (t=2.90s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=2.26s).
Accumulating evaluation results...
DONE (t=0.00s).
IoU metric: bbox
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.23682
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.36580
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.25070
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.00517
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.05644
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.26212
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.35793
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.50939
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.52983
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.02413
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.19294
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.57758
Loading and preparing results...
DONE (t=2.73s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=2.53s).
Accumulating evaluation results...
DONE (t=0.00s).
IoU metric: bbox
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.29477
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.43351
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.31756
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.00589
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.08162
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.32697
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.38503
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.54863
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.57536
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.02886
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.23281
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.62620
Loading and preparing results...
DONE (t=2.43s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=2.31s).
Accumulating evaluation results...
DONE (t=0.00s).
IoU metric: bbox
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.33191
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.47997
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.35655
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.00914
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.09151
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.36780
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.39871
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.56939
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.59751
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.03151
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.25304
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.64847
Loading and preparing results...
DONE (t=2.31s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=2.16s).
Accumulating evaluation results...
DONE (t=0.00s).
IoU metric: bbox
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.35086
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.49567
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.37778
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.00947
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.09173
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.38917
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.41297
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.58636
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.61531
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.03679
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.26430
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.66643
ENDING TIMING RUN AT 2023-10-03 08:31:15 PM
RESULT,SINGLE_STAGE_DETECTOR,,1252,dell,2023-10-03 08:10:23 PM
ENDING TIMING RUN AT 2023-10-03 08:31:15 PM
RESULT,SINGLE_STAGE_DETECTOR,,1252,dell,2023-10-03 08:10:23 PM
ENDING TIMING RUN AT 2023-10-03 08:31:15 PM
RESULT,SINGLE_STAGE_DETECTOR,,1252,dell,2023-10-03 08:10:23 PM
ENDING TIMING RUN AT 2023-10-03 08:31:15 PM
RESULT,SINGLE_STAGE_DETECTOR,,1252,dell,2023-10-03 08:10:23 PM
ENDING TIMING RUN AT 2023-10-03 08:31:15 PM
RESULT,SINGLE_STAGE_DETECTOR,,1252,dell,2023-10-03 08:10:23 PM
ENDING TIMING RUN AT 2023-10-03 08:31:15 PM
RESULT,SINGLE_STAGE_DETECTOR,,1252,dell,2023-10-03 08:10:23 PM
ENDING TIMING RUN AT 2023-10-03 08:31:16 PM
RESULT,SINGLE_STAGE_DETECTOR,,1253,dell,2023-10-03 08:10:23 PM
ENDING TIMING RUN AT 2023-10-03 08:31:16 PM
RESULT,SINGLE_STAGE_DETECTOR,,1252,dell,2023-10-03 08:10:24 PM
ENDING TIMING RUN AT 2023-10-03 08:31:16 PM
RESULT,SINGLE_STAGE_DETECTOR,,1253,dell,2023-10-03 08:10:23 PM
ENDING TIMING RUN AT 2023-10-03 08:31:16 PM
RESULT,SINGLE_STAGE_DETECTOR,,1253,dell,2023-10-03 08:10:23 PM
ENDING TIMING RUN AT 2023-10-03 08:31:16 PM
RESULT,SINGLE_STAGE_DETECTOR,,1253,dell,2023-10-03 08:10:23 PM
ENDING TIMING RUN AT 2023-10-03 08:31:16 PM
RESULT,SINGLE_STAGE_DETECTOR,,1253,dell,2023-10-03 08:10:23 PM
ENDING TIMING RUN AT 2023-10-03 08:31:17 PM
RESULT,SINGLE_STAGE_DETECTOR,,1253,dell,2023-10-03 08:10:24 PM
ENDING TIMING RUN AT 2023-10-03 08:31:17 PM
RESULT,SINGLE_STAGE_DETECTOR,,1254,dell,2023-10-03 08:10:23 PM
ENDING TIMING RUN AT 2023-10-03 08:31:17 PM
RESULT,SINGLE_STAGE_DETECTOR,,1254,dell,2023-10-03 08:10:23 PM
ENDING TIMING RUN AT 2023-10-03 08:31:17 PM
RESULT,SINGLE_STAGE_DETECTOR,,1254,dell,2023-10-03 08:10:23 PM
